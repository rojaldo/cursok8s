<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.26">
<meta name="author" content="DevOps Team">
<title>Curso Completo de Kubernetes</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.square{list-style-type:square}
ul.circle ul:not([class]),ul.disc ul:not([class]),ul.square ul:not([class]){list-style:inherit}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child{border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:first-child,.sidebarblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child,.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock pre>code{display:block}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active,#footnotes .footnote a:first-of-type:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,td.hdlist1,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>
<body class="book toc2 toc-left">
<div id="header">
<h1>Curso Completo de Kubernetes</h1>
<div class="details">
<span id="author" class="author">DevOps Team</span><br>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Temario</div>
<ul class="sectlevel1">
<li><a href="#_módulo_1_introducción_a_kubernetes">1. MÓDULO 1: Introducción a Kubernetes</a>
<ul class="sectlevel2">
<li><a href="#_1_1_conceptos_fundamentales">1.1. 1.1 Conceptos Fundamentales</a>
<ul class="sectlevel3">
<li><a href="#_1_1_1_qué_es_kubernetes">1.1.1. 1.1.1 ¿Qué es Kubernetes?</a></li>
<li><a href="#_1_1_2_comparación_con_docker_swarm">1.1.2. 1.1.2 Comparación con Docker Swarm</a></li>
<li><a href="#_1_1_3_ventajas_de_kubernetes">1.1.3. 1.1.3 Ventajas de Kubernetes</a></li>
<li><a href="#_1_1_4_desventajas_de_kubernetes">1.1.4. 1.1.4 Desventajas de Kubernetes</a></li>
<li><a href="#_1_1_5_casos_de_uso_reales">1.1.5. 1.1.5 Casos de Uso Reales</a></li>
<li><a href="#_1_1_6_arquitectura_general_de_kubernetes">1.1.6. 1.1.6 Arquitectura General de Kubernetes</a></li>
</ul>
</li>
<li><a href="#_1_2_componentes_de_la_arquitectura">1.2. 1.2 Componentes de la Arquitectura</a>
<ul class="sectlevel3">
<li><a href="#_1_2_1_control_plane_nodo_maestro">1.2.1. 1.2.1 Control Plane (Nodo Maestro)</a></li>
<li><a href="#_1_2_2_nodos_worker">1.2.2. 1.2.2 Nodos Worker</a></li>
<li><a href="#_1_2_3_componentes_adicionales">1.2.3. 1.2.3 Componentes Adicionales</a></li>
</ul>
</li>
<li><a href="#_1_3_instalación_y_configuración">1.3. 1.3 Instalación y Configuración</a>
<ul class="sectlevel3">
<li><a href="#_1_3_1_instalación_de_kubectl">1.3.1. 1.3.1 Instalación de kubectl</a></li>
<li><a href="#_1_3_2_instalación_de_docker">1.3.2. 1.3.2 Instalación de Docker</a></li>
<li><a href="#_1_3_3_opciones_de_instalación_de_kubernetes">1.3.3. 1.3.3 Opciones de Instalación de Kubernetes</a></li>
<li><a href="#_1_3_4_configuración_de_kubectl">1.3.4. 1.3.4 Configuración de kubectl</a></li>
<li><a href="#_1_3_5_verificación_de_la_instalación">1.3.5. 1.3.5 Verificación de la Instalación</a></li>
</ul>
</li>
<li><a href="#_1_4_mi_primer_cluster">1.4. 1.4 Mi Primer Cluster</a>
<ul class="sectlevel3">
<li><a href="#_1_4_1_crear_un_cluster_local_con_minikube">1.4.1. 1.4.1 Crear un Cluster Local con Minikube</a></li>
<li><a href="#_1_4_2_conectarse_al_cluster">1.4.2. 1.4.2 Conectarse al Cluster</a></li>
<li><a href="#_1_4_3_explorar_el_cluster">1.4.3. 1.4.3 Explorar el Cluster</a></li>
<li><a href="#_1_4_4_eliminar_el_cluster">1.4.4. 1.4.4 Eliminar el Cluster</a></li>
</ul>
</li>
<li><a href="#_1_5_ejercicios_prácticos">1.5. 1.5 Ejercicios Prácticos</a>
<ul class="sectlevel3">
<li><a href="#_ejercicio_1_desplegar_tu_primera_aplicación">1.5.1. Ejercicio 1: Desplegar tu Primera Aplicación</a></li>
<li><a href="#_ejercicio_2_exponer_tu_aplicación">1.5.2. Ejercicio 2: Exponer tu Aplicación</a></li>
<li><a href="#_ejercicio_3_escalar_tu_aplicación">1.5.3. Ejercicio 3: Escalar tu Aplicación</a></li>
<li><a href="#_ejercicio_4_actualizar_tu_aplicación">1.5.4. Ejercicio 4: Actualizar tu Aplicación</a></li>
<li><a href="#_ejercicio_5_monitoreo_básico">1.5.5. Ejercicio 5: Monitoreo Básico</a></li>
</ul>
</li>
<li><a href="#_1_6_solución_de_problemas_iniciales">1.6. 1.6 Solución de Problemas Iniciales</a>
<ul class="sectlevel3">
<li><a href="#_problema_the_connection_to_the_server_was_refused">1.6.1. Problema: "The connection to the server was refused"</a></li>
<li><a href="#_problema_pods_en_estado_pending">1.6.2. Problema: Pods en estado Pending</a></li>
<li><a href="#_problema_pod_en_estado_crashloopbackoff">1.6.3. Problema: Pod en estado CrashLoopBackOff</a></li>
<li><a href="#_problema_no_puedo_acceder_a_mi_aplicación">1.6.4. Problema: No puedo acceder a mi aplicación</a></li>
</ul>
</li>
<li><a href="#_1_7_resumen_del_módulo_1">1.7. 1.7 Resumen del Módulo 1</a></li>
</ul>
</li>
<li><a href="#_módulo_2_pods_y_contenedores">2. MÓDULO 2: Pods y Contenedores</a>
<ul class="sectlevel2">
<li><a href="#_2_1_pods_basics">2.1. 2.1 Pods Basics</a>
<ul class="sectlevel3">
<li><a href="#_2_1_1_concepto_de_pod">2.1.1. 2.1.1 Concepto de Pod</a></li>
<li><a href="#_2_1_2_pod_vs_contenedor">2.1.2. 2.1.2 Pod vs Contenedor</a></li>
<li><a href="#_2_1_3_ciclo_de_vida_del_pod">2.1.3. 2.1.3 Ciclo de Vida del Pod</a></li>
<li><a href="#_2_1_4_tipos_de_contenedores_en_un_pod">2.1.4. 2.1.4 Tipos de Contenedores en un Pod</a></li>
</ul>
</li>
<li><a href="#_2_2_creación_de_pods">2.2. 2.2 Creación de Pods</a>
<ul class="sectlevel3">
<li><a href="#_2_2_1_yaml_para_pods">2.2.1. 2.2.1 YAML para Pods</a></li>
<li><a href="#_2_2_2_crear_pods_con_kubectl_apply">2.2.2. 2.2.2 Crear Pods con kubectl apply</a></li>
<li><a href="#_2_2_3_campos_obligatorios_y_opcionales">2.2.3. 2.2.3 Campos Obligatorios y Opcionales</a></li>
<li><a href="#_2_2_4_etiquetas_y_anotaciones">2.2.4. 2.2.4 Etiquetas y Anotaciones</a></li>
</ul>
</li>
<li><a href="#_2_3_gestión_de_pods">2.3. 2.3 Gestión de Pods</a>
<ul class="sectlevel3">
<li><a href="#_2_3_1_listar_pods">2.3.1. 2.3.1 Listar Pods</a></li>
<li><a href="#_2_3_2_ver_detalles_de_un_pod">2.3.2. 2.3.2 Ver Detalles de un Pod</a></li>
<li><a href="#_2_3_3_logs_de_pods">2.3.3. 2.3.3 Logs de Pods</a></li>
<li><a href="#_2_3_4_ejecutar_comandos_en_pods">2.3.4. 2.3.4 Ejecutar Comandos en Pods</a></li>
<li><a href="#_2_3_5_eliminar_pods">2.3.5. 2.3.5 Eliminar Pods</a></li>
<li><a href="#_2_3_6_port_forwarding">2.3.6. 2.3.6 Port Forwarding</a></li>
</ul>
</li>
<li><a href="#_2_4_configuración_de_pods">2.4. 2.4 Configuración de Pods</a>
<ul class="sectlevel3">
<li><a href="#_2_4_1_variables_de_entorno">2.4.1. 2.4.1 Variables de Entorno</a></li>
<li><a href="#_2_4_2_volúmenes">2.4.2. 2.4.2 Volúmenes</a></li>
<li><a href="#_2_4_3_probes_health_checks">2.4.3. 2.4.3 Probes (Health Checks)</a></li>
<li><a href="#_2_4_4_resource_limits_y_requests">2.4.4. 2.4.4 Resource Limits y Requests</a></li>
<li><a href="#_2_4_5_security_context">2.4.5. 2.4.5 Security Context</a></li>
</ul>
</li>
<li><a href="#_2_5_troubleshooting_de_pods">2.5. 2.5 Troubleshooting de Pods</a>
<ul class="sectlevel3">
<li><a href="#_2_5_1_comando_describe">2.5.1. 2.5.1 Comando Describe</a></li>
<li><a href="#_2_5_2_ver_eventos">2.5.2. 2.5.2 Ver Eventos</a></li>
<li><a href="#_2_5_3_analizar_logs">2.5.3. 2.5.3 Analizar Logs</a></li>
<li><a href="#_2_5_4_problemas_comunes_y_soluciones">2.5.4. 2.5.4 Problemas Comunes y Soluciones</a></li>
<li><a href="#_2_5_5_herramientas_de_debugging_útiles">2.5.5. 2.5.5 Herramientas de Debugging Útiles</a></li>
</ul>
</li>
<li><a href="#_2_6_ejemplos_prácticos_completos">2.6. 2.6 Ejemplos Prácticos Completos</a>
<ul class="sectlevel3">
<li><a href="#_ejemplo_1_pod_simple_con_health_checks">2.6.1. Ejemplo 1: Pod Simple con Health Checks</a></li>
<li><a href="#_ejemplo_2_pod_con_init_container">2.6.2. Ejemplo 2: Pod con Init Container</a></li>
<li><a href="#_ejemplo_3_pod_con_sidecar_para_logging">2.6.3. Ejemplo 3: Pod con Sidecar para Logging</a></li>
<li><a href="#_ejemplo_4_pod_con_configuración_y_secretos">2.6.4. Ejemplo 4: Pod con Configuración y Secretos</a></li>
<li><a href="#_ejemplo_5_pod_seguro">2.6.5. Ejemplo 5: Pod Seguro</a></li>
</ul>
</li>
<li><a href="#_2_7_resumen_del_módulo_2">2.7. 2.7 Resumen del Módulo 2</a></li>
</ul>
</li>
<li><a href="#_módulo_3_controladores">3. MÓDULO 3: Controladores</a>
<ul class="sectlevel2">
<li><a href="#_3_1_deployments">3.1. 3.1 Deployments</a>
<ul class="sectlevel3">
<li><a href="#_3_1_1_concepto_de_deployment">3.1.1. 3.1.1 Concepto de Deployment</a></li>
<li><a href="#_3_1_2_yaml_de_deployment">3.1.2. 3.1.2 YAML de Deployment</a></li>
<li><a href="#_3_1_3_replicas_y_escalado">3.1.3. 3.1.3 Replicas y Escalado</a></li>
<li><a href="#_3_1_4_actualización_de_deployments">3.1.4. 3.1.4 Actualización de Deployments</a></li>
<li><a href="#_3_1_5_rollback_de_deployments">3.1.5. 3.1.5 Rollback de Deployments</a></li>
<li><a href="#_3_1_6_casos_de_uso">3.1.6. 3.1.6 Casos de Uso</a></li>
</ul>
</li>
<li><a href="#_3_2_replicasets">3.2. 3.2 ReplicaSets</a>
<ul class="sectlevel3">
<li><a href="#_3_2_1_qué_es_un_replicaset">3.2.1. 3.2.1 ¿Qué es un ReplicaSet?</a></li>
<li><a href="#_3_2_2_diferencia_con_deployment">3.2.2. 3.2.2 Diferencia con Deployment</a></li>
<li><a href="#_3_2_3_yaml_de_replicaset">3.2.3. 3.2.3 YAML de ReplicaSet</a></li>
<li><a href="#_3_2_4_manejo_de_replicas">3.2.4. 3.2.4 Manejo de Replicas</a></li>
<li><a href="#_3_2_5_labels_y_selectors">3.2.5. 3.2.5 Labels y Selectors</a></li>
</ul>
</li>
<li><a href="#_3_3_statefulsets">3.3. 3.3 StatefulSets</a>
<ul class="sectlevel3">
<li><a href="#_3_3_1_diferencias_con_deployments">3.3.1. 3.3.1 Diferencias con Deployments</a></li>
<li><a href="#_3_3_2_identidades_estables">3.3.2. 3.3.2 Identidades Estables</a></li>
<li><a href="#_3_3_3_almacenamiento_persistente">3.3.3. 3.3.3 Almacenamiento Persistente</a></li>
<li><a href="#_3_3_4_orden_de_escalado">3.3.4. 3.3.4 Orden de Escalado</a></li>
<li><a href="#_3_3_5_casos_de_uso">3.3.5. 3.3.5 Casos de Uso</a></li>
<li><a href="#_3_3_6_yaml_completo_statefulset_de_postgresql">3.3.6. 3.3.6 YAML Completo: StatefulSet de PostgreSQL</a></li>
</ul>
</li>
<li><a href="#_3_4_daemonsets">3.4. 3.4 DaemonSets</a>
<ul class="sectlevel3">
<li><a href="#_3_4_1_concepto_de_daemonset">3.4.1. 3.4.1 Concepto de DaemonSet</a></li>
<li><a href="#_3_4_2_casos_de_uso">3.4.2. 3.4.2 Casos de Uso</a></li>
<li><a href="#_3_4_3_yaml_de_daemonset">3.4.3. 3.4.3 YAML de DaemonSet</a></li>
<li><a href="#_3_4_4_monitoreo_con_daemonsets">3.4.4. 3.4.4 Monitoreo con DaemonSets</a></li>
<li><a href="#_3_4_5_logging_centralizado_con_fluentd">3.4.5. 3.4.5 Logging Centralizado con Fluentd</a></li>
</ul>
</li>
<li><a href="#_3_5_jobs_y_cronjobs">3.5. 3.5 Jobs y CronJobs</a>
<ul class="sectlevel3">
<li><a href="#_3_5_1_jobs_ejecución_única">3.5.1. 3.5.1 Jobs: Ejecución Única</a></li>
<li><a href="#_3_5_2_job_paralelo">3.5.2. 3.5.2 Job Paralelo</a></li>
<li><a href="#_3_5_3_cronjob_ejecución_programada">3.5.3. 3.5.3 CronJob: Ejecución Programada</a></li>
<li><a href="#_3_5_4_manejo_de_fallos">3.5.4. 3.5.4 Manejo de Fallos</a></li>
<li><a href="#_3_5_5_limpieza_de_jobs_completados">3.5.5. 3.5.5 Limpieza de Jobs Completados</a></li>
</ul>
</li>
<li><a href="#_3_6_ejemplos_completos">3.6. 3.6 Ejemplos Completos</a>
<ul class="sectlevel3">
<li><a href="#_ejemplo_1_deployment_con_todas_las_características">3.6.1. Ejemplo 1: Deployment con Todas las Características</a></li>
<li><a href="#_ejemplo_2_job_de_batch_processing">3.6.2. Ejemplo 2: Job de Batch Processing</a></li>
<li><a href="#_ejemplo_3_cronjob_de_backup">3.6.3. Ejemplo 3: CronJob de Backup</a></li>
</ul>
</li>
<li><a href="#_3_7_comparativa_de_controladores">3.7. 3.7 Comparativa de Controladores</a></li>
<li><a href="#_3_8_resumen_del_módulo_3">3.8. 3.8 Resumen del Módulo 3</a></li>
</ul>
</li>
<li><a href="#_módulo_4_servicios_y_networking">4. MÓDULO 4: Servicios y Networking</a>
<ul class="sectlevel2">
<li><a href="#_4_1_servicios_basics">4.1. 4.1 Servicios Basics</a>
<ul class="sectlevel3">
<li><a href="#_4_1_1_concepto_de_servicio">4.1.1. 4.1.1 Concepto de Servicio</a></li>
<li><a href="#_4_1_2_por_qué_se_necesitan_servicios">4.1.2. 4.1.2 Por Qué se Necesitan Servicios</a></li>
<li><a href="#_4_1_3_selector_labels">4.1.3. 4.1.3 Selector Labels</a></li>
<li><a href="#_4_1_4_endpoints">4.1.4. 4.1.4 Endpoints</a></li>
</ul>
</li>
<li><a href="#_4_2_tipos_de_servicios">4.2. 4.2 Tipos de Servicios</a>
<ul class="sectlevel3">
<li><a href="#_4_2_1_clusterip">4.2.1. 4.2.1 ClusterIP</a></li>
<li><a href="#_4_2_2_nodeport">4.2.2. 4.2.2 NodePort</a></li>
<li><a href="#_4_2_3_loadbalancer">4.2.3. 4.2.3 LoadBalancer</a></li>
<li><a href="#_4_2_4_externalname">4.2.4. 4.2.4 ExternalName</a></li>
</ul>
</li>
<li><a href="#_4_3_discovery_y_dns">4.3. 4.3 Discovery y DNS</a>
<ul class="sectlevel3">
<li><a href="#_4_3_1_kubernetes_dns">4.3.1. 4.3.1 Kubernetes DNS</a></li>
<li><a href="#_4_3_2_nombres_de_dominio_internos">4.3.2. 4.3.2 Nombres de Dominio Internos</a></li>
<li><a href="#_4_3_3_búsqueda_de_servicios">4.3.3. 4.3.3 Búsqueda de Servicios</a></li>
<li><a href="#_4_3_4_configuración_de_resolución_dns">4.3.4. 4.3.4 Configuración de Resolución DNS</a></li>
<li><a href="#_4_3_5_headless_services">4.3.5. 4.3.5 Headless Services</a></li>
</ul>
</li>
<li><a href="#_4_4_ingress">4.4. 4.4 Ingress</a>
<ul class="sectlevel3">
<li><a href="#_4_4_1_concepto_de_ingress">4.4.1. 4.4.1 Concepto de Ingress</a></li>
<li><a href="#_4_4_2_ingress_controller">4.4.2. 4.4.2 Ingress Controller</a></li>
<li><a href="#_4_4_3_reglas_de_ingress">4.4.3. 4.4.3 Reglas de Ingress</a></li>
<li><a href="#_4_4_4_hosts_virtuales">4.4.4. 4.4.4 Hosts Virtuales</a></li>
<li><a href="#_4_4_5_tlsssl">4.4.5. 4.4.5 TLS/SSL</a></li>
<li><a href="#_4_4_6_path_based_routing">4.4.6. 4.4.6 Path-Based Routing</a></li>
<li><a href="#_4_4_7_host_based_routing">4.4.7. 4.4.7 Host-Based Routing</a></li>
</ul>
</li>
<li><a href="#_4_5_network_policies">4.5. 4.5 Network Policies</a>
<ul class="sectlevel3">
<li><a href="#_4_5_1_concepto_de_network_policy">4.5.1. 4.5.1 Concepto de Network Policy</a></li>
<li><a href="#_4_5_2_ingress_rules">4.5.2. 4.5.2 Ingress Rules</a></li>
<li><a href="#_4_5_3_egress_rules">4.5.3. 4.5.3 Egress Rules</a></li>
<li><a href="#_4_5_4_selección_de_pods">4.5.4. 4.5.4 Selección de Pods</a></li>
<li><a href="#_4_5_5_casos_de_uso_de_seguridad">4.5.5. 4.5.5 Casos de Uso de Seguridad</a></li>
<li><a href="#_4_5_6_debugging_de_network_policies">4.5.6. 4.5.6 Debugging de Network Policies</a></li>
</ul>
</li>
<li><a href="#_4_6_ejemplos_completos">4.6. 4.6 Ejemplos Completos</a>
<ul class="sectlevel3">
<li><a href="#_ejemplo_1_aplicación_web_multiservicio">4.6.1. Ejemplo 1: Aplicación Web Multiservicio</a></li>
<li><a href="#_ejemplo_2_microservicios_con_múltiples_versiones">4.6.2. Ejemplo 2: Microservicios con múltiples versiones</a></li>
<li><a href="#_ejemplo_3_loadbalancer_service">4.6.3. Ejemplo 3: LoadBalancer Service</a></li>
</ul>
</li>
<li><a href="#_4_7_resumen_del_módulo_4">4.7. 4.7 Resumen del Módulo 4</a></li>
</ul>
</li>
<li><a href="#_módulo_5_configuración_y_secretos">5. MÓDULO 5: Configuración y Secretos</a>
<ul class="sectlevel2">
<li><a href="#_5_1_configmaps">5.1. 5.1 ConfigMaps</a>
<ul class="sectlevel3">
<li><a href="#_5_1_1_qué_es_un_configmap">5.1.1. 5.1.1 ¿Qué es un ConfigMap?</a></li>
<li><a href="#_5_1_2_crear_configmaps">5.1.2. 5.1.2 Crear ConfigMaps</a></li>
<li><a href="#_5_1_3_usar_configmaps_en_pods">5.1.3. 5.1.3 Usar ConfigMaps en Pods</a></li>
<li><a href="#_5_1_4_actualizar_configmaps">5.1.4. 5.1.4 Actualizar ConfigMaps</a></li>
<li><a href="#_5_1_5_casos_de_uso">5.1.5. 5.1.5 Casos de Uso</a></li>
</ul>
</li>
<li><a href="#_5_2_secrets">5.2. 5.2 Secrets</a>
<ul class="sectlevel3">
<li><a href="#_5_2_1_qué_es_un_secret">5.2.1. 5.2.1 ¿Qué es un Secret?</a></li>
<li><a href="#_5_2_2_tipos_de_secrets">5.2.2. 5.2.2 Tipos de Secrets</a></li>
<li><a href="#_5_2_3_crear_secrets">5.2.3. 5.2.3 Crear Secrets</a></li>
<li><a href="#_5_2_4_usar_secrets_en_pods">5.2.4. 5.2.4 Usar Secrets en Pods</a></li>
<li><a href="#_5_2_5_seguridad_de_secrets">5.2.5. 5.2.5 Seguridad de Secrets</a></li>
<li><a href="#_5_2_6_secret_management_externo">5.2.6. 5.2.6 Secret Management Externo</a></li>
</ul>
</li>
<li><a href="#_5_3_variables_de_entorno">5.3. 5.3 Variables de Entorno</a>
<ul class="sectlevel3">
<li><a href="#_5_3_1_pasar_variables_a_pods">5.3.1. 5.3.1 Pasar Variables a Pods</a></li>
<li><a href="#_5_3_2_usar_valores_de_objetos">5.3.2. 5.3.2 Usar Valores de Objetos</a></li>
<li><a href="#_5_3_3_combinación_completa">5.3.3. 5.3.3 Combinación Completa</a></li>
</ul>
</li>
<li><a href="#_5_4_image_pull_secrets">5.4. 5.4 Image Pull Secrets</a>
<ul class="sectlevel3">
<li><a href="#_5_4_1_registros_privados">5.4.1. 5.4.1 Registros Privados</a></li>
<li><a href="#_5_4_2_crear_image_pull_secrets">5.4.2. 5.4.2 Crear Image Pull Secrets</a></li>
<li><a href="#_5_4_3_usar_en_deployments">5.4.3. 5.4.3 Usar en Deployments</a></li>
<li><a href="#_5_4_4_configuración_por_defecto">5.4.4. 5.4.4 Configuración por Defecto</a></li>
</ul>
</li>
<li><a href="#_5_5_proyección_de_secrets">5.5. 5.5 Proyección de Secrets</a>
<ul class="sectlevel3">
<li><a href="#_5_5_1_proyección_de_volúmenes">5.5.1. 5.5.1 Proyección de Volúmenes</a></li>
<li><a href="#_5_5_2_token_automático_de_service_account">5.5.2. 5.5.2 Token Automático de Service Account</a></li>
<li><a href="#_5_5_3_casos_de_uso_complejos">5.5.3. 5.5.3 Casos de Uso Complejos</a></li>
</ul>
</li>
<li><a href="#_5_6_ejemplos_completos">5.6. 5.6 Ejemplos Completos</a>
<ul class="sectlevel3">
<li><a href="#_ejemplo_1_aplicación_con_configmap_y_secret">5.6.1. Ejemplo 1: Aplicación con ConfigMap y Secret</a></li>
<li><a href="#_ejemplo_2_aplicación_con_registro_privado">5.6.2. Ejemplo 2: Aplicación con Registro Privado</a></li>
<li><a href="#_ejemplo_3_aplicación_con_certificados_y_secretos">5.6.3. Ejemplo 3: Aplicación con Certificados y Secretos</a></li>
</ul>
</li>
<li><a href="#_5_7_best_practices">5.7. 5.7 Best Practices</a></li>
<li><a href="#_5_8_resumen_del_módulo_5">5.8. 5.8 Resumen del Módulo 5</a></li>
</ul>
</li>
<li><a href="#_módulo_6_storage">6. MÓDULO 6: Storage</a>
<ul class="sectlevel2">
<li><a href="#_6_1_persistent_volumes_pv">6.1. 6.1 Persistent Volumes (PV)</a>
<ul class="sectlevel3">
<li><a href="#_6_1_1_qué_es_un_persistent_volume">6.1.1. 6.1.1 ¿Qué es un Persistent Volume?</a></li>
<li><a href="#_6_1_2_tipos_de_storage_backends">6.1.2. 6.1.2 Tipos de Storage Backends</a></li>
<li><a href="#_6_1_3_crear_persistent_volumes">6.1.3. 6.1.3 Crear Persistent Volumes</a></li>
<li><a href="#_6_1_4_políticas_de_reclamación">6.1.4. 6.1.4 Políticas de Reclamación</a></li>
<li><a href="#_6_1_5_access_modes">6.1.5. 6.1.5 Access Modes</a></li>
</ul>
</li>
<li><a href="#_6_2_persistentvolumeclaims_pvc">6.2. 6.2 PersistentVolumeClaims (PVC)</a>
<ul class="sectlevel3">
<li><a href="#_6_2_1_qué_es_un_persistentvolumeclaim">6.2.1. 6.2.1 ¿Qué es un PersistentVolumeClaim?</a></li>
<li><a href="#_6_2_2_crear_persistentvolumeclaims">6.2.2. 6.2.2 Crear PersistentVolumeClaims</a></li>
<li><a href="#_6_2_3_usar_pvc_en_pods">6.2.3. 6.2.3 Usar PVC en Pods</a></li>
<li><a href="#_6_2_4_estados_de_pvc">6.2.4. 6.2.4 Estados de PVC</a></li>
</ul>
</li>
<li><a href="#_6_3_storage_classes">6.3. 6.3 Storage Classes</a>
<ul class="sectlevel3">
<li><a href="#_6_3_1_qué_es_un_storage_class">6.3.1. 6.3.1 ¿Qué es un Storage Class?</a></li>
<li><a href="#_6_3_2_storage_classes_en_diferentes_clouds">6.3.2. 6.3.2 Storage Classes en Diferentes Clouds</a></li>
<li><a href="#_6_3_3_storage_class_predeterminado">6.3.3. 6.3.3 Storage Class Predeterminado</a></li>
<li><a href="#_6_3_4_parámetros_avanzados">6.3.4. 6.3.4 Parámetros Avanzados</a></li>
</ul>
</li>
<li><a href="#_6_4_statefulsets_y_storage">6.4. 6.4 StatefulSets y Storage</a>
<ul class="sectlevel3">
<li><a href="#_6_4_1_por_qué_statefulset_storage">6.4.1. 6.4.1 ¿Por qué StatefulSet + Storage?</a></li>
<li><a href="#_6_4_2_volumeclaimtemplates">6.4.2. 6.4.2 volumeClaimTemplates</a></li>
<li><a href="#_6_4_3_postgresql_con_statefulset">6.4.3. 6.4.3 PostgreSQL con StatefulSet</a></li>
<li><a href="#_6_4_4_escalado_de_statefulsets">6.4.4. 6.4.4 Escalado de StatefulSets</a></li>
</ul>
</li>
<li><a href="#_6_5_snapshots_y_backups">6.5. 6.5 Snapshots y Backups</a>
<ul class="sectlevel3">
<li><a href="#_6_5_1_volumesnapshots">6.5.1. 6.5.1 VolumeSnapshots</a></li>
<li><a href="#_6_5_2_crear_snapshots">6.5.2. 6.5.2 Crear Snapshots</a></li>
<li><a href="#_6_5_3_restaurar_desde_snapshot">6.5.3. 6.5.3 Restaurar desde Snapshot</a></li>
<li><a href="#_6_5_4_estrategias_de_backup">6.5.4. 6.5.4 Estrategias de Backup</a></li>
<li><a href="#_6_5_5_disaster_recovery">6.5.5. 6.5.5 Disaster Recovery</a></li>
</ul>
</li>
<li><a href="#_6_6_ejemplos_completos">6.6. 6.6 Ejemplos Completos</a>
<ul class="sectlevel3">
<li><a href="#_ejemplo_1_wordpress_con_storage">6.6.1. Ejemplo 1: WordPress con Storage</a></li>
<li><a href="#_ejemplo_2_backup_y_restauración">6.6.2. Ejemplo 2: Backup y Restauración</a></li>
</ul>
</li>
<li><a href="#_6_7_best_practices">6.7. 6.7 Best Practices</a></li>
<li><a href="#_6_8_resumen_del_módulo_6">6.8. 6.8 Resumen del Módulo 6</a></li>
</ul>
</li>
<li><a href="#_módulo_7_scaling_y_autoscaling">7. MÓDULO 7: Scaling y Autoscaling</a>
<ul class="sectlevel2">
<li><a href="#_7_1_escalado_manual">7.1. 7.1 Escalado Manual</a>
<ul class="sectlevel3">
<li><a href="#_7_1_1_concepto_básico">7.1.1. 7.1.1 Concepto Básico</a></li>
<li><a href="#_7_1_2_kubectl_scale">7.1.2. 7.1.2 Kubectl Scale</a></li>
<li><a href="#_7_1_3_editar_deployment">7.1.3. 7.1.3 Editar Deployment</a></li>
<li><a href="#_7_1_4_escalado_declarativo">7.1.4. 7.1.4 Escalado Declarativo</a></li>
</ul>
</li>
<li><a href="#_7_2_horizontal_pod_autoscaler_hpa">7.2. 7.2 Horizontal Pod Autoscaler (HPA)</a>
<ul class="sectlevel3">
<li><a href="#_7_2_1_qué_es_hpa">7.2.1. 7.2.1 ¿Qué es HPA?</a></li>
<li><a href="#_7_2_2_instalar_metrics_server">7.2.2. 7.2.2 Instalar Metrics Server</a></li>
<li><a href="#_7_2_3_hpa_basado_en_cpu">7.2.3. 7.2.3 HPA Basado en CPU</a></li>
<li><a href="#_7_2_4_hpa_v1_simplificado">7.2.4. 7.2.4 HPA v1 (Simplificado)</a></li>
<li><a href="#_7_2_5_métricas_personalizadas">7.2.5. 7.2.5 Métricas Personalizadas</a></li>
<li><a href="#_7_2_6_comportamiento_de_escalado">7.2.6. 7.2.6 Comportamiento de Escalado</a></li>
</ul>
</li>
<li><a href="#_7_3_vertical_pod_autoscaler_vpa">7.3. 7.3 Vertical Pod Autoscaler (VPA)</a>
<ul class="sectlevel3">
<li><a href="#_7_3_1_qué_es_vpa">7.3.1. 7.3.1 ¿Qué es VPA?</a></li>
<li><a href="#_7_3_2_instalar_vpa">7.3.2. 7.3.2 Instalar VPA</a></li>
<li><a href="#_7_3_3_vpa_modes">7.3.3. 7.3.3 VPA Modes</a></li>
<li><a href="#_7_3_4_ejemplo_completo_vpa_hpa">7.3.4. 7.3.4 Ejemplo Completo: VPA + HPA</a></li>
</ul>
</li>
<li><a href="#_7_4_cluster_autoscaler">7.4. 7.4 Cluster Autoscaler</a>
<ul class="sectlevel3">
<li><a href="#_7_4_1_qué_es_cluster_autoscaler">7.4.1. 7.4.1 ¿Qué es Cluster Autoscaler?</a></li>
<li><a href="#_7_4_2_instalar_cluster_autoscaler">7.4.2. 7.4.2 Instalar Cluster Autoscaler</a></li>
<li><a href="#_7_4_3_configuración">7.4.3. 7.4.3 Configuración</a></li>
<li><a href="#_7_4_4_combinación_hpa_cluster_autoscaler">7.4.4. 7.4.4 Combinación: HPA + Cluster Autoscaler</a></li>
<li><a href="#_7_4_5_debugging_de_cluster_autoscaler">7.4.5. 7.4.5 Debugging de Cluster Autoscaler</a></li>
</ul>
</li>
<li><a href="#_7_5_pruebas_de_carga">7.5. 7.5 Pruebas de Carga</a>
<ul class="sectlevel3">
<li><a href="#_7_5_1_generar_carga">7.5.1. 7.5.1 Generar Carga</a></li>
<li><a href="#_7_5_2_monitorar_escalado">7.5.2. 7.5.2 Monitorar Escalado</a></li>
<li><a href="#_7_5_3_caso_práctico_e_commerce_black_friday">7.5.3. 7.5.3 Caso Práctico: E-Commerce Black Friday</a></li>
<li><a href="#_7_5_4_debugging_de_autoscaling">7.5.4. 7.5.4 Debugging de Autoscaling</a></li>
</ul>
</li>
<li><a href="#_7_6_ejemplos_completos">7.6. 7.6 Ejemplos Completos</a>
<ul class="sectlevel3">
<li><a href="#_ejemplo_1_stack_completo_de_autoscaling">7.6.1. Ejemplo 1: Stack Completo de Autoscaling</a></li>
<li><a href="#_ejemplo_2_stateful_app_con_vpa">7.6.2. Ejemplo 2: Stateful App con VPA</a></li>
</ul>
</li>
<li><a href="#_7_7_best_practices">7.7. 7.7 Best Practices</a></li>
<li><a href="#_7_8_resumen_del_módulo_7">7.8. 7.8 Resumen del Módulo 7</a></li>
</ul>
</li>
<li><a href="#_módulo_8_seguridad">8. MÓDULO 8: Seguridad</a>
<ul class="sectlevel2">
<li><a href="#_8_1_autenticación_y_rbac">8.1. 8.1 Autenticación y RBAC</a>
<ul class="sectlevel3">
<li><a href="#_8_1_1_usuarios_y_service_accounts">8.1.1. 8.1.1 Usuarios y Service Accounts</a></li>
<li><a href="#_8_1_2_rbac_role_based_access_control">8.1.2. 8.1.2 RBAC (Role-Based Access Control)</a></li>
<li><a href="#_8_1_3_roles_predefinidos">8.1.3. 8.1.3 Roles Predefinidos</a></li>
<li><a href="#_8_1_4_ejemplo_completo_rbac">8.1.4. 8.1.4 Ejemplo Completo RBAC</a></li>
</ul>
</li>
<li><a href="#_8_2_pod_security">8.2. 8.2 Pod Security</a>
<ul class="sectlevel3">
<li><a href="#_8_2_1_security_context">8.2.1. 8.2.1 Security Context</a></li>
<li><a href="#_8_2_2_pod_security_standards_pss">8.2.2. 8.2.2 Pod Security Standards (PSS)</a></li>
<li><a href="#_8_2_3_policies_de_admisión">8.2.3. 8.2.3 Policies de Admisión</a></li>
<li><a href="#_8_2_4_ejemplo_deployment_seguro">8.2.4. 8.2.4 Ejemplo: Deployment Seguro</a></li>
</ul>
</li>
<li><a href="#_8_3_network_policies">8.3. 8.3 Network Policies</a>
<ul class="sectlevel3">
<li><a href="#_8_3_1_concepto">8.3.1. 8.3.1 Concepto</a></li>
<li><a href="#_8_3_2_default_deny">8.3.2. 8.3.2 Default Deny</a></li>
<li><a href="#_8_3_3_allow_tráfico_ingress">8.3.3. 8.3.3 Allow Tráfico Ingress</a></li>
<li><a href="#_8_3_4_allow_tráfico_egress">8.3.4. 8.3.4 Allow Tráfico Egress</a></li>
<li><a href="#_8_3_5_caso_práctico_3_tier_architecture">8.3.5. 8.3.5 Caso Práctico: 3-Tier Architecture</a></li>
<li><a href="#_8_3_6_debugging_network_policies">8.3.6. 8.3.6 Debugging Network Policies</a></li>
</ul>
</li>
<li><a href="#_8_4_encriptación_y_certificados">8.4. 8.4 Encriptación y Certificados</a>
<ul class="sectlevel3">
<li><a href="#_8_4_1_tlsssl_certificates">8.4.1. 8.4.1 TLS/SSL Certificates</a></li>
<li><a href="#_8_4_2_encriptación_en_reposo_etcd">8.4.2. 8.4.2 Encriptación en Reposo (etcd)</a></li>
<li><a href="#_8_4_3_secrets_con_encryption">8.4.3. 8.4.3 Secrets con Encryption</a></li>
</ul>
</li>
<li><a href="#_8_5_auditoría_y_monitoreo">8.5. 8.5 Auditoría y Monitoreo</a>
<ul class="sectlevel3">
<li><a href="#_8_5_1_audit_logging">8.5.1. 8.5.1 Audit Logging</a></li>
<li><a href="#_8_5_2_rbac_auditoría">8.5.2. 8.5.2 RBAC Auditoría</a></li>
<li><a href="#_8_5_3_falco_runtime_security">8.5.3. 8.5.3 Falco (Runtime Security)</a></li>
</ul>
</li>
<li><a href="#_8_6_ejemplo_completo_aplicación_segura">8.6. 8.6 Ejemplo Completo: Aplicación Segura</a></li>
<li><a href="#_8_7_best_practices">8.7. 8.7 Best Practices</a></li>
<li><a href="#_8_8_resumen_del_módulo_8">8.8. 8.8 Resumen del Módulo 8</a></li>
</ul>
</li>
<li><a href="#_módulo_9_monitoreo_y_logging">9. MÓDULO 9: Monitoreo y Logging</a>
<ul class="sectlevel2">
<li><a href="#_9_1_metrics_server_y_recolección_de_métricas">9.1. 9.1 Metrics Server y Recolección de Métricas</a>
<ul class="sectlevel3">
<li><a href="#_9_1_1_qué_es_metrics_server">9.1.1. 9.1.1 ¿Qué es Metrics Server?</a></li>
<li><a href="#_9_1_2_fuentes_de_métricas">9.1.2. 9.1.2 Fuentes de Métricas</a></li>
<li><a href="#_9_1_3_scrapers_de_métricas_personalizadas">9.1.3. 9.1.3 Scrapers de Métricas Personalizadas</a></li>
</ul>
</li>
<li><a href="#_9_2_prometheus">9.2. 9.2 Prometheus</a>
<ul class="sectlevel3">
<li><a href="#_9_2_1_arquitectura_de_prometheus">9.2.1. 9.2.1 Arquitectura de Prometheus</a></li>
<li><a href="#_9_2_2_instalación_de_prometheus">9.2.2. 9.2.2 Instalación de Prometheus</a></li>
<li><a href="#_9_2_3_configuración_de_prometheus">9.2.3. 9.2.3 Configuración de Prometheus</a></li>
<li><a href="#_9_2_4_promql_prometheus_query_language">9.2.4. 9.2.4 PromQL (Prometheus Query Language)</a></li>
<li><a href="#_9_2_5_alert_rules">9.2.5. 9.2.5 Alert Rules</a></li>
<li><a href="#_9_2_6_alertmanager">9.2.6. 9.2.6 AlertManager</a></li>
</ul>
</li>
<li><a href="#_9_3_grafana">9.3. 9.3 Grafana</a>
<ul class="sectlevel3">
<li><a href="#_9_3_1_instalación_de_grafana">9.3.1. 9.3.1 Instalación de Grafana</a></li>
<li><a href="#_9_3_2_conectar_prometheus_como_data_source">9.3.2. 9.3.2 Conectar Prometheus como Data Source</a></li>
<li><a href="#_9_3_3_dashboard_personalizado_json">9.3.3. 9.3.3 Dashboard Personalizado (JSON)</a></li>
<li><a href="#_9_3_4_alertas_en_grafana">9.3.4. 9.3.4 Alertas en Grafana</a></li>
</ul>
</li>
<li><a href="#_9_4_elk_stack_elasticsearch_logstash_kibana">9.4. 9.4 ELK Stack: Elasticsearch, Logstash, Kibana</a>
<ul class="sectlevel3">
<li><a href="#_9_4_1_arquitectura_de_logging">9.4.1. 9.4.1 Arquitectura de Logging</a></li>
<li><a href="#_9_4_2_instalación_de_elk_stack">9.4.2. 9.4.2 Instalación de ELK Stack</a></li>
<li><a href="#_9_4_3_fluentd_para_recolectar_logs">9.4.3. 9.4.3 Fluentd para Recolectar Logs</a></li>
<li><a href="#_9_4_4_kibana">9.4.4. 9.4.4 Kibana</a></li>
<li><a href="#_9_4_5_búsqueda_en_kibana_kql">9.4.5. 9.4.5 Búsqueda en Kibana (KQL)</a></li>
</ul>
</li>
<li><a href="#_9_5_distributed_tracing_con_jaeger">9.5. 9.5 Distributed Tracing con Jaeger</a>
<ul class="sectlevel3">
<li><a href="#_9_5_1_concepto">9.5.1. 9.5.1 Concepto</a></li>
<li><a href="#_9_5_2_instalación_de_jaeger">9.5.2. 9.5.2 Instalación de Jaeger</a></li>
<li><a href="#_9_5_3_instrumentar_aplicación_opentelemetry">9.5.3. 9.5.3 Instrumentar Aplicación (OpenTelemetry)</a></li>
<li><a href="#_9_5_4_análisis_en_jaeger">9.5.4. 9.5.4 Análisis en Jaeger</a></li>
</ul>
</li>
<li><a href="#_9_6_observabilidad_completa_stack_integrado">9.6. 9.6 Observabilidad Completa: Stack Integrado</a></li>
<li><a href="#_9_7_best_practices">9.7. 9.7 Best Practices</a></li>
<li><a href="#_9_8_resumen_del_módulo_9">9.8. 9.8 Resumen del Módulo 9</a></li>
</ul>
</li>
<li><a href="#_módulo_10_gitops_y_cicd">10. MÓDULO 10: GitOps y CI/CD</a>
<ul class="sectlevel2">
<li><a href="#_10_1_conceptos_fundamentales">10.1. 10.1 Conceptos Fundamentales</a>
<ul class="sectlevel3">
<li><a href="#_10_1_1_git_como_fuente_de_verdad">10.1.1. 10.1.1 Git como Fuente de Verdad</a></li>
<li><a href="#_10_1_2_declarativo_vs_imperativo">10.1.2. 10.1.2 Declarativo vs Imperativo</a></li>
<li><a href="#_10_1_3_push_vs_pull">10.1.3. 10.1.3 Push vs Pull</a></li>
</ul>
</li>
<li><a href="#_10_2_flux_cd">10.2. 10.2 Flux CD</a>
<ul class="sectlevel3">
<li><a href="#_10_2_1_instalación_de_flux">10.2.1. 10.2.1 Instalación de Flux</a></li>
<li><a href="#_10_2_2_gitrepository_monitorear_cambios">10.2.2. 10.2.2 GitRepository (Monitorear cambios)</a></li>
<li><a href="#_10_2_3_kustomization_aplicar_configuración">10.2.3. 10.2.3 Kustomization (Aplicar configuración)</a></li>
<li><a href="#_10_2_4_helmrelease_gestionar_helm_charts">10.2.4. 10.2.4 HelmRelease (Gestionar Helm Charts)</a></li>
<li><a href="#_10_2_5_automatización_de_actualizaciones">10.2.5. 10.2.5 Automatización de Actualizaciones</a></li>
<li><a href="#_10_2_6_notificaciones">10.2.6. 10.2.6 Notificaciones</a></li>
</ul>
</li>
<li><a href="#_10_3_argocd">10.3. 10.3 ArgoCD</a>
<ul class="sectlevel3">
<li><a href="#_10_3_1_instalación_de_argocd">10.3.1. 10.3.1 Instalación de ArgoCD</a></li>
<li><a href="#_10_3_2_application_declarar_aplicación">10.3.2. 10.3.2 Application (Declarar aplicación)</a></li>
<li><a href="#_10_3_3_sincronización">10.3.3. 10.3.3 Sincronización</a></li>
<li><a href="#_10_3_4_appproject_rbac">10.3.4. 10.3.4 AppProject (RBAC)</a></li>
<li><a href="#_10_3_5_notifications">10.3.5. 10.3.5 Notifications</a></li>
</ul>
</li>
<li><a href="#_10_4_cicd_pipelines">10.4. 10.4 CI/CD Pipelines</a>
<ul class="sectlevel3">
<li><a href="#_10_4_1_github_actions">10.4.1. 10.4.1 GitHub Actions</a></li>
<li><a href="#_10_4_2_tekton_pipelines">10.4.2. 10.4.2 Tekton Pipelines</a></li>
<li><a href="#_10_4_3_webhook_para_cicd_automático">10.4.3. 10.4.3 Webhook para CI/CD automático</a></li>
</ul>
</li>
<li><a href="#_10_5_versionado_y_releases">10.5. 10.5 Versionado y Releases</a>
<ul class="sectlevel3">
<li><a href="#_10_5_1_semantic_versioning">10.5.1. 10.5.1 Semantic Versioning</a></li>
<li><a href="#_10_5_2_changelog_automático">10.5.2. 10.5.2 Changelog Automático</a></li>
<li><a href="#_10_5_3_github_releases">10.5.3. 10.5.3 GitHub Releases</a></li>
</ul>
</li>
<li><a href="#_10_6_ejemplo_completo_gitops_workflow">10.6. 10.6 Ejemplo Completo: GitOps Workflow</a></li>
<li><a href="#_10_7_best_practices">10.7. 10.7 Best Practices</a></li>
<li><a href="#_10_8_resumen_del_módulo_10">10.8. 10.8 Resumen del Módulo 10</a></li>
</ul>
</li>
<li><a href="#_módulo_11_helm_package_manager">11. MÓDULO 11: Helm Package Manager</a>
<ul class="sectlevel2">
<li><a href="#_11_1_helm_basics">11.1. 11.1 Helm Basics</a>
<ul class="sectlevel3">
<li><a href="#_11_1_1_instalación">11.1.1. 11.1.1 Instalación</a></li>
<li><a href="#_11_1_2_chart_qué_es">11.1.2. 11.1.2 Chart: Qué es</a></li>
<li><a href="#_11_1_3_release_instalación_de_chart">11.1.3. 11.1.3 Release: Instalación de Chart</a></li>
<li><a href="#_11_1_4_actualizar_y_rollback">11.1.4. 11.1.4 Actualizar y Rollback</a></li>
</ul>
</li>
<li><a href="#_11_2_estructura_de_chart">11.2. 11.2 Estructura de Chart</a>
<ul class="sectlevel3">
<li><a href="#_11_2_1_chart_yaml">11.2.1. 11.2.1 Chart.yaml</a></li>
<li><a href="#_11_2_2_values_yaml">11.2.2. 11.2.2 values.yaml</a></li>
<li><a href="#_11_2_3_templates">11.2.3. 11.2.3 templates/</a></li>
</ul>
</li>
<li><a href="#_11_3_templating_con_helm">11.3. 11.3 Templating con Helm</a>
<ul class="sectlevel3">
<li><a href="#_11_3_1_funciones_básicas">11.3.1. 11.3.1 Funciones Básicas</a></li>
<li><a href="#_11_3_2_condicionales_avanzados">11.3.2. 11.3.2 Condicionales Avanzados</a></li>
<li><a href="#_11_3_3_bucles">11.3.3. 11.3.3 Bucles</a></li>
</ul>
</li>
<li><a href="#_11_4_crear_chart_personalizado">11.4. 11.4 Crear Chart Personalizado</a>
<ul class="sectlevel3">
<li><a href="#_11_4_1_crear_chart">11.4.1. 11.4.1 Crear Chart</a></li>
<li><a href="#_11_4_2_dependencias">11.4.2. 11.4.2 Dependencias</a></li>
<li><a href="#_11_4_3_testing_de_charts">11.4.3. 11.4.3 Testing de Charts</a></li>
<li><a href="#_11_4_4_hooks_pre_install_post_install_etc">11.4.4. 11.4.4 Hooks (Pre-install, Post-install, etc.)</a></li>
</ul>
</li>
<li><a href="#_11_5_gestión_de_releases">11.5. 11.5 Gestión de Releases</a>
<ul class="sectlevel3">
<li><a href="#_11_5_1_instalación_avanzada">11.5.1. 11.5.1 Instalación Avanzada</a></li>
<li><a href="#_11_5_2_upgrades">11.5.2. 11.5.2 Upgrades</a></li>
<li><a href="#_11_5_3_rollback">11.5.3. 11.5.3 Rollback</a></li>
<li><a href="#_11_5_4_valores_override">11.5.4. 11.5.4 Valores Override</a></li>
</ul>
</li>
<li><a href="#_11_6_repositorios_helm">11.6. 11.6 Repositorios Helm</a>
<ul class="sectlevel3">
<li><a href="#_11_6_1_crear_y_publicar_chart">11.6.1. 11.6.1 Crear y Publicar Chart</a></li>
<li><a href="#_11_6_2_repositorio_privado">11.6.2. 11.6.2 Repositorio Privado</a></li>
</ul>
</li>
<li><a href="#_11_7_ejemplo_completo_wordpress_con_helm">11.7. 11.7 Ejemplo Completo: WordPress con Helm</a></li>
<li><a href="#_11_8_best_practices">11.8. 11.8 Best Practices</a></li>
<li><a href="#_11_9_resumen_del_módulo_11">11.9. 11.9 Resumen del Módulo 11</a></li>
</ul>
</li>
<li><a href="#_módulo_12_service_mesh_con_istio">12. MÓDULO 12: Service Mesh con Istio</a>
<ul class="sectlevel2">
<li><a href="#_12_1_conceptos_de_service_mesh">12.1. 12.1 Conceptos de Service Mesh</a>
<ul class="sectlevel3">
<li><a href="#_12_1_1_qué_es_un_service_mesh">12.1.1. 12.1.1 ¿Qué es un Service Mesh?</a></li>
<li><a href="#_12_1_2_sidecar_proxies">12.1.2. 12.1.2 Sidecar Proxies</a></li>
<li><a href="#_12_1_3_control_plane_vs_data_plane">12.1.3. 12.1.3 Control Plane vs Data Plane</a></li>
<li><a href="#_12_1_4_casos_de_uso">12.1.4. 12.1.4 Casos de Uso</a></li>
</ul>
</li>
<li><a href="#_12_2_istio_instalación_y_arquitectura">12.2. 12.2 Istio: Instalación y Arquitectura</a>
<ul class="sectlevel3">
<li><a href="#_12_2_1_instalación_de_istio">12.2.1. 12.2.1 Instalación de Istio</a></li>
<li><a href="#_12_2_2_arquitectura_de_istio">12.2.2. 12.2.2 Arquitectura de Istio</a></li>
<li><a href="#_12_2_3_envoy_proxies">12.2.3. 12.2.3 Envoy Proxies</a></li>
<li><a href="#_12_2_4_validación_de_configuración">12.2.4. 12.2.4 Validación de Configuración</a></li>
</ul>
</li>
<li><a href="#_12_3_traffic_management">12.3. 12.3 Traffic Management</a>
<ul class="sectlevel3">
<li><a href="#_12_3_1_virtualservice_routing">12.3.1. 12.3.1 VirtualService: Routing</a></li>
<li><a href="#_12_3_2_destinationrule_cómo_conectar">12.3.2. 12.3.2 DestinationRule: Cómo conectar</a></li>
<li><a href="#_12_3_3_gateway_punto_de_entrada">12.3.3. 12.3.3 Gateway: Punto de Entrada</a></li>
<li><a href="#_12_3_4_canary_deployments">12.3.4. 12.3.4 Canary Deployments</a></li>
<li><a href="#_12_3_5_ab_testing">12.3.5. 12.3.5 A/B Testing</a></li>
</ul>
</li>
<li><a href="#_12_4_seguridad_en_istio">12.4. 12.4 Seguridad en Istio</a>
<ul class="sectlevel3">
<li><a href="#_12_4_1_mtls_mutual_tls">12.4.1. 12.4.1 mTLS: Mutual TLS</a></li>
<li><a href="#_12_4_2_authorizationpolicy_control_de_acceso">12.4.2. 12.4.2 AuthorizationPolicy: Control de Acceso</a></li>
<li><a href="#_12_4_3_requestauthentication_jwt_validation">12.4.3. 12.4.3 RequestAuthentication: JWT Validation</a></li>
</ul>
</li>
<li><a href="#_12_5_observabilidad">12.5. 12.5 Observabilidad</a>
<ul class="sectlevel3">
<li><a href="#_12_5_1_distributed_tracing">12.5.1. 12.5.1 Distributed Tracing</a></li>
<li><a href="#_12_5_2_metrics_prometheus">12.5.2. 12.5.2 Metrics: Prometheus</a></li>
<li><a href="#_12_5_3_kiali_visualización">12.5.3. 12.5.3 Kiali: Visualización</a></li>
</ul>
</li>
<li><a href="#_12_6_ejemplo_completo_aplicación_con_istio">12.6. 12.6 Ejemplo Completo: Aplicación con Istio</a></li>
<li><a href="#_12_7_best_practices_con_istio">12.7. 12.7 Best Practices con Istio</a></li>
<li><a href="#_12_8_resumen_del_módulo_12">12.8. 12.8 Resumen del Módulo 12</a></li>
</ul>
</li>
<li><a href="#_apéndices">13. Apéndices</a>
<ul class="sectlevel2">
<li><a href="#_a_comandos_de_kubectl_referencia_completa">13.1. A. Comandos de kubectl: Referencia Completa</a>
<ul class="sectlevel3">
<li><a href="#_a_1_comandos_básicos">13.1.1. A.1 Comandos Básicos</a></li>
<li><a href="#_a_2_debugging">13.1.2. A.2 Debugging</a></li>
<li><a href="#_a_3_flags_comunes">13.1.3. A.3 Flags Comunes</a></li>
<li><a href="#_a_4_aliases_útiles">13.1.4. A.4 Aliases Útiles</a></li>
</ul>
</li>
<li><a href="#_b_recursos_yaml_referencia_completa">13.2. B. Recursos YAML: Referencia Completa</a>
<ul class="sectlevel3">
<li><a href="#_b_1_estructura_general">13.2.1. B.1 Estructura General</a></li>
<li><a href="#_b_2_api_versions_comunes">13.2.2. B.2 API Versions Comunes</a></li>
<li><a href="#_b_3_tipos_de_recursos_kinds">13.2.3. B.3 Tipos de Recursos (Kinds)</a></li>
<li><a href="#_b_4_campos_comunes">13.2.4. B.4 Campos Comunes</a></li>
<li><a href="#_b_5_selectores_y_queries">13.2.5. B.5 Selectores y Queries</a></li>
</ul>
</li>
<li><a href="#_c_glosario_términos_clave_de_kubernetes">13.3. C. Glosario: Términos Clave de Kubernetes</a></li>
<li><a href="#_d_referencias_y_recursos">13.4. D. Referencias y Recursos</a>
<ul class="sectlevel3">
<li><a href="#_d_1_documentación_oficial">13.4.1. D.1 Documentación Oficial</a></li>
<li><a href="#_d_2_libros_recomendados">13.4.2. D.2 Libros Recomendados</a></li>
<li><a href="#_d_3_cursos_online">13.4.3. D.3 Cursos Online</a></li>
<li><a href="#_d_4_comunidades">13.4.4. D.4 Comunidades</a></li>
</ul>
</li>
<li><a href="#_e_laboratorios_prácticos">13.5. E. Laboratorios Prácticos</a>
<ul class="sectlevel3">
<li><a href="#_e_1_setup_del_entorno_local">13.5.1. E.1 Setup del Entorno Local</a></li>
<li><a href="#_e_2_laboratorio_1_deploy_simple">13.5.2. E.2 Laboratorio 1: Deploy Simple</a></li>
<li><a href="#_e_3_laboratorio_2_configmap_y_secrets">13.5.3. E.3 Laboratorio 2: ConfigMap y Secrets</a></li>
<li><a href="#_e_4_laboratorio_3_scaling_y_autoescaling">13.5.4. E.4 Laboratorio 3: Scaling y Autoescaling</a></li>
<li><a href="#_e_5_laboratorio_4_networking">13.5.5. E.5 Laboratorio 4: Networking</a></li>
<li><a href="#_e_6_laboratorio_5_persistencia">13.5.6. E.6 Laboratorio 5: Persistencia</a></li>
</ul>
</li>
<li><a href="#_f_examen_de_certificación">13.6. F. Examen de Certificación</a>
<ul class="sectlevel3">
<li><a href="#_f_1_cka_certified_kubernetes_administrator">13.6.1. F.1 CKA: Certified Kubernetes Administrator</a></li>
<li><a href="#_f_2_ckad_certified_kubernetes_application_developer">13.6.2. F.2 CKAD: Certified Kubernetes Application Developer</a></li>
<li><a href="#_f_3_cks_certified_kubernetes_security_specialist">13.6.3. F.3 CKS: Certified Kubernetes Security Specialist</a></li>
<li><a href="#_f_4_estrategia_general_de_preparación">13.6.4. F.4 Estrategia General de Preparación</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_fin_del_curso_kubernetes_completo">14. FIN DEL CURSO: KUBERNETES COMPLETO</a></li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_módulo_1_introducción_a_kubernetes">1. MÓDULO 1: Introducción a Kubernetes</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_1_1_conceptos_fundamentales">1.1. 1.1 Conceptos Fundamentales</h3>
<div class="sect3">
<h4 id="_1_1_1_qué_es_kubernetes">1.1.1. 1.1.1 ¿Qué es Kubernetes?</h4>
<div class="paragraph">
<p>Kubernetes (también conocido como K8s) es un <strong>orquestador de contenedores de código abierto</strong> que automatiza la implementación, escalado y gestión de aplicaciones en contenedores. Fue desarrollado por Google y ahora es mantenido por la Cloud Native Computing Foundation (CNCF).</p>
</div>
<div class="paragraph">
<p><strong>Definición técnica:</strong>
Kubernetes es una plataforma de orquestación que permite:
- <strong>Automatizar el despliegue</strong> de contenedores en múltiples máquinas
- <strong>Escalar aplicaciones</strong> automáticamente según la demanda
- <strong>Gestionar recursos</strong> de forma eficiente
- <strong>Recuperarse de fallos</strong> automáticamente
- <strong>Actualizar aplicaciones</strong> sin downtime</p>
</div>
<div class="paragraph">
<p><strong>¿Por qué Kubernetes?</strong></p>
</div>
<div class="paragraph">
<p>Cuando trabajas con contenedores (Docker), surgen preguntas:
- ¿Cómo despliego múltiples contenedores en varios servidores?
- ¿Qué pasa si un contenedor falla? ¿Se reinicia automáticamente?
- ¿Cómo balancea la carga entre contenedores?
- ¿Cómo actualizo mi aplicación sin cortar el servicio?
- ¿Cómo escalo mi aplicación cuando hay mucha demanda?</p>
</div>
<div class="paragraph">
<p>Kubernetes responde a todas estas preguntas.</p>
</div>
</div>
<div class="sect3">
<h4 id="_1_1_2_comparación_con_docker_swarm">1.1.2. 1.1.2 Comparación con Docker Swarm</h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Característica</th>
<th class="tableblock halign-left valign-top">Kubernetes</th>
<th class="tableblock halign-left valign-top">Docker Swarm</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Complejidad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alta</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Baja</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Curva de aprendizaje</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pronunciada</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Suave</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Escalabilidad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Excelente (miles de nodos)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Buena (hasta 500 nodos)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Adopción empresarial</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dominante</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Baja</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Comunidad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Muy grande</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pequeña</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Herramientas de monitoreo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Amplias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Limitadas</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Networking</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Avanzado</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Básico</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Storage</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Completo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Básico</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uso en producción</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Muy recomendado</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Limitado</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Veredicto:</strong> Kubernetes es la opción estándar para empresas grandes y medianas, mientras que Docker Swarm es más simple pero menos potente.</p>
</div>
</div>
<div class="sect3">
<h4 id="_1_1_3_ventajas_de_kubernetes">1.1.3. 1.1.3 Ventajas de Kubernetes</h4>
<div class="paragraph">
<p><strong>Orquestación Automática:</strong>
- Despliegue y retirada automática de contenedores
- Escalado automático basado en métricas
- Actualización automática con cero downtime</p>
</div>
<div class="paragraph">
<p><strong>Alta Disponibilidad:</strong>
- Reinicio automático de contenedores que fallan
- Replicación de aplicaciones
- Health checks</p>
</div>
<div class="paragraph">
<p><strong>Eficiencia de Recursos:</strong>
- Bin packing (uso óptimo de recursos)
- Escalado automático de nodos
- Límites de recursos por aplicación</p>
</div>
<div class="paragraph">
<p><strong>Portabilidad:</strong>
- Funciona en cualquier nube (AWS, Google Cloud, Azure, etc.)
- Funciona on-premises
- Evita vendor lock-in</p>
</div>
<div class="paragraph">
<p><strong>Ecosistema Maduro:</strong>
- Herramientas de monitoreo (Prometheus, Grafana)
- Service mesh (Istio)
- Ingress controllers
- Package managers (Helm)</p>
</div>
</div>
<div class="sect3">
<h4 id="_1_1_4_desventajas_de_kubernetes">1.1.4. 1.1.4 Desventajas de Kubernetes</h4>
<div class="paragraph">
<p><strong>Complejidad:</strong>
- Curva de aprendizaje empinada
- Muchos conceptos para entender
- Configuración compleja</p>
</div>
<div class="paragraph">
<p><strong>Overhead de Recursos:</strong>
- Requiere recursos para los componentes del control plane
- No es ideal para aplicaciones muy pequeñas</p>
</div>
<div class="paragraph">
<p><strong>Debugging Difícil:</strong>
- Los problemas pueden ser complejos de diagnosticar
- Requiere herramientas especializadas</p>
</div>
<div class="paragraph">
<p><strong>Costo:</strong>
- Puede ser caro en infraestructura
- Requiere expertise en DevOps</p>
</div>
</div>
<div class="sect3">
<h4 id="_1_1_5_casos_de_uso_reales">1.1.5. 1.1.5 Casos de Uso Reales</h4>
<div class="paragraph">
<p><strong>Microservicios:</strong>
Kubernetes brilla cuando tienes múltiples servicios que necesitan comunicarse entre sí.</p>
</div>
<div class="paragraph">
<p><strong>Aplicaciones Web a Escala:</strong>
Si tu aplicación recibe tráfico variable, Kubernetes escala automáticamente.</p>
</div>
<div class="paragraph">
<p><strong>Machine Learning:</strong>
Distribuir trabajos de entrenamiento en múltiples GPUs.</p>
</div>
<div class="paragraph">
<p><strong>Procesamiento de Datos:</strong>
Ejecutar trabajos de batch distribuidos con Spark, Hadoop, etc.</p>
</div>
<div class="paragraph">
<p><strong>CI/CD Pipelines:</strong>
Ejecutar builds y tests en contenedores gestionados por Kubernetes.</p>
</div>
</div>
<div class="sect3">
<h4 id="_1_1_6_arquitectura_general_de_kubernetes">1.1.6. 1.1.6 Arquitectura General de Kubernetes</h4>
<div class="paragraph">
<p>[source,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>                    ┌─────────────────────────────────────┐
                    │     KUBERNETES CLUSTER              │
                    │                                     │
    ┌───────────────┤  CONTROL PLANE (Master)            │
    │               │  ├─ API Server                      │
    │               │  ├─ Scheduler                       │
    │               │  ├─ Controller Manager              │
    │               │  └─ etcd                            │
    │               └─────────────────────────────────────┘
    │
    │  ┌──────────────────────────────────────────────────┐
    │  │  NODO WORKER 1                                   │
    │  │  ├─ Kubelet                                      │
    │  │  ├─ kube-proxy                                   │
    │  │  └─ Contenedores                                │
    │  │     ├─ Pod 1 (App Container)                    │
    │  │     └─ Pod 2 (App Container)                    │
    │  └──────────────────────────────────────────────────┘
    │
    └──┬──────────────────────────────────────────────────┐
       │  NODO WORKER 2                                   │
       │  ├─ Kubelet                                      │
       │  ├─ kube-proxy                                   │
       │  └─ Contenedores                                │
       │     ├─ Pod 3 (App Container)                    │
       │     └─ Pod 4 (App Container)                    │
       └──────────────────────────────────────────────────┘</pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p>La arquitectura sigue un modelo <strong>Master-Worker (Master-Slave)</strong>:
- El <strong>Control Plane</strong> es el "cerebro" que toma decisiones
- Los <strong>Worker Nodes</strong> ejecutan las aplicaciones reales</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_1_2_componentes_de_la_arquitectura">1.2. 1.2 Componentes de la Arquitectura</h3>
<div class="sect3">
<h4 id="_1_2_1_control_plane_nodo_maestro">1.2.1. 1.2.1 Control Plane (Nodo Maestro)</h4>
<div class="paragraph">
<p>El Control Plane es el corazón de Kubernetes. Gestiona el estado del cluster y toma todas las decisiones importantes.</p>
</div>
<div class="sect4">
<h5 id="_api_server">API Server</h5>
<div class="paragraph">
<p><strong>¿Qué es?</strong>
El API Server es el punto central de comunicación de Kubernetes. Es un servicio REST que expone la API de Kubernetes.</p>
</div>
<div class="paragraph">
<p><strong>Funciones principales:</strong>
- Recibe solicitudes HTTP/REST de kubectl y otras herramientas
- Valida las solicitudes
- Persiste los cambios en etcd
- Transmite cambios a otros componentes</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo de comunicación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Cuando ejecutas esto:
kubectl create deployment nginx --image=nginx

# Lo que sucede internamente:
1. kubectl envía una solicitud HTTP POST al API Server
2. API Server valida la solicitud
3. Crea un recurso Deployment en etcd
4. El Controller Manager detecta el cambio
5. El Scheduler asigna Pods a nodos
6. Kubelet en los nodos ejecuta los contenedores</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_etcd_almacén_de_datos">etcd (Almacén de Datos)</h5>
<div class="paragraph">
<p><strong>¿Qué es?</strong>
etcd es una base de datos clave-valor distribuida que almacena <strong>TODO el estado del cluster</strong>.</p>
</div>
<div class="paragraph">
<p><strong>Características:</strong>
- Almacenamiento confiable de datos críticos
- Consistencia fuerte
- Replicación automática
- Backup y recuperación</p>
</div>
<div class="paragraph">
<p><strong>¿Qué se almacena en etcd?</strong>
- Definiciones de Pods, Deployments, Servicios
- Configuraciones (ConfigMaps, Secrets)
- Estado del cluster
- Información de nodos</p>
</div>
<div class="paragraph">
<p><strong>Advertencia Crítica:</strong>
Si pierdes etcd, pierdes TODO tu cluster. Por eso se recomienda:
- Hacer backups regulares de etcd
- Usar múltiples réplicas de etcd para HA
- Encriptar etcd en reposo</p>
</div>
</div>
<div class="sect4">
<h5 id="_scheduler">Scheduler</h5>
<div class="paragraph">
<p><strong>¿Qué es?</strong>
El Scheduler es responsable de asignar Pods a nodos.</p>
</div>
<div class="paragraph">
<p><strong>¿Cómo funciona?</strong>
[source,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>1. Un Pod es creado (pero sin nodo asignado)
2. El Scheduler observa los Pods sin asignación
3. Evalúa cada nodo disponible
4. Elige el mejor nodo basado en:
   - Recursos disponibles (CPU, memoria)
   - Labels y tolerancias
   - Afinidad de Pods
   - Políticas de distribución
5. Asigna el Pod al nodo elegido</pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Algoritmo simplificado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># El Scheduler pregunta:
- ¿Este nodo tiene suficiente CPU y memoria?
- ¿Este nodo tiene los labels requeridos?
- ¿Este Pod tiene alguna afinidad/anti-afinidad con otros Pods?
- ¿Está este nodo tainted (marcado como no disponible)?
- ¿Cómo está la distribución actual de Pods en nodos?</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_controller_manager">Controller Manager</h5>
<div class="paragraph">
<p><strong>¿Qué es?</strong>
El Controller Manager es un componente que ejecuta múltiples "controladores" que vigilan el estado del cluster.</p>
</div>
<div class="paragraph">
<p><strong>¿Qué es un Controlador?</strong>
Un controlador es un bucle infinito que:
1. Observa el estado actual
2. Compara con el estado deseado
3. Toma acciones para que coincidan</p>
</div>
<div class="paragraph">
<p><strong>Ejemplos de Controladores:</strong>
- <strong>Deployment Controller</strong>: Si deseas 3 replicas pero solo hay 2, crea otro Pod
- <strong>Node Controller</strong>: Si un nodo falla, marca sus Pods como fallidos
- <strong>Service Controller</strong>: Mantiene sincronizados los endpoints con los Pods
- <strong>StatefulSet Controller</strong>: Gestiona Pods con identidad estable
- <strong>Job Controller</strong>: Ejecuta trabajos hasta completarse</p>
</div>
<div class="paragraph">
<p><strong>Analogía:</strong>
Es como un termostato:
- Temperatura deseada (estado deseado) = 22°C
- Temperatura actual (estado actual) = 18°C
- El termostato enciende la calefacción (toma acción)
- Repite el ciclo constantemente</p>
</div>
<hr>
</div>
</div>
<div class="sect3">
<h4 id="_1_2_2_nodos_worker">1.2.2. 1.2.2 Nodos Worker</h4>
<div class="paragraph">
<p>Los Nodos Worker son máquinas (físicas o virtuales) que ejecutan tus aplicaciones.</p>
</div>
<div class="sect4">
<h5 id="_kubelet">Kubelet</h5>
<div class="paragraph">
<p><strong>¿Qué es?</strong>
Kubelet es el agente que corre en cada nodo worker. Es responsable de ejecutar los Pods.</p>
</div>
<div class="paragraph">
<p><strong>Funciones:</strong>
- Recibe especificaciones de Pods del API Server
- Descarga las imágenes de contenedores
- Inicia contenedores usando el container runtime
- Monitorea la salud de los Pods
- Realiza health checks (readiness, liveness)
- Reporta el estado del nodo y sus Pods al API Server</p>
</div>
<div class="paragraph">
<p><strong>Flujo de vida de un Pod:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">1. Scheduler asigna el Pod a este nodo
2. Kubelet observa que hay un Pod asignado
3. Kubelet descarga la imagen del contenedor
4. Kubelet inicia el contenedor
5. Kubelet ejecuta health checks
6. Si el contenedor falla, Kubelet lo reinicia (según política)
7. Kubelet reporta eventos al API Server</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_container_runtime">Container Runtime</h5>
<div class="paragraph">
<p><strong>¿Qué es?</strong>
El Container Runtime es el software que ejecuta los contenedores. Ejemplos:
- <strong>Docker</strong> (el más común históricamente)
- <strong>containerd</strong> (cada vez más común)
- <strong>CRI-O</strong> (usado en OpenShift)
- <strong>runc</strong> (runtime de bajo nivel)</p>
</div>
<div class="paragraph">
<p><strong>¿Por qué importa?</strong>
Kubernetes puede trabajar con diferentes runtimes. El Kubelet se comunica con el runtime a través de la <strong>CRI (Container Runtime Interface)</strong>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_kube_proxy">kube-proxy</h5>
<div class="paragraph">
<p><strong>¿Qué es?</strong>
kube-proxy es un componente de networking que:
- Mantiene reglas de red en cada nodo
- Implementa Servicios de Kubernetes
- Realiza balanceo de carga local</p>
</div>
<div class="paragraph">
<p><strong>¿Cómo funciona?</strong>
[source,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Cliente → kube-proxy en Nodo A → iptables/rules de red →
  → Pods en Nodo A/B/C (balanceado)</pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p>kube-proxy usa una de estas implementaciones:
- <strong>iptables mode</strong> (por defecto): Rápido pero puede ser inestable con muchos Servicios
- <strong>ipvs mode</strong>: Más escalable que iptables</p>
</div>
<hr>
</div>
</div>
<div class="sect3">
<h4 id="_1_2_3_componentes_adicionales">1.2.3. 1.2.3 Componentes Adicionales</h4>
<div class="sect4">
<h5 id="_dns_coredns">DNS (CoreDNS)</h5>
<div class="paragraph">
<p><strong>¿Qué es?</strong>
CoreDNS es el servidor DNS de Kubernetes. Proporciona resolución de nombres para Servicios y Pods.</p>
</div>
<div class="paragraph">
<p><strong>Ejemplos de nombres DNS:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Servicio en el mismo namespace
nginx-service

# Servicio en otro namespace
nginx-service.production

# FQDN completo
nginx-service.production.svc.cluster.local

# Pod individual
10-244-1-5.default.pod.cluster.local</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_sistema_de_logging">Sistema de Logging</h5>
<div class="paragraph">
<p><strong>¿Qué es?</strong>
Kubernetes genera muchos logs:
- Logs de contenedores (stdout/stderr)
- Logs del API Server
- Logs del Scheduler
- Logs del Kubelet</p>
</div>
<div class="paragraph">
<p><strong>¿Cómo se recopilan?</strong>
Generalmente con herramientas como:
- <strong>ELK Stack</strong> (Elasticsearch, Logstash, Kibana)
- <strong>Fluentd o Fluent Bit</strong>
- <strong>Loki</strong> (de Grafana Labs)
- <strong>Splunk, Datadog, etc.</strong></p>
</div>
</div>
<div class="sect4">
<h5 id="_monitoring">Monitoring</h5>
<div class="paragraph">
<p><strong>¿Qué es?</strong>
Monitoreo de:
- Métricas de recursos (CPU, memoria, disco)
- Métricas de aplicación
- Eventos del cluster</p>
</div>
<div class="paragraph">
<p><strong>Herramientas:</strong>
- <strong>Metrics Server</strong>: Proporciona métricas básicas
- <strong>Prometheus</strong>: Scraping de métricas (estándar de facto)
- <strong>Grafana</strong>: Visualización de métricas</p>
</div>
<hr>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_1_3_instalación_y_configuración">1.3. 1.3 Instalación y Configuración</h3>
<div class="sect3">
<h4 id="_1_3_1_instalación_de_kubectl">1.3.1. 1.3.1 Instalación de kubectl</h4>
<div class="paragraph">
<p>kubectl es la herramienta de línea de comandos para interactuar con Kubernetes.</p>
</div>
<div class="paragraph">
<p><strong>En Linux:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Descargar kubectl
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"

# Hacer ejecutable
chmod +x kubectl

# Mover a PATH
sudo mv kubectl /usr/local/bin/

# Verificar instalación
kubectl version --client</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Con Homebrew (macOS):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">brew install kubectl
kubectl version --client</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Con Chocolatey (Windows):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-powershell" data-lang="powershell">choco install kubernetes-cli
kubectl version --client</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_1_3_2_instalación_de_docker">1.3.2. 1.3.2 Instalación de Docker</h4>
<div class="paragraph">
<p>Docker es necesario para crear imágenes de contenedores.</p>
</div>
<div class="paragraph">
<p><strong>En Ubuntu/Debian:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Actualizar repos
sudo apt-get update

# Instalar dependencias
sudo apt-get install -y \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg \
    lsb-release

# Agregar clave GPG de Docker
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# Agregar repositorio
echo \
  "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null

# Instalar Docker
sudo apt-get update
sudo apt-get install -y docker-ce docker-ce-cli containerd.io

# Permitir usar Docker sin sudo
sudo usermod -aG docker $USER
newgrp docker

# Verificar
docker run hello-world</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_1_3_3_opciones_de_instalación_de_kubernetes">1.3.3. 1.3.3 Opciones de Instalación de Kubernetes</h4>
<div class="sect4">
<h5 id="_minikube_desarrollo_local">Minikube (Desarrollo Local)</h5>
<div class="paragraph">
<p><strong>¿Qué es?</strong>
Minikube es una herramienta que crea un cluster Kubernetes pequeño en tu máquina local. Perfecto para desarrollo.</p>
</div>
<div class="paragraph">
<p><strong>Ventajas:</strong>
- Fácil de instalar y usar
- Rápido para experimentar
- Incluye un cluster completo (aunque pequeño)</p>
</div>
<div class="paragraph">
<p><strong>Desventajas:</strong>
- Un único nodo
- Limitado en recursos
- No es para producción</p>
</div>
<div class="paragraph">
<p><strong>Instalación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># En macOS
brew install minikube

# En Linux
curl -LO https://github.com/kubernetes/minikube/releases/latest/download/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube

# En Windows
choco install minikube</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Uso:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Iniciar el cluster
minikube start

# Ver el estado
minikube status

# Detener el cluster
minikube stop

# Eliminar el cluster
minikube delete

# Ver IP del cluster
minikube ip

# Acceder al dashboard
minikube dashboard</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_kubeadm">kubeadm</h5>
<div class="paragraph">
<p><strong>¿Qué es?</strong>
kubeadm es una herramienta para crear clusters Kubernetes de forma manual. Más control pero más complejidad.</p>
</div>
<div class="paragraph">
<p><strong>Instalación del master:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalación de dependencias
sudo apt-get update &amp;&amp; sudo apt-get install -y apt-transport-https ca-certificates curl

# Agregar repo de Kubernetes
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list

# Instalar kubeadm, kubelet y kubectl
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl

# Inicializar el master
sudo kubeadm init --pod-network-cidr=10.244.0.0/16

# Copiar kubeconfig
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# Instalar CNI (red)
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_kubernetes_en_la_nube">Kubernetes en la Nube</h5>
<div class="paragraph">
<p><strong>Amazon EKS (Elastic Kubernetes Service):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalar AWS CLI y eksctl
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install

# Crear cluster
eksctl create cluster --name my-cluster --region us-east-1

# Conectarse
aws eks update-kubeconfig --name my-cluster --region us-east-1</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Google GKE (Google Kubernetes Engine):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalar Google Cloud SDK
curl https://sdk.cloud.google.com | bash

# Crear cluster
gcloud container clusters create my-cluster --zone us-central1-a

# Conectarse
gcloud container clusters get-credentials my-cluster --zone us-central1-a</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Azure AKS (Azure Kubernetes Service):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalar Azure CLI
curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

# Crear grupo de recursos
az group create --name myResourceGroup --location eastus

# Crear cluster
az aks create --resource-group myResourceGroup --name myAKSCluster --node-count 2

# Conectarse
az aks get-credentials --resource-group myResourceGroup --name myAKSCluster</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_1_3_4_configuración_de_kubectl">1.3.4. 1.3.4 Configuración de kubectl</h4>
<div class="paragraph">
<p>kubectl se configura con un archivo <code>kubeconfig</code> que contiene conexiones a clusters.</p>
</div>
<div class="paragraph">
<p><strong>Ubicación por defecto:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">~/.kube/config</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Estructura del archivo kubeconfig:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Config
clusters:
  - cluster:
      certificate-authority: /path/to/ca.crt
      server: https://kubernetes.example.com:6443
    name: kubernetes-cluster
contexts:
  - context:
      cluster: kubernetes-cluster
      user: admin
    name: kubernetes-admin
current-context: kubernetes-admin
users:
  - name: admin
    user:
      client-certificate: /path/to/admin.crt
      client-key: /path/to/admin.key</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Comandos útiles:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver configuración actual
kubectl config view

# Ver contexto actual
kubectl config current-context

# Listar contextos disponibles
kubectl config get-contexts

# Cambiar de contexto
kubectl config use-context kubernetes-admin

# Agregar nuevo cluster
kubectl config set-cluster my-cluster --server=https://my-cluster:6443

# Agregar nuevo usuario
kubectl config set-credentials my-user --client-certificate=path/to/cert</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_1_3_5_verificación_de_la_instalación">1.3.5. 1.3.5 Verificación de la Instalación</h4>
<div class="paragraph">
<p><strong>Verificar que Kubernetes está funcionando:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Verificar versión
kubectl version

# Ver nodos disponibles
kubectl get nodes

# Ver servicios del sistema
kubectl get services --namespace kube-system

# Ver pods del sistema
kubectl get pods --namespace kube-system

# Descripción detallada del cluster
kubectl cluster-info

# Ver logs del cluster
kubectl cluster-info dump --output-directory=/tmp/cluster-dump</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo de salida esperada:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ kubectl version
Client Version: version.Info{Major:"1", Minor:"27"...}
Server Version: version.Info{Major:"1", Minor:"27"...}

$ kubectl get nodes
NAME       STATUS   ROLES           AGE   VERSION
minikube   Ready    control-plane   10m   v1.27.0

$ kubectl get pods --namespace kube-system
NAME                               READY   STATUS    RESTARTS   AGE
coredns-64897fb6d9-qr5v6          1/1     Running   0          10m
etcd-minikube                      1/1     Running   0          10m
kube-apiserver-minikube            1/1     Running   0          10m
kube-controller-manager-minikube   1/1     Running   0          10m</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_1_4_mi_primer_cluster">1.4. 1.4 Mi Primer Cluster</h3>
<div class="sect3">
<h4 id="_1_4_1_crear_un_cluster_local_con_minikube">1.4.1. 1.4.1 Crear un Cluster Local con Minikube</h4>
<div class="paragraph">
<p><strong>Paso 1: Iniciar Minikube</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Iniciar con configuración recomendada
minikube start --cpus 4 --memory 4096

# O con más recursos
minikube start --cpus 8 --memory 8192 --disk-size 50gb</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Paso 2: Esperar a que esté listo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver el estado
minikube status

# Espera a ver:
# minikube: Running
# kubectl.io: Running</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_1_4_2_conectarse_al_cluster">1.4.2. 1.4.2 Conectarse al Cluster</h4>
<div class="paragraph">
<p><strong>kubectl ya está configurado automáticamente:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Verificar conexión
kubectl cluster-info

# Debe mostrar:
# Kubernetes master is running at https://192.168.59.100:8443
# CoreDNS is running at https://192.168.59.100:8443/api/v1/namespaces/kube-system/services/kube-dns/proxy</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_1_4_3_explorar_el_cluster">1.4.3. 1.4.3 Explorar el Cluster</h4>
<div class="paragraph">
<p><strong>Ver nodos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">kubectl get nodes

# Salida:
# NAME       STATUS   ROLES           AGE   VERSION
# minikube   Ready    control-plane   2m    v1.27.0</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ver pods del sistema:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">kubectl get pods --namespace kube-system

# Salida mostrará los componentes de Kubernetes</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Crear tu primer Pod:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear un Deployment simple
kubectl create deployment hello-world --image=nginx:latest

# Ver el Deployment
kubectl get deployments

# Ver los Pods creados
kubectl get pods

# Ver descripción detallada
kubectl describe pod &lt;pod-name&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Acceder a tu aplicación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Port forward al Pod
kubectl port-forward pod/hello-world-xxxxx 8080:80

# Ahora accede en tu navegador a http://localhost:8080</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ver logs:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">kubectl logs &lt;pod-name&gt;

# Seguir logs en vivo
kubectl logs -f &lt;pod-name&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_1_4_4_eliminar_el_cluster">1.4.4. 1.4.4 Eliminar el Cluster</h4>
<div class="paragraph">
<p><strong>Detener Minikube:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Solo detener (los datos se mantienen)
minikube stop

# Completamente eliminar
minikube delete

# Borrar todo incluyendo configuraciones
minikube delete --all</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_1_5_ejercicios_prácticos">1.5. 1.5 Ejercicios Prácticos</h3>
<div class="sect3">
<h4 id="_ejercicio_1_desplegar_tu_primera_aplicación">1.5.1. Ejercicio 1: Desplegar tu Primera Aplicación</h4>
<div class="paragraph">
<p><strong>Objetivo:</strong> Crear y ejecutar un Deployment simple</p>
</div>
<div class="paragraph">
<p><strong>YAML - deployment-nginx.yaml:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  namespace: default
  labels:
    app: nginx
    version: v1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21
        ports:
        - containerPort: 80
          name: http
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "500m"
            memory: "512Mi"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Comandos para ejecutar:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Aplicar el YAML
kubectl apply -f deployment-nginx.yaml

# Ver el Deployment
kubectl get deployments

# Ver los Pods
kubectl get pods

# Ver detalles
kubectl describe deployment nginx-deployment

# Ver eventos
kubectl get events

# Eliminar el Deployment
kubectl delete deployment nginx-deployment</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejercicio_2_exponer_tu_aplicación">1.5.2. Ejercicio 2: Exponer tu Aplicación</h4>
<div class="paragraph">
<p><strong>Objetivo:</strong> Crear un Servicio para acceder a la aplicación</p>
</div>
<div class="paragraph">
<p><strong>YAML - service-nginx.yaml:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: nginx-service
  namespace: default
  labels:
    app: nginx
spec:
  type: ClusterIP
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    name: http</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Comandos para ejecutar:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Aplicar el Servicio
kubectl apply -f service-nginx.yaml

# Ver servicios
kubectl get services

# Obtener IP del Servicio
kubectl get svc nginx-service

# Describir el Servicio
kubectl describe service nginx-service

# Acceder al servicio (desde dentro del cluster)
kubectl run -it --rm debug --image=busybox --restart=Never -- wget -O- http://nginx-service</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejercicio_3_escalar_tu_aplicación">1.5.3. Ejercicio 3: Escalar tu Aplicación</h4>
<div class="paragraph">
<p><strong>Objetivo:</strong> Cambiar el número de replicas</p>
</div>
<div class="paragraph">
<p><strong>Comando directo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Escalar a 5 replicas
kubectl scale deployment nginx-deployment --replicas=5

# Ver los nuevos Pods
kubectl get pods

# Escalar de nuevo a 2
kubectl scale deployment nginx-deployment --replicas=2</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Usando YAML:</strong>
Modificar el archivo <code>deployment-nginx.yaml</code> y cambiar <code>replicas: 3</code> a <code>replicas: 5</code>, luego:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">kubectl apply -f deployment-nginx.yaml

# Ver cambios
kubectl get pods</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejercicio_4_actualizar_tu_aplicación">1.5.4. Ejercicio 4: Actualizar tu Aplicación</h4>
<div class="paragraph">
<p><strong>Objetivo:</strong> Cambiar la versión de nginx</p>
</div>
<div class="paragraph">
<p><strong>YAML actualizado - deployment-nginx-v2.yaml:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  namespace: default
  labels:
    app: nginx
    version: v2
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.22  # Versión actualizada
        ports:
        - containerPort: 80
          name: http
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "500m"
            memory: "512Mi"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Comandos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Aplicar la actualización
kubectl apply -f deployment-nginx-v2.yaml

# Ver el progreso del update
kubectl rollout status deployment/nginx-deployment

# Ver el historial de rollouts
kubectl rollout history deployment/nginx-deployment

# Si algo sale mal, revertir a la versión anterior
kubectl rollout undo deployment/nginx-deployment

# Ver nuevamente
kubectl rollout status deployment/nginx-deployment</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejercicio_5_monitoreo_básico">1.5.5. Ejercicio 5: Monitoreo Básico</h4>
<div class="paragraph">
<p><strong>Objetivo:</strong> Observar recursos y eventos</p>
</div>
<div class="paragraph">
<p><strong>Comandos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver uso de recursos en nodos
kubectl top nodes

# Ver uso de recursos en Pods
kubectl top pods

# Monitorear cambios en tiempo real
kubectl get pods --watch

# Ver eventos del cluster
kubectl get events --sort-by='.lastTimestamp'

# Ver eventos de un pod específico
kubectl describe pod &lt;pod-name&gt;

# Ver logs de un contenedor
kubectl logs &lt;pod-name&gt;

# Seguir logs en vivo
kubectl logs -f &lt;pod-name&gt;

# Ver logs de múltiples Pods
kubectl logs -l app=nginx

# Ver logs del pod anterior (si fue reiniciado)
kubectl logs &lt;pod-name&gt; --previous</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_1_6_solución_de_problemas_iniciales">1.6. 1.6 Solución de Problemas Iniciales</h3>
<div class="sect3">
<h4 id="_problema_the_connection_to_the_server_was_refused">1.6.1. Problema: "The connection to the server was refused"</h4>
<div class="paragraph">
<p><strong>Causa:</strong> Kubernetes no está corriendo o no hay conexión</p>
</div>
<div class="paragraph">
<p><strong>Solución:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Verificar si Minikube está corriendo
minikube status

# Si no está corriendo, iniciar
minikube start

# Verificar kubeconfig
kubectl config view

# Intentar conectarse
kubectl cluster-info</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_problema_pods_en_estado_pending">1.6.2. Problema: Pods en estado Pending</h4>
<div class="paragraph">
<p><strong>Causa:</strong> El Pod no puede ser programado (recursos insuficientes, nodo no disponible)</p>
</div>
<div class="paragraph">
<p><strong>Solución:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Describir el Pod
kubectl describe pod &lt;pod-name&gt;

# Ver eventos del cluster
kubectl get events

# Verificar recursos disponibles
kubectl top nodes

# Si es Minikube, aumentar recursos
minikube stop
minikube start --cpus 8 --memory 8192</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_problema_pod_en_estado_crashloopbackoff">1.6.3. Problema: Pod en estado CrashLoopBackOff</h4>
<div class="paragraph">
<p><strong>Causa:</strong> El contenedor está fallando al iniciar</p>
</div>
<div class="paragraph">
<p><strong>Solución:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver logs del Pod
kubectl logs &lt;pod-name&gt;

# Ver logs del pod anterior
kubectl logs &lt;pod-name&gt; --previous

# Describir el Pod
kubectl describe pod &lt;pod-name&gt;

# Revisar que la imagen exista
kubectl describe pod &lt;pod-name&gt; | grep Image

# Si es error de imagen, ver los eventos
kubectl get events --sort-by='.lastTimestamp'</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_problema_no_puedo_acceder_a_mi_aplicación">1.6.4. Problema: No puedo acceder a mi aplicación</h4>
<div class="paragraph">
<p><strong>Causa:</strong> El Servicio no está configurado correctamente o el Port Forward falla</p>
</div>
<div class="paragraph">
<p><strong>Solución:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Verificar que el Pod está corriendo
kubectl get pods

# Verificar que el Servicio existe
kubectl get services

# Describir el Servicio
kubectl describe service &lt;service-name&gt;

# Ver endpoints del Servicio
kubectl get endpoints

# Intentar conectarse desde dentro del cluster
kubectl run -it --rm debug --image=busybox --restart=Never -- /bin/sh

# Dentro del Pod de debug:
wget -O- http://service-name:port</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_1_7_resumen_del_módulo_1">1.7. 1.7 Resumen del Módulo 1</h3>
<div class="paragraph">
<p>En este módulo aprendiste:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Conceptos Fundamentales</strong>: Qué es Kubernetes, sus ventajas, desventajas y casos de uso</p>
</li>
<li>
<p><strong>Arquitectura</strong>: Control Plane y Worker Nodes con todos sus componentes</p>
</li>
<li>
<p><strong>Instalación</strong>: Cómo instalar Kubernetes localmente con Minikube</p>
</li>
<li>
<p><strong>Configuración</strong>: Cómo configurar kubectl para interactuar con el cluster</p>
</li>
<li>
<p><strong>Primeros pasos</strong>: Crear Deployments, Servicios, escalar y actualizar aplicaciones</p>
</li>
<li>
<p><strong>Troubleshooting</strong>: Resolver problemas comunes</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Con estos conocimientos, estás listo para profundizar en Pods y Deployments en el Módulo 2.</p>
</div>
<hr>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_2_pods_y_contenedores">2. MÓDULO 2: Pods y Contenedores</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_2_1_pods_basics">2.1. 2.1 Pods Basics</h3>
<div class="sect3">
<h4 id="_2_1_1_concepto_de_pod">2.1.1. 2.1.1 Concepto de Pod</h4>
<div class="paragraph">
<p><strong>¿Qué es un Pod?</strong></p>
</div>
<div class="paragraph">
<p>Un Pod es la <strong>unidad mínima desplegable en Kubernetes</strong>. Es un contenedor (o conjunto de contenedores estrechamente acoplados) que comparte recursos de red y almacenamiento.</p>
</div>
<div class="paragraph">
<p><strong>Analogía:</strong>
Si Docker es como un contenedor de envío (contiene tu aplicación), Kubernetes no es el contenedor sino la grúa que lo maneja. Y un Pod es como un pequeño paquete dentro del contenedor que puede contener una o varias cajas (contenedores).</p>
</div>
<div class="paragraph">
<p><strong>Características importantes:</strong>
- Un Pod puede contener 1 o más contenedores
- Los contenedores en un Pod comparten la interfaz de red (misma IP)
- Los contenedores en un Pod pueden compartir almacenamiento (volúmenes)
- Los Pods son <strong>efímeros</strong> (temporales, pueden ser eliminados en cualquier momento)
- Los Pods son típicamente creados por Controladores (Deployments, StatefulSets, etc.)</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo visual:</strong>
[source,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>┌─────────────────────────────────────┐
│         POD                         │
│                                     │
│  ┌──────────────┐  ┌──────────────┐│
│  │  Container 1 │  │  Container 2 ││
│  │  (nginx)     │  │  (logging)   ││
│  │  Puerto 80   │  │  Sidecar     ││
│  └──────────────┘  └──────────────┘│
│                                     │
│  Compartidos:                       │
│  - IP: 10.244.1.5                   │
│  - Filesystem (volúmenes)           │
│  - IPC namespace                    │
│  - Network namespace                │
└─────────────────────────────────────┘</pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_1_2_pod_vs_contenedor">2.1.2. 2.1.2 Pod vs Contenedor</h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Aspecto</th>
<th class="tableblock halign-left valign-top">Contenedor (Docker)</th>
<th class="tableblock halign-left valign-top">Pod (Kubernetes)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Unidad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Empaquetado de aplicación</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Unidad de despliegue en K8s</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cantidad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 contenedor por contenedor</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1+ contenedores por Pod</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Red</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Red propia isolada</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Red compartida dentro del Pod</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ciclo de vida</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Independiente</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Gestionado por K8s</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reemplazo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reemplazable</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Efímero</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Escalado</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Manual</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Automático (via Deployments)</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_2_1_3_ciclo_de_vida_del_pod">2.1.3. 2.1.3 Ciclo de Vida del Pod</h4>
<div class="paragraph">
<p>Un Pod pasa por varios estados desde su creación hasta su eliminación:</p>
</div>
<div class="paragraph">
<p>[source,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Pending → Running → Succeeded/Failed → Terminating → Terminated</pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Estado: Pending</strong>
- El Pod ha sido aceptado por Kubernetes
- Pero los contenedores aún no han sido iniciados
- Puede estar esperando recursos, descargas de imágenes, etc.</p>
</div>
<div class="paragraph">
<p><strong>Estado: Running</strong>
- Al menos un contenedor está en ejecución
- El Pod está completamente operacional
- Puede manejar tráfico</p>
</div>
<div class="paragraph">
<p><strong>Estado: Succeeded</strong>
- Todos los contenedores han completado exitosamente
- No se reinician
- Típico en Jobs</p>
</div>
<div class="paragraph">
<p><strong>Estado: Failed</strong>
- Al menos un contenedor falló
- El Pod no se reinicia automáticamente
- El controlador (Deployment) puede crear un nuevo Pod</p>
</div>
<div class="paragraph">
<p><strong>Estado: Terminating</strong>
- El Pod está siendo eliminado
- Grace period: espera a que se limpien los recursos (por defecto 30 segundos)
- Después se termina forzosamente</p>
</div>
<div class="paragraph">
<p><strong>Diagrama de estados:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">Pod Lifecycle:

1. CREATE
   ├─ Pod objeto creado
   ├─ Guardado en etcd
   └─ Scheduler lo observa

2. SCHEDULING
   ├─ Scheduler selecciona un nodo
   ├─ Pod asignado al nodo
   └─ Kubelet en el nodo lo observa

3. CONTAINER SETUP
   ├─ Pull imagen del contenedor
   ├─ Crear volúmenes
   ├─ Montar volúmenes
   └─ Iniciar contenedor

4. RUNNING
   ├─ Health checks activos
   ├─ Tráfico acepto
   └─ Esperando órdenes

5. TERMINATION
   ├─ Grace period (30s por defecto)
   ├─ SIGTERM a contenedores
   ├─ Kill si no terminan
   └─ Limpieza</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_1_4_tipos_de_contenedores_en_un_pod">2.1.4. 2.1.4 Tipos de Contenedores en un Pod</h4>
<div class="sect4">
<h5 id="_contenedor_principal_application_container">Contenedor Principal (Application Container)</h5>
<div class="paragraph">
<p>Es el contenedor que ejecuta tu aplicación. <strong>Debe estar presente</strong>.</p>
</div>
<div class="paragraph">
<p><strong>Características:</strong>
- Ejecuta el proceso principal
- Si falla, el Pod falla (generalmente)
- Es lo que típicamente desplegarás</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">containers:
- name: web-app
  image: my-app:1.0
  ports:
  - containerPort: 8080</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_sidecar_containers">Sidecar Containers</h5>
<div class="paragraph">
<p>Contenedores adicionales que <strong>apoyan al contenedor principal</strong> pero no son la aplicación en sí.</p>
</div>
<div class="paragraph">
<p><strong>Casos de uso comunes:</strong>
- <strong>Logging</strong>: Recolectar logs del contenedor principal
- <strong>Monitoring</strong>: Ejecutar agentes de monitoreo
- <strong>Networking</strong>: Proxies, VPNs
- <strong>Seguridad</strong>: Firewalls, encriptación</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo de Sidecar de Logging:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">containers:
- name: web-app
  image: nginx:latest
  # Contenedor principal

- name: log-shipper
  image: fluent-bit:latest
  # Sidecar que envía logs a un servicio central</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ventajas de Sidecars:</strong>
- Separación de responsabilidades
- Reutilizable en múltiples Pods
- No necesita cambiar la imagen principal</p>
</div>
</div>
<div class="sect4">
<h5 id="_init_containers">Init Containers</h5>
<div class="paragraph">
<p>Contenedores que <strong>se ejecutan antes</strong> que los contenedores principales.</p>
</div>
<div class="paragraph">
<p><strong>Características:</strong>
- Se ejecutan secuencialmente (uno por uno)
- Deben completar exitosamente (exit code 0)
- Se usan para setup inicial
- No continúan ejecutándose después del Pod listo</p>
</div>
<div class="paragraph">
<p><strong>Casos de uso:</strong>
- Descargar archivos de configuración
- Esperar a que otros servicios estén listos
- Realizar migraciones de base de datos
- Inicializar datos</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">initContainers:
- name: wait-for-db
  image: busybox:latest
  command: ['sh', '-c', 'until nslookup postgres; do echo waiting for postgres; sleep 2; done']

- name: db-migration
  image: my-app:1.0
  command: ['./migrate.sh']

containers:
- name: web-app
  image: my-app:1.0
  # Solo se ejecuta después de que init containers completen</code></pre>
</div>
</div>
<hr>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_2_creación_de_pods">2.2. 2.2 Creación de Pods</h3>
<div class="sect3">
<h4 id="_2_2_1_yaml_para_pods">2.2.1. 2.2.1 YAML para Pods</h4>
<div class="paragraph">
<p>Un Pod se define en YAML con una estructura específica. Veamos la estructura completa:</p>
</div>
<div class="paragraph">
<p><strong>Estructura Mínima:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1                    # Versión de API de Kubernetes
kind: Pod                         # Tipo de objeto (Pod)
metadata:
  name: my-pod                    # Nombre único del Pod
spec:
  containers:
  - name: app                     # Nombre del contenedor
    image: nginx:latest           # Imagen del contenedor</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Estructura Completa con Todas las Opciones:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: complete-pod
  namespace: default              # Namespace donde reside el Pod
  labels:                          # Labels para seleccionar el Pod
    app: myapp
    environment: production
    version: v1
  annotations:                     # Anotaciones (metadatos adicionales)
    description: "Production Pod"
    owner: "team-backend"
spec:
  # Política de reinicio
  restartPolicy: Always           # Always, Never, OnFailure

  # Duración máxima del Pod (segundos)
  activeDeadlineSeconds: 3600

  # Tolerancia de riesgos (taints)
  tolerations:
  - key: node-type
    operator: Equal
    value: gpu
    effect: NoSchedule

  # Afinidad de nodos
  nodeSelector:
    kubernetes.io/hostname: worker-1

  # Cuenta de servicio
  serviceAccountName: my-account

  # Seguridad del Pod
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000

  # DNS
  dnsPolicy: ClusterFirst
  dnsConfig:
    nameservers:
    - 8.8.8.8
    searches:
    - my.dns.search.suffix

  # Volúmenes
  volumes:
  - name: config-vol
    configMap:
      name: my-config
  - name: secret-vol
    secret:
      secretName: my-secret
  - name: storage-vol
    emptyDir: {}

  # Init containers (se ejecutan primero)
  initContainers:
  - name: init
    image: busybox:latest
    command: ['echo', 'Initializing...']

  # Contenedores principales
  containers:
  - name: app
    image: myapp:1.0
    imagePullPolicy: IfNotPresent  # Always, Never, IfNotPresent

    # Puertos
    ports:
    - name: http
      containerPort: 8080
      protocol: TCP

    # Variables de entorno
    env:
    - name: APP_ENV
      value: production
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: password

    # Mount de volúmenes
    volumeMounts:
    - name: config-vol
      mountPath: /etc/config
    - name: storage-vol
      mountPath: /data

    # Recursos
    resources:
      requests:
        cpu: "100m"
        memory: "128Mi"
      limits:
        cpu: "500m"
        memory: "512Mi"

    # Health checks
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 10
      periodSeconds: 5

    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 3

    startupProbe:
      httpGet:
        path: /started
        port: 8080
      failureThreshold: 30
      periodSeconds: 10

  # Sidecars (contenedores adicionales)
  - name: logging-sidecar
    image: fluent-bit:latest
    volumeMounts:
    - name: config-vol
      mountPath: /etc/config

  # Terminación grácil
  terminationGracePeriodSeconds: 30</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_2_2_crear_pods_con_kubectl_apply">2.2.2. 2.2.2 Crear Pods con kubectl apply</h4>
<div class="paragraph">
<p><strong>Método Imperativo (rápido para testing):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear un Pod simple directamente
kubectl run my-pod --image=nginx:latest

# Con especificaciones adicionales
kubectl run my-pod \
  --image=nginx:latest \
  --port=8080 \
  --env=APP_ENV=production

# Con límites de recursos
kubectl run my-pod \
  --image=nginx:latest \
  --limits=cpu=500m,memory=512Mi \
  --requests=cpu=100m,memory=128Mi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Método Declarativo (recomendado para producción):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear desde archivo YAML
kubectl apply -f pod.yaml

# Crear desde múltiples archivos
kubectl apply -f pod1.yaml -f pod2.yaml

# Crear desde directorio
kubectl apply -f ./pods/

# Crear desde URL
kubectl apply -f https://example.com/pod.yaml

# Ver qué cambiaría (dry-run)
kubectl apply -f pod.yaml --dry-run=client
kubectl apply -f pod.yaml --dry-run=server</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_2_3_campos_obligatorios_y_opcionales">2.2.3. 2.2.3 Campos Obligatorios y Opcionales</h4>
<div class="paragraph">
<p><strong>Campos Obligatorios:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1              # Requerido
kind: Pod                   # Requerido
metadata:
  name: my-pod              # Requerido (único en el namespace)
spec:
  containers:               # Requerido (al menos 1)
  - name: app               # Requerido
    image: nginx:latest     # Requerido</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Campos Opcionales pero Recomendados:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">metadata:
  namespace: production      # Por defecto: default
  labels:
    app: myapp
  annotations:
    owner: team

spec:
  containers:
  - resources:
      requests:             # Recomendado para scheduling
        cpu: 100m
        memory: 128Mi
      limits:                # Recomendado para evitar OOM
        cpu: 500m
        memory: 512Mi

    livenessProbe:           # Recomendado para health checks
      httpGet:
        path: /health
        port: 8080

    readinessProbe:          # Recomendado para zero-downtime deploys
      httpGet:
        path: /ready
        port: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_2_4_etiquetas_y_anotaciones">2.2.4. 2.2.4 Etiquetas y Anotaciones</h4>
<div class="sect4">
<h5 id="_etiquetas_labels">Etiquetas (Labels)</h5>
<div class="paragraph">
<p>Las <strong>labels</strong> son pares clave-valor que identifican objetos. Se usan para <strong>seleccionar y agrupar</strong> objetos.</p>
</div>
<div class="paragraph">
<p><strong>Reglas:</strong>
- Clave: debe ser válida (letras, números, guiones, puntos, máximo 63 caracteres)
- Valor: alfanumérico, guiones, puntos, máximo 63 caracteres
- Máximo 64 labels por objeto</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: web-pod
  labels:
    app: web                        # Label simple
    environment: production
    team: backend
    version: v1
    component: api
    tier: frontend
spec:
  containers:
  - name: web
    image: nginx:latest</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Uso de Labels:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Seleccionar Pods por label
kubectl get pods -l app=web

# Múltiples labels
kubectl get pods -l app=web,environment=production

# Operadores: in, notin, exists
kubectl get pods -l environment in (production,staging)
kubectl get pods -l tier notin (frontend)
kubectl get pods -l version

# Describir con labels
kubectl describe pod web-pod
kubectl get pods --show-labels</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_anotaciones_annotations">Anotaciones (Annotations)</h5>
<div class="paragraph">
<p>Las <strong>annotations</strong> son similares a labels pero se usan para información que <strong>no es para selección</strong>.</p>
</div>
<div class="paragraph">
<p><strong>Usos:</strong>
- Información de build
- Información de contacto
- URLs de documentación
- Información de debugging</p>
</div>
<div class="paragraph">
<p><strong>Reglas similares a labels</strong> pero pueden ser más largas.</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: web-pod
  annotations:
    description: "Main web server for API"
    documentation: "https://wiki.company.com/web-pod"
    contact: "team-backend@company.com"
    build-date: "2025-01-10"
    git-commit: "abc123def456"
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
    prometheus.io/path: "/metrics"
spec:
  containers:
  - name: web
    image: nginx:latest</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ventajas de Anotaciones:</strong>
- No tienen restricciones de formato
- Pueden contener datos complejos
- Herramientas pueden leerlas e interpretarlas</p>
</div>
<hr>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_3_gestión_de_pods">2.3. 2.3 Gestión de Pods</h3>
<div class="sect3">
<h4 id="_2_3_1_listar_pods">2.3.1. 2.3.1 Listar Pods</h4>
<div class="paragraph">
<p><strong>Comandos básicos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Listar Pods en namespace actual (default)
kubectl get pods

# Listar con más información
kubectl get pods -o wide

# Listar en todos los namespaces
kubectl get pods -A
kubectl get pods --all-namespaces

# Listar en namespace específico
kubectl get pods -n kube-system

# Listar con labels
kubectl get pods --show-labels

# Listar filtrando por label
kubectl get pods -l app=nginx

# Formato de salida personalizado
kubectl get pods -o yaml        # YAML format
kubectl get pods -o json        # JSON format
kubectl get pods -o json | jq   # JSON con jq para filtrar</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Salida de ejemplo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ kubectl get pods
NAME                    READY   STATUS    RESTARTS   AGE
nginx-deployment-5d...  1/1     Running   0          10m
nginx-deployment-7c...  1/1     Running   0          10m
redis-cache             1/1     Running   2          5d
postgres-db-0           1/1     Running   0          3d

READY: contenedores listos / total de contenedores
STATUS: estado actual del Pod
RESTARTS: número de veces que se reinició
AGE: tiempo desde que se creó</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_3_2_ver_detalles_de_un_pod">2.3.2. 2.3.2 Ver Detalles de un Pod</h4>
<div class="paragraph">
<p><strong>Comando describe (muy útil):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver todos los detalles de un Pod
kubectl describe pod nginx-deployment-5d...

# Salida incluye:
# - Metadata (nombre, namespace, labels, etc.)
# - Spec (configuración)
# - Status (estado actual)
# - Eventos (qué pasó)
# - Mounts (volúmenes)
# - Resource limits
# - Health checks</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ver en YAML:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver definición YAML actual
kubectl get pod nginx-deployment-5d... -o yaml

# Salida es YAML completo que puedes editar o guardar</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_3_3_logs_de_pods">2.3.3. 2.3.3 Logs de Pods</h4>
<div class="paragraph">
<p><strong>Ver logs:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver logs del último startup
kubectl logs pod-name

# Seguir logs en vivo (like tail -f)
kubectl logs -f pod-name

# Últimas N líneas
kubectl logs pod-name --tail=50

# Últimos N segundos
kubectl logs pod-name --since=10m

# Con timestamps
kubectl logs pod-name --timestamps=true

# De contenedor específico en Pod multi-contenedor
kubectl logs pod-name -c container-name

# Pod anterior (si fue reiniciado)
kubectl logs pod-name --previous</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Logs de múltiples Pods:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># De múltiples Pods con label
kubectl logs -l app=nginx

# De múltiples Pods (todos con prefijo)
kubectl logs -f -l app=nginx --all-containers=true</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_3_4_ejecutar_comandos_en_pods">2.3.4. 2.3.4 Ejecutar Comandos en Pods</h4>
<div class="paragraph">
<p><strong>Ejecutar comando una vez:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ejecutar comando en Pod
kubectl exec pod-name -- ls -la

# Ejecutar en contenedor específico
kubectl exec pod-name -c container-name -- pwd

# Ejecutar shell command
kubectl exec pod-name -- sh -c "echo Hello from Pod"

# Pasar variables de entorno
kubectl exec pod-name -- env</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Sesión interactiva:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Abrir bash/sh interactivo
kubectl exec -it pod-name -- /bin/bash
kubectl exec -it pod-name -- /bin/sh

# Una vez dentro, puedes ejecutar comandos normales
$ ls -la
$ cat /etc/config/app.conf
$ ps aux</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Copiar archivos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Copiar archivo desde Pod a local
kubectl cp pod-name:/path/in/pod /path/local

# Copiar archivo desde local a Pod
kubectl cp /path/local pod-name:/path/in/pod

# Especificar contenedor
kubectl cp pod-name:/path -c container-name /path/local</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_3_5_eliminar_pods">2.3.5. 2.3.5 Eliminar Pods</h4>
<div class="paragraph">
<p><strong>Eliminar Pods:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Eliminar un Pod
kubectl delete pod pod-name

# Eliminar múltiples Pods
kubectl delete pod pod1 pod2 pod3

# Eliminar por label
kubectl delete pods -l app=nginx

# Eliminar todos los Pods en namespace
kubectl delete pods --all

# Eliminar con período de gracia (segundos)
kubectl delete pod pod-name --grace-period=30

# Forzar eliminación inmediata (puede causar problemas)
kubectl delete pod pod-name --force

# De un archivo YAML
kubectl delete -f pod.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_3_6_port_forwarding">2.3.6. 2.3.6 Port Forwarding</h4>
<div class="paragraph">
<p><strong>Conectar a un Pod directamente:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Port forward simple
kubectl port-forward pod/pod-name 8080:8080

# Forward a puerto diferente en local
kubectl port-forward pod/pod-name 9090:8080
# Accede en http://localhost:9090

# Forward en background
kubectl port-forward pod/pod-name 8080:8080 &amp;

# Usar dirección específica
kubectl port-forward pod/pod-name 127.0.0.1:8080:8080

# Multiple ports
kubectl port-forward pod/pod-name 8080:8080 8443:8443

# De un Servicio
kubectl port-forward svc/service-name 8080:8080</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_2_4_configuración_de_pods">2.4. 2.4 Configuración de Pods</h3>
<div class="sect3">
<h4 id="_2_4_1_variables_de_entorno">2.4.1. 2.4.1 Variables de Entorno</h4>
<div class="paragraph">
<p><strong>Método 1: Valor literal</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: env-demo
spec:
  containers:
  - name: app
    image: myapp:latest
    env:
    - name: APP_ENV
      value: production
    - name: LOG_LEVEL
      value: "INFO"
    - name: DATABASE_URL
      value: postgres://db.example.com:5432/mydb</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Método 2: Desde ConfigMap</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  APP_ENV: production
  LOG_LEVEL: "INFO"

---
apiVersion: v1
kind: Pod
metadata:
  name: env-demo
spec:
  containers:
  - name: app
    image: myapp:latest
    envFrom:
    - configMapRef:
        name: app-config
    # Todas las keys del ConfigMap se importan como variables</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Método 3: Desde Secrets</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: db-secret
type: Opaque
data:
  password: cGFzc3dvcmQxMjM=  # base64 encoded

---
apiVersion: v1
kind: Pod
metadata:
  name: env-demo
spec:
  containers:
  - name: app
    image: myapp:latest
    env:
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: password</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Método 4: Field references (desde metadata del Pod)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: env-demo
spec:
  containers:
  - name: app
    image: myapp:latest
    env:
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: POD_UID
      valueFrom:
        fieldRef:
          fieldPath: metadata.uid
    - name: CONTAINER_CPU_LIMIT
      valueFrom:
        resourceFieldRef:
          containerName: app
          resource: limits.cpu
    - name: CONTAINER_MEM_REQUEST
      valueFrom:
        resourceFieldRef:
          containerName: app
          resource: requests.memory</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_4_2_volúmenes">2.4.2. 2.4.2 Volúmenes</h4>
<div class="paragraph">
<p><strong>Volumen emptyDir (almacenamiento temporal):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: vol-demo
spec:
  containers:
  - name: writer
    image: busybox
    command: ['sh', '-c', 'for i in 1 2 3; do echo $i &gt; /data/file$i; sleep 1; done']
    volumeMounts:
    - name: data
      mountPath: /data

  - name: reader
    image: busybox
    command: ['sh', '-c', 'watch "ls -la /data"']
    volumeMounts:
    - name: data
      mountPath: /data

  volumes:
  - name: data
    emptyDir: {}  # Se elimina cuando el Pod se elimina</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Volumen hostPath (acceso al nodo):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: hostpath-demo
spec:
  containers:
  - name: app
    image: busybox
    volumeMounts:
    - name: host-vol
      mountPath: /data

  volumes:
  - name: host-vol
    hostPath:
      path: /var/data          # Path en el nodo
      type: DirectoryOrCreate  # Crear si no existe</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_4_3_probes_health_checks">2.4.3. 2.4.3 Probes (Health Checks)</h4>
<div class="sect4">
<h5 id="_liveness_probe">Liveness Probe</h5>
<div class="paragraph">
<p>Determina si el Pod está vivo. Si falla, el Pod se reinicia.</p>
</div>
<div class="paragraph">
<p><strong>HTTP GET:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: probe-demo
spec:
  containers:
  - name: app
    image: myapp:latest
    ports:
    - containerPort: 8080
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 10   # Esperar 10s antes de empezar
      periodSeconds: 5          # Check cada 5s
      timeoutSeconds: 2         # Timeout de 2s
      failureThreshold: 3       # Reiniciar después de 3 fallos</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>TCP Socket:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">livenessProbe:
  tcpSocket:
    port: 3306
  initialDelaySeconds: 15
  periodSeconds: 10</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Exec (ejecutar comando):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">livenessProbe:
  exec:
    command:
    - /bin/sh
    - -c
    - "curl -f http://localhost:8080/health || exit 1"
  initialDelaySeconds: 10
  periodSeconds: 10</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_readiness_probe">Readiness Probe</h5>
<div class="paragraph">
<p>Determina si el Pod está listo para recibir tráfico. Si falla, se quita del Service.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: probe-demo
spec:
  containers:
  - name: app
    image: myapp:latest
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 3
      failureThreshold: 2</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_startup_probe">Startup Probe</h5>
<div class="paragraph">
<p>Para aplicaciones que toman mucho tiempo en iniciar. Previene que Liveness Probe las mate antes de iniciar.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: slow-app
spec:
  containers:
  - name: app
    image: slow-startup-app:latest
    startupProbe:
      httpGet:
        path: /started
        port: 8080
      failureThreshold: 30      # 30 intentos
      periodSeconds: 10         # Cada 10s = 300s = 5 minutos máximo

    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      periodSeconds: 10</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo Completo con los 3 Probes:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: healthy-app
spec:
  containers:
  - name: app
    image: myapp:latest
    ports:
    - containerPort: 8080

    # Esperar a que la app inicie
    startupProbe:
      httpGet:
        path: /started
        port: 8080
      failureThreshold: 30
      periodSeconds: 10

    # Asegurar que la app sigue viva
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 10
      periodSeconds: 5
      failureThreshold: 3

    # Determinar si puede recibir tráfico
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 3
      failureThreshold: 2</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_2_4_4_resource_limits_y_requests">2.4.4. 2.4.4 Resource Limits y Requests</h4>
<div class="paragraph">
<p><strong>Requests: Lo que el Pod necesita</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: resource-demo
spec:
  containers:
  - name: app
    image: myapp:latest
    resources:
      requests:
        cpu: "100m"        # 100 milli-cores (0.1 CPU)
        memory: "128Mi"    # 128 Mebibytes
        ephemeralStorage: "1Gi"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p>El Scheduler usa <code>requests</code> para decidir en qué nodo ejecutar el Pod. El Pod solo será programado en nodos con suficientes recursos libres.</p>
</div>
<div class="paragraph">
<p><strong>Limits: Máximo que el Pod puede usar</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">resources:
  limits:
    cpu: "500m"        # Máximo 500 milli-cores
    memory: "512Mi"    # Máximo 512 Mebibytes
    ephemeralStorage: "2Gi"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p>El kubelet enforces <code>limits</code>. Si el Pod excede CPU, es throttled. Si excede memoria, es OOMKilled.</p>
</div>
<div class="paragraph">
<p><strong>Unidades:</strong>
- <strong>CPU</strong>: <code>m</code> (milli-cores), <code>100m</code> = 0.1 CPU
- <strong>Memoria</strong>: <code>Mi</code> (Mebibytes), <code>Gi</code> (Gibibytes)
- <strong>Storage</strong>: <code>Gi</code> (Gibibytes)</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo Recomendado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: well-configured
spec:
  containers:
  - name: app
    image: myapp:latest
    resources:
      requests:
        cpu: "100m"
        memory: "128Mi"
      limits:
        cpu: "500m"
        memory: "512Mi"

    # El ratio típico es 1:5 (requests:limits)
    # Pero depende de tu aplicación</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_4_5_security_context">2.4.5. 2.4.5 Security Context</h4>
<div class="paragraph">
<p><strong>Pod Security Context (aplica a todos los contenedores):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: secure-pod
spec:
  securityContext:
    runAsUser: 1000          # UID del usuario que ejecuta procesos
    runAsGroup: 3000         # GID
    fsGroup: 2000            # GID para permisos de archivo
    runAsNonRoot: true       # No permitir root
  containers:
  - name: app
    image: myapp:latest
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
        add:
        - NET_BIND_SERVICE</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Container Security Context (por contenedor):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: container-security-demo
spec:
  containers:
  - name: app
    image: myapp:latest
    securityContext:
      runAsUser: 2000
      runAsNonRoot: true
      readOnlyRootFilesystem: true
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      seccompProfile:
        type: RuntimeDefault
      seLinuxOptions:
        level: "s0:c123,c456"
    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: var-log
      mountPath: /var/log
  volumes:
  - name: tmp
    emptyDir: {}
  - name: var-log
    emptyDir: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_2_5_troubleshooting_de_pods">2.5. 2.5 Troubleshooting de Pods</h3>
<div class="sect3">
<h4 id="_2_5_1_comando_describe">2.5.1. 2.5.1 Comando Describe</h4>
<div class="paragraph">
<p>El comando <code>kubectl describe pod</code> es tu mejor amigo para debugging:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">kubectl describe pod pod-name

# Salida incluye:
# - Name, Namespace, Priority
# - Node donde está ejecutándose
# - Start Time
# - Labels y Annotations
# - Image, Image ID
# - Ports
# - Resource limits/requests
# - State (Running/Waiting/Terminated)
# - Reason y Message
# - Last State
# - Ready y RestartCount
# - Probes
# - Environment
# - Mounts
# - Eventos (MUY IMPORTANTE)</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Los eventos son lo más importante. Muestran el historial:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">Events:
  Type    Reason     Age   From               Message
  ----    ------     ---   ----               -------
  Normal  Scheduled  2m    default-scheduler  Successfully assigned default/pod to node1
  Normal  Pulling    2m    kubelet            Pulling image "myapp:latest"
  Normal  Pulled     1m    kubelet            Successfully pulled image
  Normal  Created    1m    kubelet            Created container
  Normal  Started    1m    kubelet            Started container</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_5_2_ver_eventos">2.5.2. 2.5.2 Ver Eventos</h4>
<div class="paragraph">
<p><strong>Eventos del cluster:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Todos los eventos (últimos)
kubectl get events

# Ordenar por tiempo
kubectl get events --sort-by='.lastTimestamp'

# Eventos de un Pod
kubectl describe pod pod-name | grep -A 100 "Events:"

# Eventos en tiempo real (watch)
kubectl get events -w

# Eventos en namespace específico
kubectl get events -n kube-system

# Eventos por tipo
kubectl get events --field-selector type=Warning
kubectl get events --field-selector type=Normal</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_5_3_analizar_logs">2.5.3. 2.5.3 Analizar Logs</h4>
<div class="paragraph">
<p><strong>Estrategia de debugging con logs:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># 1. Ver logs actuales
kubectl logs pod-name

# 2. Seguir logs en vivo mientras genera carga
kubectl logs -f pod-name

# 3. Ver logs del startup anterior
kubectl logs pod-name --previous

# 4. Ver logs de solo los últimos 5 minutos
kubectl logs pod-name --since=5m

# 5. Combinar con grep para buscar
kubectl logs pod-name | grep ERROR

# 6. Ver todas las líneas que coinciden
kubectl logs pod-name | grep -C 5 "ERROR"

# 7. Si hay múltiples contenedores
kubectl logs pod-name -c container-name

# 8. Logs de todos los Pods con label
kubectl logs -l app=nginx -f</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo: Debugging de Pod que no inicia:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># 1. Ver estado
kubectl get pods
# Resultado: CrashLoopBackOff

# 2. Describir para ver el error
kubectl describe pod problem-pod
# En Eventos verás el problema

# 3. Ver logs del último startup
kubectl logs problem-pod

# 4. Ver logs del anterior
kubectl logs problem-pod --previous

# 5. Si la imagen está mal:
kubectl describe pod problem-pod | grep Image
# Verás ImagePullBackOff si hay problema con la imagen</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_5_4_problemas_comunes_y_soluciones">2.5.4. 2.5.4 Problemas Comunes y Soluciones</h4>
<div class="sect4">
<h5 id="_imagepullbackoff">ImagePullBackOff</h5>
<div class="paragraph">
<p><strong>Problema:</strong> No puede descargar la imagen</p>
</div>
<div class="paragraph">
<p><strong>Síntomas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Status: ImagePullBackOff</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Causas posibles:</strong>
- Imagen no existe
- Registry privada sin credenciales
- Red no funciona
- Typo en nombre de imagen</p>
</div>
<div class="paragraph">
<p><strong>Solución:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver el error específico
kubectl describe pod problem-pod

# Si es privada, crear secret
kubectl create secret docker-registry regcred \
  --docker-server=docker.io \
  --docker-username=myuser \
  --docker-password=mypass

# Usar en Pod
spec:
  imagePullSecrets:
  - name: regcred

# Verificar que la imagen existe
docker search myimage
docker pull docker.io/myuser/myimage:tag</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_crashloopbackoff">CrashLoopBackOff</h5>
<div class="paragraph">
<p><strong>Problema:</strong> El contenedor inicia pero luego falla</p>
</div>
<div class="paragraph">
<p><strong>Síntomas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Status: CrashLoopBackOff
Restarts: 5 (in last 2m)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Solución:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver logs del último startup
kubectl logs pod-name

# Ver logs anteriores
kubectl logs pod-name --previous

# Describir el pod
kubectl describe pod pod-name

# Ejecutar bash en el mismo contexto para debuggear
kubectl run -it --rm debug \
  --image=myapp:latest \
  --restart=Never \
  -- /bin/bash</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_pending">Pending</h5>
<div class="paragraph">
<p><strong>Problema:</strong> Pod no se inicia</p>
</div>
<div class="paragraph">
<p><strong>Síntomas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Status: Pending</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Causas posibles:</strong>
- Recursos insuficientes
- Nodo no disponible
- PVC no vinculado</p>
</div>
<div class="paragraph">
<p><strong>Solución:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver descripción (muestra por qué está pending)
kubectl describe pod pod-name

# Ver recursos disponibles
kubectl top nodes
kubectl describe nodes

# Si es por storage
kubectl get pvc
kubectl describe pvc pvc-name

# Aumentar recursos del cluster
minikube stop
minikube start --cpus 8 --memory 8192</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_pod_stuck_in_terminating">Pod Stuck in Terminating</h5>
<div class="paragraph">
<p><strong>Problema:</strong> Pod no se elimina</p>
</div>
<div class="paragraph">
<p><strong>Síntomas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Status: Terminating
Age: 10m</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Solución:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver qué tiene el Pod
kubectl describe pod pod-name

# Forzar eliminación (último recurso)
kubectl delete pod pod-name --grace-period=0 --force

# O con alternativa:
kubectl patch pod pod-name -p '{"metadata":{"finalizers":null}}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_oomkilled">OOMKilled</h5>
<div class="paragraph">
<p><strong>Problema:</strong> Pod se queda sin memoria</p>
</div>
<div class="paragraph">
<p><strong>Síntomas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Last State: Terminated
Reason: OOMKilled</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Solución:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver memoria actual
kubectl top pods

# Aumentar límites
kubectl set resources pod pod-name --limits=memory=1Gi

# O editar YAML
kubectl edit pod pod-name
# Editar resources.limits.memory

# Depende del Pod en namespace
kubectl top pods -n kube-system</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_2_5_5_herramientas_de_debugging_útiles">2.5.5. 2.5.5 Herramientas de Debugging Útiles</h4>
<div class="paragraph">
<p><strong>Ejecutar un Pod de debug:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Pod debug simple
kubectl run -it --rm debug --image=busybox --restart=Never -- /bin/sh

# Pod debug con tooling avanzado
kubectl run -it --rm debug \
  --image=nicolaka/netshoot \
  --restart=Never \
  -- /bin/bash</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Dentro del Pod de debug:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Verificar conectividad DNS
nslookup kubernetes.default
nslookup nginx-service

# Ping a service
ping nginx-service

# Wget/curl a servicio
wget -O- http://nginx-service:80
curl http://nginx-service:80

# Ver puertos abiertos
netstat -tlnp
ss -tlnp

# Verificar variables de entorno
env | grep KUBERNETES

# Ver servicios disponibles
nslookup nginx-service.default.svc.cluster.local</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_2_6_ejemplos_prácticos_completos">2.6. 2.6 Ejemplos Prácticos Completos</h3>
<div class="sect3">
<h4 id="_ejemplo_1_pod_simple_con_health_checks">2.6.1. Ejemplo 1: Pod Simple con Health Checks</h4>
<div class="paragraph">
<p><strong>YAML - simple-pod.yaml:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: simple-app
  labels:
    app: simple
    version: v1
spec:
  containers:
  - name: app
    image: nginx:1.21
    ports:
    - containerPort: 80
      name: http

    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 10

    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 5

    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 500m
        memory: 512Mi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Uso:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">kubectl apply -f simple-pod.yaml
kubectl get pods
kubectl describe pod simple-app
kubectl logs simple-app
kubectl port-forward pod/simple-app 8080:80</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_2_pod_con_init_container">2.6.2. Ejemplo 2: Pod con Init Container</h4>
<div class="paragraph">
<p><strong>YAML - init-container-pod.yaml:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: init-demo
spec:
  initContainers:
  - name: wait-for-network
    image: busybox:latest
    command: ['sh', '-c', 'for i in {1..30}; do ping -c 1 8.8.8.8 &amp;&amp; break || sleep 1; done']

  - name: setup-config
    image: busybox:latest
    command: ['sh', '-c', 'echo "APP_READY=true" &gt; /config/app.conf']
    volumeMounts:
    - name: config-vol
      mountPath: /config

  containers:
  - name: app
    image: nginx:latest
    volumeMounts:
    - name: config-vol
      mountPath: /config
      readOnly: true

  volumes:
  - name: config-vol
    emptyDir: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_3_pod_con_sidecar_para_logging">2.6.3. Ejemplo 3: Pod con Sidecar para Logging</h4>
<div class="paragraph">
<p><strong>YAML - sidecar-pod.yaml:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-logging
spec:
  containers:
  - name: app
    image: nginx:latest
    ports:
    - containerPort: 80
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx

  - name: log-rotator
    image: busybox:latest
    command: ['sh', '-c', 'while true; do sleep 3600; rm -f /var/log/nginx/*.log.* ; done']
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx

  volumes:
  - name: shared-logs
    emptyDir: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_4_pod_con_configuración_y_secretos">2.6.4. Ejemplo 4: Pod con Configuración y Secretos</h4>
<div class="paragraph">
<p><strong>YAML - config-secret-pod.yaml:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  app.properties: |
    APP_NAME=MyApp
    LOG_LEVEL=INFO
    DATABASE_HOST=db.default.svc.cluster.local

---
apiVersion: v1
kind: Secret
metadata:
  name: db-credentials
type: Opaque
stringData:
  username: admin
  password: "secret123"

---
apiVersion: v1
kind: Pod
metadata:
  name: app-configured
spec:
  containers:
  - name: app
    image: myapp:latest
    env:
    - name: DB_USER
      valueFrom:
        secretKeyRef:
          name: db-credentials
          key: username
    - name: DB_PASS
      valueFrom:
        secretKeyRef:
          name: db-credentials
          key: password
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name

    volumeMounts:
    - name: config
      mountPath: /etc/config
      readOnly: true
    - name: secrets
      mountPath: /etc/secrets
      readOnly: true

  volumes:
  - name: config
    configMap:
      name: app-config
  - name: secrets
    secret:
      secretName: db-credentials</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_5_pod_seguro">2.6.5. Ejemplo 5: Pod Seguro</h4>
<div class="paragraph">
<p><strong>YAML - secure-pod.yaml:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: secure-app
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000

  containers:
  - name: app
    image: myapp:latest

    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
        add:
        - NET_BIND_SERVICE

    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 200m
        memory: 256Mi

    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: app-data
      mountPath: /app/data

  volumes:
  - name: tmp
    emptyDir: {}
  - name: app-data
    emptyDir: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_2_7_resumen_del_módulo_2">2.7. 2.7 Resumen del Módulo 2</h3>
<div class="paragraph">
<p>En este módulo aprendiste:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Conceptos de Pods</strong>: Unidad mínima, ciclo de vida, tipos de contenedores</p>
</li>
<li>
<p><strong>Crear Pods</strong>: YAML declarativo, campos obligatorios y opcionales</p>
</li>
<li>
<p><strong>Gestión</strong>: Listar, describir, logs, exec, port-forward</p>
</li>
<li>
<p><strong>Configuración</strong>: Variables de entorno, volúmenes, probes</p>
</li>
<li>
<p><strong>Seguridad</strong>: Security context, permisos, capabilities</p>
</li>
<li>
<p><strong>Troubleshooting</strong>: Describe, logs, eventos, problemas comunes</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Con estos conocimientos, estás listo para aprender sobre <strong>Controladores como Deployments</strong> en el Módulo 3.</p>
</div>
<hr>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_3_controladores">3. MÓDULO 3: Controladores</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Un <strong>Controlador</strong> en Kubernetes es un bucle infinito que observa el estado actual del cluster y toma acciones para que coincida con el estado deseado. Es el concepto fundamental de Kubernetes.</p>
</div>
<div class="paragraph">
<p><strong>Patrón del Controlador:</strong>
[source,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>┌─────────────────────────────────────────┐
│     BUCLE INFINITO DEL CONTROLADOR      │
├─────────────────────────────────────────┤
│  1. OBSERVE (observar estado actual)    │
│  2. COMPARE (con estado deseado)        │
│  3. ACT (tomar acciones para sincronizar)
│  4. REPEAT (volver al paso 1)           │
└─────────────────────────────────────────┘</pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
<div class="sect2">
<h3 id="_3_1_deployments">3.1. 3.1 Deployments</h3>
<div class="sect3">
<h4 id="_3_1_1_concepto_de_deployment">3.1.1. 3.1.1 Concepto de Deployment</h4>
<div class="paragraph">
<p>Un <strong>Deployment</strong> es un controlador que gestiona un conjunto de Pods idénticos replicados. Es la forma <strong>estándar y recomendada</strong> de desplegar aplicaciones en Kubernetes.</p>
</div>
<div class="paragraph">
<p><strong>¿Por qué Deployments en lugar de Pods?</strong></p>
</div>
<div class="paragraph">
<p>Con Pods solos:
- Si un Pod falla, debe reiniciarlo manualmente
- Para escalar, debe crear Pods manualmente
- Para actualizar, debe eliminar y recrear Pods (downtime)</p>
</div>
<div class="paragraph">
<p>Con Deployments:
- ✅ Reinicio automático de Pods fallidos
- ✅ Escalado automático (manual o automático)
- ✅ Actualizaciones con cero downtime (rolling updates)
- ✅ Rollback automático si algo sale mal
- ✅ Historial de versiones</p>
</div>
<div class="paragraph">
<p><strong>Analogía:</strong>
Un Deployment es como un manager de un equipo de trabajo:
- Asegura que siempre haya el número correcto de personas trabajando
- Si alguien se enferma, contrata a otro
- Cuando hay mucho trabajo, contrata a más personas
- Cuando necesita cambiar procesos, lo hace gradualmente para no perder eficiencia</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_1_2_yaml_de_deployment">3.1.2. 3.1.2 YAML de Deployment</h4>
<div class="paragraph">
<p><strong>Estructura Mínima:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21
        ports:
        - containerPort: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Desglose:</strong>
- <code>apiVersion: apps/v1</code>: Versión de API para Deployments
- <code>kind: Deployment</code>: Tipo de objeto
- <code>metadata.name</code>: Nombre único del Deployment
- <code>spec.replicas</code>: Número de Pods que deseas
- <code>spec.selector</code>: Cómo identificar los Pods que gestiona este Deployment
- <code>spec.template</code>: Plantilla para crear Pods (es básicamente un Pod spec)</p>
</div>
<div class="paragraph">
<p><strong>Estructura Completa con Todas las Opciones:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
  namespace: production
  labels:
    app: web-app
    version: v1
  annotations:
    description: "Production web application"

spec:
  # Número de replicas
  replicas: 3

  # Revisión historial (para rollback)
  revisionHistoryLimit: 10

  # Estrategia de actualización
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1           # Máximo Pods extra durante update (además de replicas)
      maxUnavailable: 0     # Máximo Pods no disponibles durante update

  # Tiempo máximo para que un Deployment esté listo
  progressDeadlineSeconds: 600

  # Tiempo máximo entre checks de progreso
  minReadySeconds: 0

  # Selector de Pods
  selector:
    matchLabels:
      app: web-app
    matchExpressions:
    - key: version
      operator: In
      values: [v1, v2]

  # Plantilla de Pod
  template:
    metadata:
      labels:
        app: web-app
        version: v1
      annotations:
        prometheus.io/scrape: "true"

    spec:
      # Duración de shutdown grácil
      terminationGracePeriodSeconds: 30

      # Pod disruption budget
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - web-app
              topologyKey: kubernetes.io/hostname

      containers:
      - name: web-app
        image: myapp:1.0
        imagePullPolicy: IfNotPresent

        ports:
        - containerPort: 8080
          name: http

        env:
        - name: ENVIRONMENT
          value: production
        - name: LOG_LEVEL
          value: info

        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi

        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10
          failureThreshold: 3

        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
          failureThreshold: 2

        volumeMounts:
        - name: config
          mountPath: /etc/config

      volumes:
      - name: config
        configMap:
          name: app-config</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_1_3_replicas_y_escalado">3.1.3. 3.1.3 Replicas y Escalado</h4>
<div class="paragraph">
<p><strong>Ver replicas actuales:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">kubectl get deployment nginx-deployment
kubectl describe deployment nginx-deployment

# Salida:
# Replicas: 3 desired | 3 updated | 3 total | 3 available</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Escalado Manual:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Escalar a 5 replicas
kubectl scale deployment nginx-deployment --replicas=5

# Ver cambios
kubectl get pods

# Escalar hacia abajo
kubectl scale deployment nginx-deployment --replicas=2

# Editar directamente
kubectl edit deployment nginx-deployment
# Busca "replicas" y cambia el número</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Escalado mediante YAML:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Actualizar el YAML y aplicar
kubectl apply -f deployment.yaml

# O hacer un patch
kubectl patch deployment nginx-deployment -p '{"spec":{"replicas":4}}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Observar escalado en tiempo real:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver Pods siendo creados
kubectl get pods --watch

# Ver eventos de escalado
kubectl get events --sort-by='.lastTimestamp'

# Describir el Deployment para ver progreso
kubectl describe deployment nginx-deployment</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_1_4_actualización_de_deployments">3.1.4. 3.1.4 Actualización de Deployments</h4>
<div class="sect4">
<h5 id="_rolling_update_estrategia_recomendada">Rolling Update (Estrategia Recomendada)</h5>
<div class="paragraph">
<p>La estrategia <strong>RollingUpdate</strong> actualiza Pods gradualmente, manteniendo disponibilidad.</p>
</div>
<div class="paragraph">
<p><strong>Cómo funciona:</strong>
[source,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Estado Inicial (3 Pods v1):
Pod1-v1  Pod2-v1  Pod3-v1

Paso 1 (maxSurge=1, maxUnavailable=0):
Pod1-v1  Pod2-v1  Pod3-v1  Pod4-v2  ← Nuevo

Paso 2 (Elimina uno antiguo):
Pod1-v1  Pod2-v1  Pod4-v2  Pod5-v2

Paso 3:
Pod1-v1  Pod3-v2  Pod4-v2  Pod5-v2

Final (3 Pods v2):
Pod3-v2  Pod4-v2  Pod5-v2</pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Configuración en YAML:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1          # Máximo 1 Pod extra (4 en lugar de 3)
      maxUnavailable: 0    # Siempre 3 disponibles (0 indisponibles)
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.22  # Versión actualizada</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Actualizar la versión de imagen:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Método 1: Editar el Deployment
kubectl edit deployment nginx-deployment
# Cambiar imagen y guardar

# Método 2: Set image
kubectl set image deployment/nginx-deployment nginx=nginx:1.22

# Método 3: Patch
kubectl patch deployment nginx-deployment -p '{"spec":{"template":{"spec":{"containers":[{"name":"nginx","image":"nginx:1.22"}]}}}}'

# Ver progreso
kubectl rollout status deployment/nginx-deployment

# Ver en tiempo real
kubectl get pods --watch

# Ver eventos
kubectl get events --sort-by='.lastTimestamp'</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_recreate_strategy">Recreate Strategy</h5>
<div class="paragraph">
<p>La estrategia <strong>Recreate</strong> elimina todos los Pods y luego crea nuevos. Causa downtime.</p>
</div>
<div class="paragraph">
<p><strong>Cuándo usar:</strong>
- Aplicaciones que no pueden correr múltiples versiones simultáneamente
- Datos compartidos en estado inconsistente</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-deployment
spec:
  replicas: 3
  strategy:
    type: Recreate
    # No hay opciones de configuración para Recreate
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: app
        image: myapp:2.0</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Cómo se ve:</strong>
[source,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>t=0s: 3 Pods v1 ejecutándose
t=5s: Se inician todos los Pods v1 (downtime)
t=10s: Se crean 3 Pods v2
t=15s: 3 Pods v2 ejecutándose

DOWNTIME: ~10 segundos</pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_3_1_5_rollback_de_deployments">3.1.5. 3.1.5 Rollback de Deployments</h4>
<div class="paragraph">
<p>Kubernetes guarda un historial de todas las versiones del Deployment.</p>
</div>
<div class="paragraph">
<p><strong>Ver historial:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver todas las revisiones
kubectl rollout history deployment/nginx-deployment

# Salida:
# REVISION  CHANGE-CAUSE
# 1         kubectl apply --filename=deployment.yaml
# 2         kubectl set image deployment/nginx-deployment nginx=nginx:1.22
# 3         kubectl set image deployment/nginx-deployment nginx=nginx:1.23-broken

# Ver detalles de una revisión
kubectl rollout history deployment/nginx-deployment --revision=2</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Revertir a versión anterior:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Revertir a la versión anterior
kubectl rollout undo deployment/nginx-deployment

# Revertir a una versión específica
kubectl rollout undo deployment/nginx-deployment --to-revision=2

# Ver progreso del rollback
kubectl rollout status deployment/nginx-deployment</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Configurar límite de revisiones a guardar:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  revisionHistoryLimit: 10  # Guardar últimas 10 versiones
  replicas: 3
  # ... resto del spec</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_1_6_casos_de_uso">3.1.6. 3.1.6 Casos de Uso</h4>
<div class="paragraph">
<p><strong>Aplicaciones Web Stateless:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">- Nginx, Apache
- APIs REST
- Frontends</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Microservicios:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">- Cada microservicio como un Deployment
- Escalado independiente
- Actualizaciones independientes</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Batch Processing (para aplicaciones que pueden escalar):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">- Workers de procesamiento
- Scraping distribuido</code></pre>
</div>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_3_2_replicasets">3.2. 3.2 ReplicaSets</h3>
<div class="sect3">
<h4 id="_3_2_1_qué_es_un_replicaset">3.2.1. 3.2.1 ¿Qué es un ReplicaSet?</h4>
<div class="paragraph">
<p>Un <strong>ReplicaSet</strong> es un controlador de bajo nivel que <strong>garantiza que un número específico de Pods idénticos está en ejecución</strong>.</p>
</div>
<div class="paragraph">
<p><strong>Responsabilidades:</strong>
- Crear/eliminar Pods para mantener el número deseado
- Monitorear la salud de los Pods
- Reiniciar Pods fallidos</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_2_2_diferencia_con_deployment">3.2.2. 3.2.2 Diferencia con Deployment</h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Aspecto</th>
<th class="tableblock halign-left valign-top">ReplicaSet</th>
<th class="tableblock halign-left valign-top">Deployment</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nivel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Bajo nivel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alto nivel</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Gestión</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Directa</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Indirecta (via Deployment)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Actualización</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No tiene mecanismo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Rolling/Recreate updates</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Historial</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No guarda</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sí (revisionHistoryLimit)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Rollback</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Manual</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Automático</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uso recomendado</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Raramente directo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Siempre</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Regla de Oro:</strong> Casi nunca creas ReplicaSets directamente. Los Deployments los crean automáticamente.</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_2_3_yaml_de_replicaset">3.2.3. 3.2.3 YAML de ReplicaSet</h4>
<div class="paragraph">
<p><strong>Estructura:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-replicaset
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ver ReplicaSets creadas por Deployments:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver todos los ReplicaSets
kubectl get replicasets

# Salida:
# NAME                            DESIRED   CURRENT   READY
# nginx-deployment-5d4d4d4d4d     3         3         3
# nginx-deployment-7a8a8a8a8a     0         0         0  (versión anterior)

# El Deployment crea ReplicaSets automáticamente
# y las gestiona según la estrategia de actualización

# Ver relación
kubectl get deployment nginx-deployment -o yaml | grep -A 20 "spec:"

# Ver Pods creados por ReplicaSet
kubectl get pods -l app=nginx</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_2_4_manejo_de_replicas">3.2.4. 3.2.4 Manejo de Replicas</h4>
<div class="paragraph">
<p><strong>Escalar ReplicaSet directamente (no recomendado):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Si editas el ReplicaSet directamente
kubectl scale replicaset nginx-replicaset --replicas=5

# El Deployment lo revierte (si lo controla)
# Por eso es mejor escalar el Deployment
kubectl scale deployment nginx-deployment --replicas=5</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_2_5_labels_y_selectors">3.2.5. 3.2.5 Labels y Selectors</h4>
<div class="paragraph">
<p>Los ReplicaSets usan <strong>selectors</strong> para identificar qué Pods deben gestionar.</p>
</div>
<div class="paragraph">
<p><strong>Tipos de Selectors:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># matchLabels: Coincidencia exacta
selector:
  matchLabels:
    app: nginx
    version: v1

# matchExpressions: Más flexibilidad
selector:
  matchExpressions:
  - key: app
    operator: In
    values: [nginx, apache]
  - key: environment
    operator: NotIn
    values: [test]
  - key: release
    operator: Exists

# Operadores disponibles:
# In, NotIn, Exists, DoesNotExist</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: complex-rs
spec:
  replicas: 3
  selector:
    matchExpressions:
    - key: tier
      operator: In
      values:
      - frontend
      - backend
    - key: environment
      operator: NotIn
      values:
      - test
  template:
    metadata:
      labels:
        tier: frontend
        environment: production
        version: v1
    spec:
      containers:
      - name: app
        image: myapp:1.0</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_3_3_statefulsets">3.3. 3.3 StatefulSets</h3>
<div class="sect3">
<h4 id="_3_3_1_diferencias_con_deployments">3.3.1. 3.3.1 Diferencias con Deployments</h4>
<div class="paragraph">
<p><strong>Deployments</strong> asumen que Pods son <strong>intercambiables</strong> (stateless).
<strong>StatefulSets</strong> están diseñados para aplicaciones con <strong>estado persistente</strong>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Aspecto</th>
<th class="tableblock halign-left valign-top">Deployment</th>
<th class="tableblock halign-left valign-top">StatefulSet</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Identidad de Pods</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Efímera, intercambiable</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Estable, única</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nombres de Pods</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Aleatorio (nginx-5d&#8230;&#8203;)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ordenado (mysql-0, mysql-1, mysql-2)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DNS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A través de Service</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">DNS predecible para cada Pod</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Almacenamiento</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Compartido</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dedicado a cada Pod</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Orden de inicio</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Paralelo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Secuencial (por defecto)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Casos de uso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Web apps, APIs</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Bases de datos, colas</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>¿Por qué StatefulSets?</strong></p>
</div>
<div class="paragraph">
<p>Imagina una base de datos con 3 nodos:
- Con Deployment: Los nombres cambian, rompe la replicación
- Con StatefulSet: <code>postgres-0</code>, <code>postgres-1</code>, <code>postgres-2</code> (siempre)</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_3_2_identidades_estables">3.3.2. 3.3.2 Identidades Estables</h4>
<div class="paragraph">
<p><strong>Nombres ordenados:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Con Deployment:
kubectl get pods
# nginx-deployment-5d4d... (nombre aleatorio)
# nginx-deployment-7a8a... (nombre aleatorio)

# Con StatefulSet:
kubectl get pods
# mysql-0
# mysql-1
# mysql-2
# (Siempre los mismos nombres)</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>DNS predecible:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Puedes confiar en estos nombres:
# mysql-0.mysql-headless.default.svc.cluster.local
# mysql-1.mysql-headless.default.svc.cluster.local
# mysql-2.mysql-headless.default.svc.cluster.local</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_3_3_almacenamiento_persistente">3.3.3. 3.3.3 Almacenamiento Persistente</h4>
<div class="paragraph">
<p><strong>VolumeClaimTemplates:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql-statefulset
spec:
  serviceName: mysql-headless
  replicas: 3
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - name: mysql
        image: mysql:5.7
        ports:
        - containerPort: 3306
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: password
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql

  # Clave para StatefulSets: volumeClaimTemplates
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "fast"
      resources:
        requests:
          storage: 10Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Resultado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">Se crean automáticamente:
- mysql-0 con PVC: data-mysql-0 (10Gi)
- mysql-1 con PVC: data-mysql-1 (10Gi)
- mysql-2 con PVC: data-mysql-2 (10Gi)

Cada uno con su almacenamiento dedicado.</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_3_3_4_orden_de_escalado">3.3.4. 3.3.4 Orden de Escalado</h4>
<div class="paragraph">
<p><strong>Creación (secuencial):</strong>
[source,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>1. Crear mysql-0 → esperar a listo
2. Crear mysql-1 → esperar a listo
3. Crear mysql-2 → esperar a listo</pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Eliminación (inverso):</strong>
[source,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>1. Eliminar mysql-2
2. Eliminar mysql-1
3. Eliminar mysql-0</pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Configurar orden de inicio:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">spec:
  podManagementPolicy: Parallel  # Paralelo (por defecto: OrderedReady)
  # OrderedReady: Espera a que cada Pod esté listo
  # Parallel: Crea todos en paralelo</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_3_5_casos_de_uso">3.3.5. 3.3.5 Casos de Uso</h4>
<div class="paragraph">
<p><strong>Bases de Datos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">- MySQL con replicación
- PostgreSQL con replicación
- MongoDB con replica sets</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Colas de Mensajes:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">- Kafka brokers (ordenados)
- RabbitMQ nodes</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Almacenamiento Distribuido:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">- Elasticsearch nodes
- Cassandra nodes
- HDFS datanodes</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Aplicaciones de Juegos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">- Game servers que necesitan identidad estable
- Session storage ordenado</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_3_3_6_yaml_completo_statefulset_de_postgresql">3.3.6. 3.3.6 YAML Completo: StatefulSet de PostgreSQL</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-config
data:
  postgresql.conf: |
    shared_buffers = 256MB
    max_connections = 100

---
apiVersion: v1
kind: Secret
metadata:
  name: postgres-secret
type: Opaque
stringData:
  password: "secure-password-123"

---
apiVersion: v1
kind: Service
metadata:
  name: postgres-headless
spec:
  clusterIP: None  # Headless service
  selector:
    app: postgres
  ports:
  - name: postgres
    port: 5432
    targetPort: 5432

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres-headless
  replicas: 3
  selector:
    matchLabels:
      app: postgres

  template:
    metadata:
      labels:
        app: postgres
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - postgres
            topologyKey: kubernetes.io/hostname

      initContainers:
      - name: init-chmod
        image: busybox
        command: ['chmod', '700', '/var/lib/postgresql/data']
        volumeMounts:
        - name: data
          mountPath: /var/lib/postgresql/data

      containers:
      - name: postgres
        image: postgres:13
        ports:
        - containerPort: 5432
          name: postgres

        env:
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata

        resources:
          requests:
            cpu: 250m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi

        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - pg_isready -U postgres
          initialDelaySeconds: 30
          periodSeconds: 10

        readinessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - pg_isready -U postgres
          initialDelaySeconds: 5
          periodSeconds: 10

        volumeMounts:
        - name: data
          mountPath: /var/lib/postgresql/data
        - name: config
          mountPath: /etc/postgresql

      volumes:
      - name: config
        configMap:
          name: postgres-config

  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "standard"
      resources:
        requests:
          storage: 20Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_3_4_daemonsets">3.4. 3.4 DaemonSets</h3>
<div class="sect3">
<h4 id="_3_4_1_concepto_de_daemonset">3.4.1. 3.4.1 Concepto de DaemonSet</h4>
<div class="paragraph">
<p>Un <strong>DaemonSet</strong> asegura que <strong>cada nodo en el cluster tenga exactamente una copia de un Pod</strong>.</p>
</div>
<div class="paragraph">
<p><strong>Característica clave:</strong> Si agregas nuevos nodos, el DaemonSet automáticamente crea Pods en ellos.</p>
</div>
<div class="paragraph">
<p>[source,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>┌─────────────────────────────────────────┐
│  CLUSTER KUBERNETES                     │
├─────────────────┬───────────────┬───────┤
│   NODO 1        │   NODO 2      │ NODO 3│
│                 │               │       │
│  ┌───────────┐  │ ┌───────────┐ │ ┌───┐ │
│  │ Pod-v1    │  │ │ Pod-v2    │ │ │Pod││
│  └───────────┘  │ └───────────┘ │ └───┘ │
└─────────────────┴───────────────┴───────┘

1 Pod por nodo (exactamente)</pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_4_2_casos_de_uso">3.4.2. 3.4.2 Casos de Uso</h4>
<div class="paragraph">
<p><strong>Monitoreo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">- Recolector de métricas (node-exporter para Prometheus)
- Recolector de logs (Fluentd, Logstash)
- APM agents</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Mantenimiento:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">- Limpieza de disco
- Sincronización de datos
- Actualizaciones de sistema</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Networking:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">- CNI plugins (Flannel, Calico)
- Ingress controller local
- Network proxies</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Seguridad:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">- Antivirus
- Firewall local
- RBAC enforcers</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_3_4_3_yaml_de_daemonset">3.4.3. 3.4.3 YAML de DaemonSet</h4>
<div class="paragraph">
<p><strong>Ejemplo: Node Exporter (Prometheus)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-exporter
  namespace: monitoring
  labels:
    app: node-exporter
spec:
  selector:
    matchLabels:
      app: node-exporter

  # Política de actualización
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1

  template:
    metadata:
      labels:
        app: node-exporter
    spec:
      # Permitir ejecutarse en nodos del control plane (master)
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      - key: node-role.kubernetes.io/control-plane
        effect: NoSchedule

      hostNetwork: true         # Acceso a red del nodo
      hostPID: true             # Acceso a PID del nodo

      containers:
      - name: node-exporter
        image: prom/node-exporter:latest
        args:
        - --path.procfs=/host/proc
        - --path.rootfs=/rootfs
        - --path.sysfs=/host/sys
        - --collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)

        ports:
        - containerPort: 9100
          name: metrics

        resources:
          requests:
            cpu: 100m
            memory: 64Mi
          limits:
            cpu: 200m
            memory: 128Mi

        volumeMounts:
        - name: proc
          mountPath: /host/proc
          readOnly: true
        - name: sys
          mountPath: /host/sys
          readOnly: true
        - name: rootfs
          mountPath: /rootfs
          readOnly: true

      volumes:
      - name: proc
        hostPath:
          path: /proc
      - name: sys
        hostPath:
          path: /sys
      - name: rootfs
        hostPath:
          path: /</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_4_4_monitoreo_con_daemonsets">3.4.4. 3.4.4 Monitoreo con DaemonSets</h4>
<div class="paragraph">
<p><strong>Ver DaemonSets:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Listar DaemonSets
kubectl get daemonsets

# Ver detalles
kubectl describe daemonset node-exporter

# Ver Pods creados por DaemonSet
kubectl get pods -l app=node-exporter

# Salida: Un Pod por nodo
# node-exporter-xxxxx (en nodo-1)
# node-exporter-yyyyy (en nodo-2)
# node-exporter-zzzzz (en nodo-3)

# Escalar (no aplica para DaemonSets)
# Los Pods se crean automáticamente según nodos disponibles</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_4_5_logging_centralizado_con_fluentd">3.4.5. 3.4.5 Logging Centralizado con Fluentd</h4>
<div class="paragraph">
<p><strong>Ejemplo: DaemonSet de Fluentd</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: logging
data:
  fluent.conf: |
    &lt;source&gt;
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/containers/*.log.pos
      tag kubernetes.*
      read_from_head true
      &lt;parse&gt;
        @type json
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      &lt;/parse&gt;
    &lt;/source&gt;

    &lt;match **&gt;
      @type elasticsearch
      @id output_elasticsearch
      @log_level info
      include_tag_key true
      host elasticsearch-service
      port 9200
      path _bulk
      &lt;buffer&gt;
        @type file
        path /var/log/fluentd-buffers/kubernetes.system.buffer
        flush_mode interval
        retry_type exponential_backoff
        flush_interval 5s
        retry_forever
        retry_max_interval 30
        retry_max_times 18
      &lt;/buffer&gt;
    &lt;/match&gt;

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: logging
  labels:
    app: fluentd
spec:
  selector:
    matchLabels:
      app: fluentd

  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1

  template:
    metadata:
      labels:
        app: fluentd
    spec:
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule

      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch-service"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        - name: FLUENT_ELASTICSEARCH_LOGSTASH_PREFIX
          value: "logstash"

        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: config
          mountPath: /fluentd/etc/fluent.conf
          subPath: fluent.conf
        - name: buffer
          mountPath: /var/log/fluentd-buffers

      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: config
        configMap:
          name: fluentd-config
      - name: buffer
        emptyDir: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_3_5_jobs_y_cronjobs">3.5. 3.5 Jobs y CronJobs</h3>
<div class="sect3">
<h4 id="_3_5_1_jobs_ejecución_única">3.5.1. 3.5.1 Jobs: Ejecución Única</h4>
<div class="paragraph">
<p>Un <strong>Job</strong> crea Pods que ejecutan una tarea hasta completarse exitosamente, luego se detienen.</p>
</div>
<div class="paragraph">
<p><strong>Diferencias con Deployments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Aspecto</th>
<th class="tableblock halign-left valign-top">Deployment</th>
<th class="tableblock halign-left valign-top">Job</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Duración</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Indefinida</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hasta completarse</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reinicio fallido</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sí, forever</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configurable</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Exitoso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No existe ese concepto</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sí (exit 0)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Servicios siempre activos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Tareas únicas</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>YAML de Job:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: batch/v1
kind: Job
metadata:
  name: data-processing-job
spec:
  # Número de Pods que deben completarse exitosamente
  completions: 1

  # Número de Pods paralelos
  parallelism: 1

  # Tiempo máximo para completar el Job (segundos)
  activeDeadlineSeconds: 3600

  # Política de reinicio si falla
  backoffLimit: 3

  # Tiempo de retención después de completar
  ttlSecondsAfterFinished: 3600

  template:
    metadata:
      labels:
        app: data-processor
    spec:
      restartPolicy: Never  # Never, OnFailure, Always

      containers:
      - name: processor
        image: data-processor:1.0
        args:
        - --input=/data/input.csv
        - --output=/data/output.csv
        - --format=parquet

        volumeMounts:
        - name: data
          mountPath: /data

      volumes:
      - name: data
        hostPath:
          path: /mnt/data</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Gestión de Jobs:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear Job
kubectl apply -f job.yaml

# Ver Jobs
kubectl get jobs

# Ver detalles
kubectl describe job data-processing-job

# Ver Pods del Job
kubectl get pods --selector=job-name=data-processing-job

# Ver logs del Job
kubectl logs job/data-processing-job

# Esperar a que complete
kubectl wait --for=condition=complete job/data-processing-job

# Eliminar Job (mantiene Pods)
kubectl delete job data-processing-job

# Eliminar Job y sus Pods
kubectl delete job data-processing-job --cascade=foreground</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Parámetros importantes:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>completions</code>: Cuántos Pods deben completar exitosamente</p>
</li>
<li>
<p><code>parallelism</code>: Cuántos Pods ejecutar en paralelo</p>
</li>
<li>
<p><code>backoffLimit</code>: Cuántas veces reintentar antes de marcar como fallido</p>
</li>
<li>
<p><code>ttlSecondsAfterFinished</code>: Tiempo antes de limpiar el Job completado</p>
</li>
<li>
<p><code>restartPolicy</code>: Never (no reiniciar), OnFailure (reiniciar si falla), Always (siempre)</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_3_5_2_job_paralelo">3.5.2. 3.5.2 Job Paralelo</h4>
<div class="paragraph">
<p><strong>Procesar trabajo en paralelo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: batch/v1
kind: Job
metadata:
  name: parallel-job
spec:
  # Se necesitan 10 completiones exitosas
  completions: 10

  # Ejecutar 5 Pods en paralelo
  parallelism: 5

  # Reintentar máximo 3 veces
  backoffLimit: 3

  activeDeadlineSeconds: 7200

  template:
    metadata:
      labels:
        app: worker
    spec:
      restartPolicy: OnFailure

      containers:
      - name: worker
        image: worker:1.0
        env:
        - name: JOB_INDEX
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['batch.kubernetes.io/job-completion-index']</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Resultado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">Se crean 5 Pods inicialmente:
Pod-0, Pod-1, Pod-2, Pod-3, Pod-4

Cuando 1 completa, se crea Pod-5 (mantiene 5 en paralelo)
Cuando 2 completa, se crea Pod-6
...hasta 10 completiones totales</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_3_5_3_cronjob_ejecución_programada">3.5.3. 3.5.3 CronJob: Ejecución Programada</h4>
<div class="paragraph">
<p>Un <strong>CronJob</strong> es un Job que se ejecuta según un cronograma.</p>
</div>
<div class="paragraph">
<p><strong>YAML de CronJob:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: batch/v1
kind: CronJob
metadata:
  name: backup-job
spec:
  # Cronograma (formato cron estándar de Unix)
  schedule: "0 2 * * *"  # Todos los días a las 2 AM

  # Zona horaria (opcional)
  timeZone: "America/New_York"

  # Mantener historial de Jobs exitosos
  successfulJobsHistoryLimit: 3

  # Mantener historial de Jobs fallidos
  failedJobsHistoryLimit: 1

  # Política de concurrencia
  concurrencyPolicy: Forbid  # Allow, Forbid, Replace

  # Plazo para ejecutar si se perdió una ejecución
  startingDeadlineSeconds: 300

  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: backup
        spec:
          restartPolicy: OnFailure

          containers:
          - name: backup
            image: backup-tool:1.0
            args:
            - backup
            - --database=postgres
            - --destination=s3://backups/
            - --retention=30d

            env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: aws-secret
                  key: access-key
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: aws-secret
                  key: secret-key</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Sintaxis de Cronograma:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-text" data-lang="text">┌───────────── minuto (0-59)
│ ┌───────────── hora (0-23)
│ │ ┌───────────── día del mes (1-31)
│ │ │ ┌───────────── mes (1-12)
│ │ │ │ ┌───────────── día de la semana (0-6, 0=domingo)
│ │ │ │ │
│ │ │ │ │
* * * * *

Ejemplos:
0 0 * * *   - Medianoche todos los días
0 9 * * 1-5 - 9 AM de lunes a viernes
*/30 * * * * - Cada 30 minutos
0 0 1 * *   - Primer día del mes a medianoche</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Gestión de CronJobs:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear CronJob
kubectl apply -f cronjob.yaml

# Ver CronJobs
kubectl get cronjobs

# Ver detalles
kubectl describe cronjob backup-job

# Ver Jobs generados por CronJob
kubectl get jobs --selector=cronjob=backup-job

# Ver últimas ejecuciones
kubectl get jobs --sort-by=.metadata.creationTimestamp

# Ejecutar manualmente (para testing)
kubectl create job backup-manual --from=cronjob/backup-job

# Ver logs de última ejecución
kubectl logs job/backup-job-xxxxx</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_5_4_manejo_de_fallos">3.5.4. 3.5.4 Manejo de Fallos</h4>
<div class="paragraph">
<p><strong>Política backoffLimit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">spec:
  backoffLimit: 3  # Reintentar 3 veces antes de fallar

  # Tiempo entre reintentos: 1s, 2s, 4s, 8s... (exponencial)
  # hasta backoff.maxDuration (15 minutos)</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Política activeDeadlineSeconds:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">spec:
  activeDeadlineSeconds: 3600  # Máximo 1 hora total de ejecución

  # Si se excede, el Job se marca como fallido</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Política de concurrencia (para CronJobs):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">concurrencyPolicy: Allow    # Múltiples ejecuciones simultáneas (default)
concurrencyPolicy: Forbid   # No ejecutar si anterior aún corre
concurrencyPolicy: Replace  # Cancelar anterior y ejecutar nueva</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_5_5_limpieza_de_jobs_completados">3.5.5. 3.5.5 Limpieza de Jobs Completados</h4>
<div class="paragraph">
<p><strong>Automática con ttlSecondsAfterFinished:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: batch/v1
kind: Job
metadata:
  name: cleanup-job
spec:
  ttlSecondsAfterFinished: 3600  # Limpiar después de 1 hora
  completions: 1
  parallelism: 1

  template:
    metadata:
      labels:
        app: cleanup
    spec:
      restartPolicy: Never

      containers:
      - name: cleanup
        image: busybox:latest
        command: ['sh', '-c', 'echo "Cleaning up..." &amp;&amp; sleep 5']</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Manual:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Eliminar Jobs completados
kubectl delete jobs --field-selector=status.successful=1

# Eliminar Jobs fallidos
kubectl delete jobs --field-selector=status.failed=1

# Eliminar todo
kubectl delete jobs --all</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_3_6_ejemplos_completos">3.6. 3.6 Ejemplos Completos</h3>
<div class="sect3">
<h4 id="_ejemplo_1_deployment_con_todas_las_características">3.6.1. Ejemplo 1: Deployment con Todas las Características</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: production-app
  namespace: production
  labels:
    app: production-app
    version: v1
  annotations:
    description: "Production grade application deployment"
    owner: "platform-team"

spec:
  replicas: 3
  revisionHistoryLimit: 10

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0

  selector:
    matchLabels:
      app: production-app

  template:
    metadata:
      labels:
        app: production-app
        version: v1
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"

    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - production-app
              topologyKey: kubernetes.io/hostname

      containers:
      - name: app
        image: myapp:1.0
        imagePullPolicy: IfNotPresent

        ports:
        - containerPort: 8080
          name: http

        env:
        - name: ENVIRONMENT
          value: production
        - name: LOG_LEVEL
          value: info
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: password

        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi

        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10
          failureThreshold: 3

        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
          failureThreshold: 2

        volumeMounts:
        - name: config
          mountPath: /etc/config
          readOnly: true
        - name: cache
          mountPath: /tmp/cache

      volumes:
      - name: config
        configMap:
          name: app-config
      - name: cache
        emptyDir: {}

      terminationGracePeriodSeconds: 30</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_2_job_de_batch_processing">3.6.2. Ejemplo 2: Job de Batch Processing</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: batch/v1
kind: Job
metadata:
  name: batch-processor
  labels:
    app: batch-processor
spec:
  completions: 100
  parallelism: 10
  backoffLimit: 3
  activeDeadlineSeconds: 7200
  ttlSecondsAfterFinished: 3600

  template:
    metadata:
      labels:
        app: batch-processor
    spec:
      restartPolicy: OnFailure

      initContainers:
      - name: download-data
        image: curl:latest
        command:
        - /bin/sh
        - -c
        - curl https://data.example.com/data.zip -o /data/data.zip
        volumeMounts:
        - name: data
          mountPath: /data

      containers:
      - name: processor
        image: batch-processor:1.0
        args:
        - --input=/data/data.zip
        - --index=$(JOB_COMPLETION_INDEX)
        - --output=/results/result-$(JOB_COMPLETION_INDEX).json

        env:
        - name: JOB_COMPLETION_INDEX
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['batch.kubernetes.io/job-completion-index']

        volumeMounts:
        - name: data
          mountPath: /data
        - name: results
          mountPath: /results

      volumes:
      - name: data
        emptyDir: {}
      - name: results
        hostPath:
          path: /mnt/results</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_3_cronjob_de_backup">3.6.3. Ejemplo 3: CronJob de Backup</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: batch/v1
kind: CronJob
metadata:
  name: daily-backup
  labels:
    app: backup-system
spec:
  schedule: "0 2 * * *"  # 2 AM todos los días
  timeZone: "UTC"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 7
  failedJobsHistoryLimit: 3

  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          serviceAccountName: backup-sa

          containers:
          - name: backup
            image: backup-tool:latest
            args:
            - backup
            - --database=postgres
            - --destination=s3://backups/
            - --encryption=true
            - --retention=30d
            - --notify=slack

            env:
            - name: DB_HOST
              value: postgres.database.svc.cluster.local
            - name: DB_USER
              valueFrom:
                secretKeyRef:
                  name: db-credentials
                  key: username
            - name: DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-credentials
                  key: password
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: access-key
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: secret-key
            - name: SLACK_WEBHOOK
              valueFrom:
                secretKeyRef:
                  name: slack-webhook
                  key: url

            resources:
              requests:
                cpu: 500m
                memory: 512Mi
              limits:
                cpu: 1000m
                memory: 1024Mi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_3_7_comparativa_de_controladores">3.7. 3.7 Comparativa de Controladores</h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Característica</th>
<th class="tableblock halign-left valign-top">Deployment</th>
<th class="tableblock halign-left valign-top">StatefulSet</th>
<th class="tableblock halign-left valign-top">DaemonSet</th>
<th class="tableblock halign-left valign-top">Job</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Propósito</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Apps stateless</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Apps stateful</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Monitoreo/Mantenimiento</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Tareas únicas</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Réplicas</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Escalable</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ordenado</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Un Pod por nodo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configurable</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Identidad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Efímera</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Estable</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Efímera</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Efímera</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Almacenamiento</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Compartido</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dedicado</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Host path</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Temporal</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Actualizaciones</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Rolling/Recreate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Rolling</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">RollingUpdate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N/A</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uso común</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Web, APIs</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">BD, Colas</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Monitoring</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Backups, Procesamiento</p></td>
</tr>
</tbody>
</table>
<hr>
</div>
<div class="sect2">
<h3 id="_3_8_resumen_del_módulo_3">3.8. 3.8 Resumen del Módulo 3</h3>
<div class="paragraph">
<p>En este módulo aprendiste:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Deployments</strong>: Orquestación de Pods stateless, actualizaciones, rollbacks</p>
</li>
<li>
<p><strong>ReplicaSets</strong>: Bajo nivel, gestión de replicas (raramente directo)</p>
</li>
<li>
<p><strong>StatefulSets</strong>: Aplicaciones con estado, identidades estables, almacenamiento dedicado</p>
</li>
<li>
<p><strong>DaemonSets</strong>: Un Pod por nodo, monitoreo, logging centralizado</p>
</li>
<li>
<p><strong>Jobs</strong>: Tareas únicas, batch processing, manejo de fallos</p>
</li>
<li>
<p><strong>CronJobs</strong>: Tareas programadas, backups automáticos, mantenimiento</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Con estos conocimientos, estás listo para aprender sobre <strong>Servicios y Networking</strong> en el Módulo 4.</p>
</div>
<hr>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_4_servicios_y_networking">4. MÓDULO 4: Servicios y Networking</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Los <strong>Servicios</strong> en Kubernetes son abstracciones que definen un conjunto lógico de Pods y cómo acceder a ellos. Sin Servicios, los Pods serían inaccesibles desde otros Pods o desde el exterior.</p>
</div>
<div class="paragraph">
<p><strong>Problema que resuelven los Servicios:</strong>
- Los Pods tienen IPs que cambian constantemente
- Necesitamos una forma estable de acceder a Pods
- Necesitamos balancear carga entre múltiples Pods
- Necesitamos exponer aplicaciones al exterior</p>
</div>
<hr>
<div class="sect2">
<h3 id="_4_1_servicios_basics">4.1. 4.1 Servicios Basics</h3>
<div class="sect3">
<h4 id="_4_1_1_concepto_de_servicio">4.1.1. 4.1.1 Concepto de Servicio</h4>
<div class="paragraph">
<p>Un <strong>Servicio</strong> es un objeto Kubernetes que:
1. Agrupa Pods usando <strong>labels</strong>
2. Asigna un <strong>IP y nombre DNS estable</strong>
3. Proporciona <strong>balanceo de carga</strong> entre Pods
4. Es <strong>independiente de la ubicación</strong> de los Pods</p>
</div>
<div class="paragraph">
<p><strong>Analogía:</strong>
Un Servicio es como un teléfono de atención al cliente:
- Clientes llaman a un número (Servicio)
- El teléfono dirige la llamada a agentes disponibles (Pods)
- Si un agente se va, el sistema redirecciona automáticamente
- Clientes no necesitan saber quién atiende</p>
</div>
<div class="paragraph">
<p><strong>Diagrama Visual:</strong>
[source,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>┌─────────────────────────────────────────────┐
│         KUBERNETES CLUSTER                  │
│                                             │
│  ┌──────────────────────────────────────┐   │
│  │   SERVICE (estable)                  │   │
│  │   IP: 10.0.1.10                      │   │
│  │   DNS: nginx.default.svc.cluster.local
│  └──────┬──────────────────────┬────────┘   │
│         │                      │            │
│    ┌────▼────┐           ┌─────▼────┐     │
│    │ Pod 1   │           │ Pod 2    │     │
│    │ (nginx) │           │ (nginx)  │     │
│    │ 10.1.1.5│           │ 10.1.2.7 │     │
│    └─────────┘           └──────────┘     │
│                                             │
│  Client requests: nginx.default.svc...     │
│  Service elige aleatoriamente Pod 1 o 2   │
└─────────────────────────────────────────────┘</pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_1_2_por_qué_se_necesitan_servicios">4.1.2. 4.1.2 Por Qué se Necesitan Servicios</h4>
<div class="paragraph">
<p><strong>Problema 1: IPs de Pods Cambian</strong></p>
</div>
<div class="paragraph">
<p>Con Pods solos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Pod creado con IP 10.0.0.5
↓
Pod se reinicia
↓
Nueva IP 10.0.0.15
↓
Cliente intenta conectar a 10.0.0.5
↓
❌ Falla</code></pre>
</div>
</div>
<div class="paragraph">
<p>Con Servicios:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Servicio con IP estable 10.0.1.10
↓
Pod 1 falla (10.0.0.5)
↓
Deployment crea Pod 2 (10.0.0.99)
↓
Servicio redirige a Pod 2 automáticamente
↓
✅ Cliente conecta sin cambios</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Problema 2: Balanceo de Carga</strong></p>
</div>
<div class="paragraph">
<p>Sin Servicio:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Cliente debe saber todas las IPs de Pods
→ 10.0.0.5, 10.0.0.7, 10.0.0.9
→ Cliente debe balancear manualmente</code></pre>
</div>
</div>
<div class="paragraph">
<p>Con Servicio:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Cliente conecta a: nginx-service
Servicio distribuye tráfico a todos los Pods
Balanceo automático y transparente</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_1_3_selector_labels">4.1.3. 4.1.3 Selector Labels</h4>
<div class="paragraph">
<p>Los Servicios usan <strong>labels</strong> para identificar qué Pods gestiona.</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx        # ← Busca Pods con este label
    environment: prod # ← Y este
  ports:
  - port: 80
    targetPort: 8080

---
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  labels:
    app: nginx        # ← Coincide con selector
    environment: prod # ← Coincide con selector
    version: v1       # ← No afecta (no está en selector)
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p>El Servicio automáticamente descubre y agrupa todos los Pods con <code>app: nginx</code> y <code>environment: prod</code>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_1_4_endpoints">4.1.4. 4.1.4 Endpoints</h4>
<div class="paragraph">
<p><strong>Endpoints</strong> son los Pods reales que el Servicio mantiene automáticamente.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver Pods que gestiona un Servicio
kubectl get endpoints nginx-service

# Salida:
# NAME              ENDPOINTS
# nginx-service     10.0.0.5:8080,10.0.0.7:8080,10.0.0.9:8080

# Ver con detalles
kubectl describe service nginx-service
# Endpoints: 10.0.0.5:8080, 10.0.0.7:8080, 10.0.0.9:8080

# Ver el objeto Endpoints directamente
kubectl get endpoints
kubectl describe endpoints nginx-service</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Cómo funciona:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">1. Servicio define selector: app=nginx
2. Kubernetes busca Pods con ese label
3. Crea objeto Endpoints con las IPs de Pods
4. kube-proxy usa Endpoints para balanceo de carga
5. Si Pod falla, lo elimina de Endpoints automáticamente
6. Si nuevo Pod nace, lo agrega</code></pre>
</div>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_4_2_tipos_de_servicios">4.2. 4.2 Tipos de Servicios</h3>
<div class="sect3">
<h4 id="_4_2_1_clusterip">4.2.1. 4.2.1 ClusterIP</h4>
<div class="paragraph">
<p><strong>ClusterIP</strong> es el tipo de Servicio por defecto. Proporciona acceso <strong>dentro del cluster</strong>.</p>
</div>
<div class="paragraph">
<p><strong>Características:</strong>
- IP interna (solo accesible desde dentro del cluster)
- DNS: <code>nombre.namespace.svc.cluster.local</code>
- Balanceo de carga automático
- No accesible desde afuera</p>
</div>
<div class="paragraph">
<p><strong>YAML:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: nginx-service
  namespace: default
  labels:
    app: nginx
spec:
  type: ClusterIP        # Por defecto, puede omitirse

  # IP interna específica (opcional, genera una si no se especifica)
  clusterIP: 10.0.1.100

  selector:
    app: nginx

  ports:
  - name: http
    protocol: TCP
    port: 80              # Puerto del Servicio (acceso interno)
    targetPort: 8080      # Puerto del contenedor

  - name: https
    protocol: TCP
    port: 443
    targetPort: 8443

  # SessionAffinity para sticky sessions (opcional)
  sessionAffinity: None   # None, ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Acceso dentro del cluster:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Desde otro Pod, accedes así:
curl http://nginx-service           # En el mismo namespace
curl http://nginx-service:80        # Especificar puerto
curl http://nginx-service.default.svc.cluster.local  # FQDN completo

# Puedes usar variables de entorno:
curl http://$NGINX_SERVICE_HOST:$NGINX_SERVICE_PORT</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo Completo: Frontend a Backend</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend-api
spec:
  replicas: 2
  selector:
    matchLabels:
      app: backend-api
  template:
    metadata:
      labels:
        app: backend-api
    spec:
      containers:
      - name: api
        image: backend:1.0
        ports:
        - containerPort: 5000

---
apiVersion: v1
kind: Service
metadata:
  name: backend-service
spec:
  type: ClusterIP
  selector:
    app: backend-api
  ports:
  - port: 5000
    targetPort: 5000

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 1
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: web
        image: frontend:1.0
        ports:
        - containerPort: 3000
        env:
        - name: BACKEND_URL
          value: "http://backend-service:5000"  # ← Acceso automático

---
apiVersion: v1
kind: Service
metadata:
  name: frontend-service
spec:
  type: NodePort  # Para acceso externo
  selector:
    app: frontend
  ports:
  - port: 3000
    targetPort: 3000
    nodePort: 30000</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_2_2_nodeport">4.2.2. 4.2.2 NodePort</h4>
<div class="paragraph">
<p><strong>NodePort</strong> expone el Servicio en un puerto específico en <strong>cada nodo del cluster</strong>.</p>
</div>
<div class="paragraph">
<p><strong>Características:</strong>
- Crea un ClusterIP internamente
- Expone cada nodo en un puerto (30000-32767)
- Accesible desde fuera del cluster
- Acceso: <code>&lt;nodo-ip&gt;:&lt;nodePort&gt;</code></p>
</div>
<div class="paragraph">
<p><strong>Diagrama:</strong>
[source,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Internet
   │
   ├─ 192.168.1.10:30080 ─────┐
   ├─ 192.168.1.11:30080 ─────┤
   ├─ 192.168.1.12:30080 ─────┤
   │                          │
   └──────────────────────────┘
                │
          NodePort Service
          (redirige al Pod)
                │
         ┌──────┴──────┐
         │              │
      Pod 1 (10.0.0.5)  Pod 2 (10.0.0.7)</pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>YAML:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: web-service
  labels:
    app: web
spec:
  type: NodePort

  selector:
    app: web

  ports:
  - name: http
    protocol: TCP
    port: 80                # Puerto interno
    targetPort: 8080        # Puerto del contenedor
    nodePort: 30080         # Puerto en los nodos (30000-32767)
                            # Si no especificas, K8s elige uno

  # Rango de puertos:
  # - Por defecto: 30000-32767
  # - Configurable en API Server: --service-node-port-range=30000:35000</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Acceso:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Obtener nodos
kubectl get nodes -o wide
# NAME      STATUS  ROLES  ... EXTERNAL-IP   INTERNAL-IP
# master    Ready   ...       203.0.113.10   192.168.1.10
# worker1   Ready   ...       203.0.113.11   192.168.1.11

# Obtener NodePort
kubectl get svc web-service
# NAME          TYPE      PORT(S)        AGE
# web-service   NodePort  80:30080/TCP   5m

# Acceder desde internet
curl http://203.0.113.10:30080  # IP externa del nodo
curl http://192.168.1.10:30080  # IP interna del nodo
curl http://node-hostname:30080 # También funciona

# Los tres nodos sirven el mismo servicio:
curl http://203.0.113.10:30080
curl http://203.0.113.11:30080
curl http://203.0.113.12:30080
# Todas van al mismo Pod (con balanceo)</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Casos de Uso:</strong>
- Desarrollo/testing
- Acceso temporal
- No recomendado para producción (usa LoadBalancer o Ingress)</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_2_3_loadbalancer">4.2.3. 4.2.3 LoadBalancer</h4>
<div class="paragraph">
<p><strong>LoadBalancer</strong> usa un balanceador de carga externo del proveedor cloud para exponer el Servicio.</p>
</div>
<div class="paragraph">
<p><strong>Características:</strong>
- Crea ClusterIP + NodePort + LoadBalancer
- IP externa asignada por el cloud provider
- Acceso directo desde internet
- Recomendado para producción
- Requiere integración con cloud provider</p>
</div>
<div class="paragraph">
<p><strong>Diagrama:</strong>
[source,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Internet (203.0.113.50:80)
          │
     ┌────▼────────┐
     │ Cloud LB    │ ← Balanceador del proveedor
     │ (AWS ELB)   │   (AWS, Google Cloud, Azure, etc.)
     └────┬────────┘
          │
     ┌────┴──────────┐
     │               │
  Node1:30080    Node2:30080   (NodePort)
     │               │
  Pod-1 (5000)   Pod-2 (5000)  (Servicio)</pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>YAML:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: web-lb-service
  namespace: production
  labels:
    app: web
spec:
  type: LoadBalancer

  selector:
    app: web

  ports:
  - name: http
    protocol: TCP
    port: 80              # Puerto externo (en el LB)
    targetPort: 8080      # Puerto del Pod
    nodePort: 30080       # NodePort (generado automáticamente)

  # IP específica para el LoadBalancer (si el cloud lo permite)
  loadBalancerIP: 203.0.113.50

  # Restricción de acceso (si el cloud lo permite)
  loadBalancerSourceRanges:
  - 203.0.113.0/24
  - 198.51.100.0/24

  # Política de tráfico
  externalTrafficPolicy: Local  # Local, Cluster (por defecto)
  # Local: Solo Pods en el nodo que recibe tráfico
  # Cluster: kube-proxy redirecciona entre nodos

  # Session affinity
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Acceso:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver el Servicio LoadBalancer
kubectl get svc web-lb-service
# NAME              TYPE          EXTERNAL-IP    PORT(S)
# web-lb-service    LoadBalancer  203.0.113.50   80:30080/TCP

# Esperar a que el cloud asigne IP (puede tomar minutos)
kubectl get svc web-lb-service --watch

# Acceder
curl http://203.0.113.50:80

# Ver detalles
kubectl describe svc web-lb-service</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo en AWS:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: web-service
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"  # Network Load Balancer
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"
    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: "http"
spec:
  type: LoadBalancer
  selector:
    app: web
  ports:
  - port: 80
    targetPort: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_2_4_externalname">4.2.4. 4.2.4 ExternalName</h4>
<div class="paragraph">
<p><strong>ExternalName</strong> mapea un Servicio a un nombre DNS externo.</p>
</div>
<div class="paragraph">
<p><strong>Características:</strong>
- No proporciona balanceo de carga
- Es un alias DNS
- Útil para integrar servicios externos</p>
</div>
<div class="paragraph">
<p><strong>YAML:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: external-db
  namespace: default
spec:
  type: ExternalName

  # El FQDN del servicio externo
  externalName: postgres.example.com

  # Puertos (opcional)
  ports:
  - port: 5432
    protocol: TCP</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Acceso desde dentro del cluster:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Dentro de cualquier Pod
psql -h external-db -p 5432

# Se resuelve a: postgres.example.com
# Y luego a la IP real</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Caso de Uso: Migración Gradual</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Primero: Todos usan ExternalName que apunta al DB externo
apiVersion: v1
kind: Service
metadata:
  name: database
spec:
  type: ExternalName
  externalName: old-db.example.com
  ports:
  - port: 5432

---
# Luego: Cambias ExternalName a un ClusterIP con StatefulSet
apiVersion: v1
kind: Service
metadata:
  name: database
spec:
  type: ClusterIP
  selector:
    app: postgres
  ports:
  - port: 5432

# Aplicaciones no necesitan cambios, solo cambia el Servicio</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Tabla Comparativa de Tipos:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Tipo</th>
<th class="tableblock halign-left valign-top">Acceso Interno</th>
<th class="tableblock halign-left valign-top">Acceso Externo</th>
<th class="tableblock halign-left valign-top">IP Estable</th>
<th class="tableblock halign-left valign-top">Caso de Uso</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ClusterIP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Inter-Pod communication</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NodePort</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅ (limitado)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Testing, desarrollo</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LoadBalancer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Producción, aplicaciones públicas</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ExternalName</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">❌</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">✅</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Mapeo a servicios externos</p></td>
</tr>
</tbody>
</table>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_4_3_discovery_y_dns">4.3. 4.3 Discovery y DNS</h3>
<div class="sect3">
<h4 id="_4_3_1_kubernetes_dns">4.3.1. 4.3.1 Kubernetes DNS</h4>
<div class="paragraph">
<p><strong>CoreDNS</strong> es el servidor DNS de Kubernetes. Cada cluster tiene un Servicio CoreDNS que resuelve nombres automáticamente.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver CoreDNS en acción
kubectl get pods -n kube-system | grep coredns

# CoreDNS responde a todas las consultas DNS del cluster</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Características:</strong>
- Cada Pod tiene acceso automático al DNS del cluster
- Resolución de nombres de Servicios
- Resolución de Pods individuales
- Caché local
- Forwarding a DNS externos</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_2_nombres_de_dominio_internos">4.3.2. 4.3.2 Nombres de Dominio Internos</h4>
<div class="paragraph">
<p><strong>Estructura FQDN completo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>service-name.namespace.svc.cluster.local</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Niveles:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>service-name        → Nombre del Servicio
namespace           → Namespace donde está
svc                 → Service (tipo de recurso)
cluster.local       → Dominio raíz del cluster</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># En el mismo namespace:
ping nginx-service              # ← Resuelve dentro del namespace
ping nginx-service.default      # ← Con namespace explícito

# Desde otro namespace:
ping nginx-service.production.svc.cluster.local
# ← FQDN completo necesario

# En el namespace default:
curl http://nginx-service:80
# En el namespace kube-system (necesitas FQDN):
curl http://nginx-service.default.svc.cluster.local:80</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>DNS de Pods:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Pod individual:
pod-ip-dash-separated.namespace.pod.cluster.local

# Ejemplo: Pod con IP 10.0.1.5 en namespace default
# 10-0-1-5.default.pod.cluster.local

# Acceso a Pod directo (raro, no recomendado):
curl http://10-0-1-5.default.pod.cluster.local</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_3_búsqueda_de_servicios">4.3.3. 4.3.3 Búsqueda de Servicios</h4>
<div class="paragraph">
<p><strong>Variables de entorno automáticas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Kubernetes inyecta automáticamente variables de entorno
# para cada Servicio en el namespace

env | grep NGINX
# NGINX_SERVICE_HOST=10.0.1.100
# NGINX_SERVICE_PORT=80
# NGINX_SERVICE_PORT_HTTP=80</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo en aplicación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import os

# Método 1: Variables de entorno (más antiguo)
host = os.getenv('NGINX_SERVICE_HOST')
port = os.getenv('NGINX_SERVICE_PORT')

# Método 2: DNS directo (recomendado)
host = 'nginx-service'  # O 'nginx-service.default.svc.cluster.local'
port = 80</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_4_configuración_de_resolución_dns">4.3.4. 4.3.4 Configuración de Resolución DNS</h4>
<div class="paragraph">
<p><strong>Ver configuración DNS en un Pod:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Dentro de un Pod
cat /etc/resolv.conf

# Salida típica:
# nameserver 10.96.0.10          ← IP de CoreDNS
# search default.svc.cluster.local svc.cluster.local cluster.local
# options ndots:5 single-request-tcp</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Explicación:</strong>
- <code>nameserver 10.96.0.10</code>: IP del Servicio CoreDNS
- <code>search</code>: Dominios que buscar automáticamente
- <code>ndots:5</code>: Si hay más de 5 puntos, busca FQDN primero</p>
</div>
<div class="paragraph">
<p><strong>Configurar DNS personalizado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: dns-config-pod
spec:
  dnsPolicy: Default  # Usar DNS del nodo
  dnsConfig:
    nameservers:
    - 8.8.8.8
    - 8.8.4.4
    searches:
    - my.custom.domain
    options:
    - name: ndots
      value: "2"

  containers:
  - name: app
    image: busybox:latest</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_5_headless_services">4.3.5. 4.3.5 Headless Services</h4>
<div class="paragraph">
<p>Un <strong>Headless Service</strong> no asigna ClusterIP. Se usa para aplicaciones que necesitan comunicación directa entre Pods.</p>
</div>
<div class="paragraph">
<p><strong>Cuándo usar:</strong>
- StatefulSets (identidades estables)
- Aplicaciones de máster-esclavo
- Servicios que no necesitan balanceo de carga</p>
</div>
<div class="paragraph">
<p><strong>YAML:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: mysql-headless
spec:
  clusterIP: None  # ← Headless
  selector:
    app: mysql
  ports:
  - port: 3306
    targetPort: 3306

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
spec:
  serviceName: mysql-headless  # ← Vinculado al Headless Service
  replicas: 3
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - name: mysql
        image: mysql:5.7
        ports:
        - containerPort: 3306</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>DNS con Headless Service:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Con ClusterIP normal:
$ nslookup nginx-service
# nginx-service.default.svc.cluster.local → 10.0.1.100 (una IP)

# Con Headless Service:
$ nslookup mysql-headless
# mysql-headless.default.svc.cluster.local → 10.0.0.5
#                                         → 10.0.0.7
#                                         → 10.0.0.9
# (Todas las IPs de Pods)

# Acceso a Pod específico en StatefulSet:
$ nslookup mysql-0.mysql-headless
# mysql-0.mysql-headless.default.svc.cluster.local → 10.0.0.5

# Conexión directa a Pod específico:
mysql -h mysql-0.mysql-headless.default.svc.cluster.local</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_4_4_ingress">4.4. 4.4 Ingress</h3>
<div class="sect3">
<h4 id="_4_4_1_concepto_de_ingress">4.4.1. 4.4.1 Concepto de Ingress</h4>
<div class="paragraph">
<p><strong>Ingress</strong> es un objeto Kubernetes que expone <strong>rutas HTTP/HTTPS</strong> a Servicios dentro del cluster.</p>
</div>
<div class="paragraph">
<p><strong>Problema que resuelve:</strong>
- LoadBalancer crea un LB por Servicio (costoso)
- Ingress permite múltiples Servicios con un LB</p>
</div>
<div class="paragraph">
<p><strong>Analogía:</strong>
- LoadBalancer = Línea telefónica dedicada (costosa)
- Ingress = Centralita que redirecciona llamadas según número</p>
</div>
<div class="paragraph">
<p><strong>Diagrama:</strong>
[source,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Internet
   │
   └─ 203.0.113.50:80
        │
    ┌───▼──────────┐
    │ Ingress      │
    │ Controller   │
    └───┬──────────┘
        │
    ┌───┴──────────────────┐
    │                      │
┌───▼───┐            ┌────▼───┐
│ Service1 (api)    │ Service2 (web)
│ nginx:80          │ frontend:3000
└─────────┘         └────────┘</pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ventajas:</strong>
- Un IP/hostname para múltiples servicios
- Enrutamiento basado en ruta y host
- HTTPS/TLS centralizado
- Más económico que múltiples LoadBalancers</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_4_2_ingress_controller">4.4.2. 4.4.2 Ingress Controller</h4>
<div class="paragraph">
<p>El <strong>Ingress Controller</strong> implementa las reglas de Ingress. Es un programa que corre en el cluster.</p>
</div>
<div class="paragraph">
<p><strong>Controladores disponibles:</strong>
- <strong>nginx-ingress</strong>: El más popular
- <strong>Traefik</strong>: Moderno, fácil de usar
- <strong>HAProxy</strong>: Robusto
- <strong>AWS ALB Controller</strong>: Para AWS
- <strong>GCE Ingress</strong>: Para Google Cloud</p>
</div>
<div class="paragraph">
<p><strong>Instalación de nginx-ingress:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalación estándar
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.0/deploy/static/provider/cloud/deploy.yaml

# O con Helm
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm install my-ingress ingress-nginx/ingress-nginx \
  --namespace ingress-nginx \
  --create-namespace

# Verificar instalación
kubectl get pods -n ingress-nginx
kubectl get svc -n ingress-nginx</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_4_3_reglas_de_ingress">4.4.3. 4.4.3 Reglas de Ingress</h4>
<div class="paragraph">
<p><strong>YAML Mínimo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: web-ingress
spec:
  ingressClassName: nginx  # Especificar qué controller
  rules:
  - host: example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-service
            port:
              number: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>YAML Completo con Múltiples Servicios:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: multi-service-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/rate-limit: "100"
spec:
  ingressClassName: nginx

  rules:
  # API backend
  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: api-service
            port:
              number: 5000

  # Frontend
  - host: example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-service
            port:
              number: 3000

      # Admin
      - path: /admin
        pathType: Prefix
        backend:
          service:
            name: admin-service
            port:
              number: 8080

  # Ruta por defecto
  - host: any.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: default-service
            port:
              number: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>PathType Explained:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">Exact      - /admin solo coincide /admin, no /admin/
Prefix     - /admin coincide /admin, /admin/, /admin/users
ImplementationSpecific - Depende del Ingress Controller</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_4_4_hosts_virtuales">4.4.4. 4.4.4 Hosts Virtuales</h4>
<div class="paragraph">
<p>Puedes servir diferentes aplicaciones en diferentes hosts con un solo Ingress.</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: vhost-ingress
spec:
  ingressClassName: nginx

  rules:
  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: api-service
            port:
              number: 5000

  - host: www.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-service
            port:
              number: 3000

  - host: admin.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: admin-service
            port:
              number: 8080

  - host: docs.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: docs-service
            port:
              number: 3000</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>DNS debe apuntar a Ingress:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Obtener IP/hostname del Ingress
kubectl get ingress web-ingress

# Salida:
# NAME          CLASS   HOSTS                           ADDRESS       PORTS
# web-ingress   nginx   api.example.com,www.example.com 203.0.113.50  80, 443

# En tu DNS:
api.example.com         → 203.0.113.50
www.example.com         → 203.0.113.50
admin.example.com       → 203.0.113.50
docs.example.com        → 203.0.113.50

# Ingress Controller redirige según Host header</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_4_5_tlsssl">4.4.5. 4.4.5 TLS/SSL</h4>
<div class="paragraph">
<p>Ingress puede terminar conexiones HTTPS usando Secrets.</p>
</div>
<div class="paragraph">
<p><strong>Crear certificado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Generar certificado auto-firmado
openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes \
  -subj "/CN=example.com"

# Crear Secret con certificado
kubectl create secret tls my-tls-secret \
  --cert=cert.pem \
  --key=key.pem</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Usar TLS en Ingress:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: tls-ingress
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  ingressClassName: nginx

  # TLS configuration
  tls:
  - hosts:
    - example.com
    - www.example.com
    secretName: my-tls-secret  # Secret con cert + key

  - hosts:
    - api.example.com
    secretName: api-tls-secret

  # HTTP rules
  rules:
  - host: example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-service
            port:
              number: 80

  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: api-service
            port:
              number: 5000</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Con Let&#8217;s Encrypt automático (require cert-manager):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: admin@example.com
    privateKeySecretRef:
      name: letsencrypt-prod
    solvers:
    - http01:
        ingress:
          class: nginx

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: tls-ingress
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  ingressClassName: nginx

  tls:
  - hosts:
    - example.com
    secretName: example-com-tls  # Se genera automáticamente

  rules:
  - host: example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-service
            port:
              number: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_4_6_path_based_routing">4.4.6. 4.4.6 Path-Based Routing</h4>
<div class="paragraph">
<p>Diferentes Servicios basados en ruta:</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: path-routing
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx

  rules:
  - host: api.example.com
    http:
      paths:
      - path: /v1
        pathType: Prefix
        backend:
          service:
            name: api-v1-service
            port:
              number: 5000

      - path: /v2
        pathType: Prefix
        backend:
          service:
            name: api-v2-service
            port:
              number: 5001

      - path: /admin
        pathType: Prefix
        backend:
          service:
            name: admin-service
            port:
              number: 8080

      - path: /
        pathType: Prefix
        backend:
          service:
            name: default-service
            port:
              number: 5000</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Requests:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>GET api.example.com/v1/users     → api-v1-service
GET api.example.com/v2/users     → api-v2-service
GET api.example.com/admin/users  → admin-service
GET api.example.com/status       → default-service</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_4_7_host_based_routing">4.4.7. 4.4.7 Host-Based Routing</h4>
<div class="paragraph">
<p>Diferentes Servicios basados en hostname:</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: host-routing
spec:
  ingressClassName: nginx

  rules:
  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: api-service
            port:
              number: 5000

  - host: www.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-service
            port:
              number: 3000

  - host: cdn.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: cdn-service
            port:
              number: 9000

  - host: shop.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: shop-service
            port:
              number: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_4_5_network_policies">4.5. 4.5 Network Policies</h3>
<div class="sect3">
<h4 id="_4_5_1_concepto_de_network_policy">4.5.1. 4.5.1 Concepto de Network Policy</h4>
<div class="paragraph">
<p><strong>Network Policy</strong> es un objeto Kubernetes que define reglas de seguridad de red entre Pods.</p>
</div>
<div class="paragraph">
<p><strong>Sin Network Policy:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Todos los Pods pueden comunicarse entre sí
↓
Riesgo de seguridad</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Con Network Policy:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Solo tráfico permitido por reglas
↓
Defensa en profundidad</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_5_2_ingress_rules">4.5.2. 4.5.2 Ingress Rules</h4>
<div class="paragraph">
<p>Define qué Pods pueden <strong>recibir</strong> tráfico.</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo 1: Solo desde namespace específico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: database-network-policy
spec:
  podSelector:
    matchLabels:
      app: database  # Aplica a Pods con este label

  policyTypes:
  - Ingress

  ingress:
  - from:
    - namespaceSelector:  # Solo desde este namespace
        matchLabels:
          name: production
    ports:
    - protocol: TCP
      port: 5432</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo 2: Solo desde Pods específicos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: api-network-policy
spec:
  podSelector:
    matchLabels:
      app: api  # Aplica a API Pods

  policyTypes:
  - Ingress

  ingress:
  - from:
    - podSelector:  # Solo desde Pods con este label
        matchLabels:
          app: frontend  # Todos los frontends en el mismo namespace
    ports:
    - protocol: TCP
      port: 5000

    - podSelector:
        matchLabels:
          role: admin  # O desde Pods admin (en cualquier namespace)
      namespaceSelector:
        matchLabels:
          name: management</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo 3: Múltiples origenes</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: multi-source-policy
spec:
  podSelector:
    matchLabels:
      app: backend

  policyTypes:
  - Ingress

  ingress:
  # Opción 1: Frontend en cualquier lugar
  - from:
    - podSelector:
        matchLabels:
          app: frontend

  # Opción 2: Admin desde namespace management
  - from:
    - namespaceSelector:
        matchLabels:
          name: management
      podSelector:
        matchLabels:
          role: admin

  # Opción 3: Monitoreo desde namespace monitoring
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 9090  # Prometheus</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_5_3_egress_rules">4.5.3. 4.5.3 Egress Rules</h4>
<div class="paragraph">
<p>Define qué Pods pueden <strong>enviar</strong> tráfico.</p>
</div>
<div class="paragraph">
<p><strong>Ejemplo: Backend solo a database y API externa</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: backend-egress-policy
spec:
  podSelector:
    matchLabels:
      app: backend

  policyTypes:
  - Egress

  egress:
  # Permitir a database
  - to:
    - podSelector:
        matchLabels:
          app: database
    ports:
    - protocol: TCP
      port: 5432

  # Permitir a API externa
  - to:
    - namespaceSelector:
        matchLabels:
          name: default
    podSelector:
        matchLabels:
          app: external-api
    ports:
    - protocol: TCP
      port: 443

  # Permitir DNS (necesario para resolver nombres)
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    podSelector:
      matchLabels:
        k8s-app: kube-dns
    ports:
    - protocol: UDP
      port: 53</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_5_4_selección_de_pods">4.5.4. 4.5.4 Selección de Pods</h4>
<div class="paragraph">
<p><strong>PodSelector:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Todos los Pods en el namespace
podSelector: {}

# Pods con label específico
podSelector:
  matchLabels:
    app: nginx

# Pods con múltiples labels
podSelector:
  matchLabels:
    app: nginx
    tier: frontend

# Expresiones (más flexibilidad)
podSelector:
  matchExpressions:
  - key: app
    operator: In
    values: [nginx, apache]</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>NamespaceSelector:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Todos los namespaces
namespaceSelector: {}

# Namespaces con label específico
namespaceSelector:
  matchLabels:
    name: production

# Namespace actual (raro)
namespaceSelector:
  matchLabels:
    kubernetes.io/metadata.name: default</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>IPBlock (por rango IP):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Desde rango IP específico
ipBlock:
  cidr: 203.0.113.0/24
  except:
  - 203.0.113.50  # Excepto esta IP

# A rango IP externo
to:
- ipBlock:
    cidr: 0.0.0.0/0
    except:
    - 10.0.0.0/8  # Excepto red interna</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_5_5_casos_de_uso_de_seguridad">4.5.5. 4.5.5 Casos de Uso de Seguridad</h4>
<div class="paragraph">
<p><strong>Caso 1: Arquitectura de 3 niveles</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Frontend solo recibe desde internet
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: frontend-policy
spec:
  podSelector:
    matchLabels:
      tier: frontend
  policyTypes:
  - Ingress
  ingress:
  - from: []  # Permite de cualquier lugar
    ports:
    - protocol: TCP
      port: 80

---
# API solo recibe desde frontend
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: api-policy
spec:
  podSelector:
    matchLabels:
      tier: api
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tier: frontend
    ports:
    - protocol: TCP
      port: 5000

---
# Database solo recibe desde API
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: database-policy
spec:
  podSelector:
    matchLabels:
      tier: database
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tier: api
    ports:
    - protocol: TCP
      port: 5432</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Caso 2: Deny All, Allow Only Specific (Default Deny)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Denegar todo tráfico de entrada
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-ingress
spec:
  podSelector: {}  # Aplica a todos los Pods
  policyTypes:
  - Ingress

---
# Denegar todo tráfico de salida
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-egress
spec:
  podSelector: {}  # Aplica a todos los Pods
  policyTypes:
  - Egress

---
# Luego permite específicamente
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-frontend
spec:
  podSelector:
    matchLabels:
      app: frontend
  policyTypes:
  - Ingress
  ingress:
  - from: []  # Permite desde cualquier lugar
    ports:
    - protocol: TCP
      port: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Caso 3: Microservicios isolados</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: microservices-isolation
spec:
  podSelector: {}  # Aplicar a todos

  policyTypes:
  - Ingress
  - Egress

  # Permitir solo tráfico desde ServiceMonitor/Prometheus
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring
      podSelector:
        matchLabels:
          app: prometheus
    ports:
    - protocol: TCP
      port: 9090

  # Permitir DNS y servicios internos
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: UDP
      port: 53

  - to:
    - podSelector: {}  # Otros Pods del cluster
    ports:
    - protocol: TCP</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_5_6_debugging_de_network_policies">4.5.6. 4.5.6 Debugging de Network Policies</h4>
<div class="paragraph">
<p><strong>Verificar policies aplicadas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver todas las network policies
kubectl get networkpolicies

# Ver en namespace específico
kubectl get networkpolicies -n production

# Ver detalles
kubectl describe networkpolicy frontend-policy

# Ver en YAML
kubectl get networkpolicy frontend-policy -o yaml

# Verificar tráfico permitido
# Crear Pod de debug
kubectl run -it --rm debug --image=nicolaka/netshoot --restart=Never -- /bin/bash

# Dentro del Pod de debug
curl http://api-service:5000  # ¿Funciona o está bloqueado?</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Verificar si el tráfico está bloqueado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver logs del network plugin (depende del CNI)
# Para Calico:
kubectl logs -n calico-system -l k8s-app=calico-node

# Para Cilium:
kubectl logs -n cilium -l k8s-app=cilium

# Verificar si tráfico es rechazado
kubectl top pods  # Ver uso de red</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_4_6_ejemplos_completos">4.6. 4.6 Ejemplos Completos</h3>
<div class="sect3">
<h4 id="_ejemplo_1_aplicación_web_multiservicio">4.6.1. Ejemplo 1: Aplicación Web Multiservicio</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">---
# Frontend Service
apiVersion: v1
kind: Service
metadata:
  name: frontend-service
  labels:
    app: frontend
spec:
  type: ClusterIP
  selector:
    app: frontend
  ports:
  - port: 3000
    targetPort: 3000

---
# Backend Service (ClusterIP - acceso interno)
apiVersion: v1
kind: Service
metadata:
  name: backend-service
  labels:
    app: backend
spec:
  type: ClusterIP
  selector:
    app: backend
  ports:
  - name: http
    port: 5000
    targetPort: 5000

---
# Database Service (Headless)
apiVersion: v1
kind: Service
metadata:
  name: postgres-headless
spec:
  clusterIP: None
  selector:
    app: postgres
  ports:
  - port: 5432
    targetPort: 5432

---
# Ingress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: web-ingress
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/rate-limit: "100"
spec:
  ingressClassName: nginx

  tls:
  - hosts:
    - example.com
    - api.example.com
    secretName: example-com-tls

  rules:
  - host: example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend-service
            port:
              number: 3000

  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: backend-service
            port:
              number: 5000

---
# Network Policies
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: frontend-policy
spec:
  podSelector:
    matchLabels:
      app: frontend
  policyTypes:
  - Ingress
  ingress:
  - from: []  # De cualquier lugar
    ports:
    - protocol: TCP
      port: 3000

---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: backend-policy
spec:
  podSelector:
    matchLabels:
      app: backend
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend
    ports:
    - protocol: TCP
      port: 5000

---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: database-policy
spec:
  podSelector:
    matchLabels:
      app: postgres
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: backend
    ports:
    - protocol: TCP
      port: 5432</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_2_microservicios_con_múltiples_versiones">4.6.2. Ejemplo 2: Microservicios con múltiples versiones</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">---
# API v1 Service
apiVersion: v1
kind: Service
metadata:
  name: api-v1-service
spec:
  type: ClusterIP
  selector:
    app: api
    version: v1
  ports:
  - port: 5000
    targetPort: 5000

---
# API v2 Service
apiVersion: v1
kind: Service
metadata:
  name: api-v2-service
spec:
  type: ClusterIP
  selector:
    app: api
    version: v2
  ports:
  - port: 5000
    targetPort: 5000

---
# Ingress con path-based routing
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: api-versioning
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
  - host: api.example.com
    http:
      paths:
      - path: /v1
        pathType: Prefix
        backend:
          service:
            name: api-v1-service
            port:
              number: 5000

      - path: /v2
        pathType: Prefix
        backend:
          service:
            name: api-v2-service
            port:
              number: 5000</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_3_loadbalancer_service">4.6.3. Ejemplo 3: LoadBalancer Service</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: web-loadbalancer
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
spec:
  type: LoadBalancer
  selector:
    app: web

  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 8080

  - name: https
    protocol: TCP
    port: 443
    targetPort: 8443

  # Restricción de acceso
  loadBalancerSourceRanges:
  - 203.0.113.0/24
  - 198.51.100.0/24

  # Session persistence
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800

  # External traffic policy
  externalTrafficPolicy: Local  # Evita hop extra</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_4_7_resumen_del_módulo_4">4.7. 4.7 Resumen del Módulo 4</h3>
<div class="paragraph">
<p>En este módulo aprendiste:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Servicios Basics</strong>: Concepto, labels, endpoints</p>
</li>
<li>
<p><strong>Tipos de Servicios:</strong></p>
<div class="ulist">
<ul>
<li>
<p>ClusterIP: Acceso interno</p>
</li>
<li>
<p>NodePort: Acceso externo limitado</p>
</li>
<li>
<p>LoadBalancer: Acceso externo robusto</p>
</li>
<li>
<p>ExternalName: Mapeo DNS</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Discovery y DNS</strong>: Nombres internos, resolución, headless services</p>
</li>
<li>
<p><strong>Ingress</strong>: Enrutamiento HTTP/HTTPS, múltiples servicios, TLS</p>
</li>
<li>
<p><strong>Network Policies</strong>: Control de tráfico entre Pods, seguridad</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Con estos conocimientos, estás listo para aprender sobre <strong>Configuración y Secretos</strong> en el Módulo 5.</p>
</div>
<hr>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_5_configuración_y_secretos">5. MÓDULO 5: Configuración y Secretos</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Los <strong>ConfigMaps</strong> y <strong>Secrets</strong> son objetos de Kubernetes que almacenan datos de configuración. La diferencia principal:
- <strong>ConfigMaps</strong>: Para datos no sensibles (configuración, variables, archivos)
- <strong>Secrets</strong>: Para datos sensibles (contraseñas, tokens, certificados)</p>
</div>
<div class="paragraph">
<p><strong>Principio de 12 Factor Apps:</strong>
Separar configuración de código es una best practice. ConfigMaps y Secrets hacen precisamente esto.</p>
</div>
<hr>
<div class="sect2">
<h3 id="_5_1_configmaps">5.1. 5.1 ConfigMaps</h3>
<div class="sect3">
<h4 id="_5_1_1_qué_es_un_configmap">5.1.1. 5.1.1 ¿Qué es un ConfigMap?</h4>
<div class="paragraph">
<p>Un <strong>ConfigMap</strong> es un objeto Kubernetes que almacena datos de configuración como pares clave-valor.</p>
</div>
<div class="paragraph">
<p><strong>Características:</strong>
- Datos no encriptados
- Máximo 1 MB por ConfigMap
- No debe contener secrets
- Se puede actualizar sin recrear Pods
- Accesible a través de variables de entorno o volúmenes</p>
</div>
<div class="paragraph">
<p><strong>Analogía:</strong>
Un ConfigMap es como un archivo de configuración (config.ini, application.properties) que vive en Kubernetes en lugar de en el Dockerfile.</p>
</div>
<div class="paragraph">
<p><strong>Tipos de datos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>- Valores simples: "production", "5000"
- Archivos: archivos.conf, nginx.conf
- JSON/YAML: Configuraciones estructuradas</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_5_1_2_crear_configmaps">5.1.2. 5.1.2 Crear ConfigMaps</h4>
<div class="sect4">
<h5 id="_método_1_desde_valores_literales">Método 1: Desde Valores Literales</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear ConfigMap simple
kubectl create configmap app-config \
  --from-literal=app.env=production \
  --from-literal=app.port=5000 \
  --from-literal=app.debug=false

# Verificar
kubectl get configmap app-config -o yaml

# Salida:
# apiVersion: v1
# kind: ConfigMap
# metadata:
#   name: app-config
# data:
#   app.env: production
#   app.port: "5000"
#   app.debug: "false"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_método_2_desde_archivos">Método 2: Desde Archivos</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear archivos de configuración
cat &gt; app.conf &lt;&lt; EOF
server {
  listen 80;
  location / {
    proxy_pass http://backend:5000;
  }
}
EOF

cat &gt; database.ini &lt;&lt; EOF
[postgres]
host=postgres.default.svc.cluster.local
port=5432
user=admin
EOF

# Crear ConfigMap desde archivos
kubectl create configmap app-files \
  --from-file=app.conf \
  --from-file=database.ini

# Ver contenido
kubectl get configmap app-files -o yaml

# Salida:
# data:
#   app.conf: |
#     server {
#       listen 80;
#       ...
#     }
#   database.ini: |
#     [postgres]
#     ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_método_3_desde_directorio">Método 3: Desde Directorio</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear directorio con archivos
mkdir config-files
cat &gt; config-files/app.conf &lt;&lt; EOF
app_name=MyApp
version=1.0
EOF
cat &gt; config-files/logging.conf &lt;&lt; EOF
log_level=INFO
log_file=/var/log/app.log
EOF

# Crear ConfigMap desde directorio
kubectl create configmap app-dir-config \
  --from-file=config-files/

# Verifica: Cada archivo es una key
kubectl get configmap app-dir-config -o yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_método_4_declarativo_yaml">Método 4: Declarativo (YAML)</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production
  labels:
    app: myapp
    environment: prod
data:
  # Valores simples
  APP_ENV: production
  APP_PORT: "5000"
  APP_DEBUG: "false"
  LOG_LEVEL: info

  # Archivo de configuración
  nginx.conf: |
    server {
      listen 80;
      server_name _;

      location / {
        proxy_pass http://backend:5000;
        proxy_set_header Host $host;
      }
    }

  # JSON
  database.json: |
    {
      "host": "postgres.default.svc.cluster.local",
      "port": 5432,
      "user": "admin",
      "pool_size": 10
    }

  # YAML
  app.yaml: |
    server:
      port: 5000
      timeout: 30s
    database:
      url: postgres://postgres:5432/mydb
      pool_size: 10</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_5_1_3_usar_configmaps_en_pods">5.1.3. 5.1.3 Usar ConfigMaps en Pods</h4>
<div class="sect4">
<h5 id="_método_1_variables_de_entorno">Método 1: Variables de Entorno</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  APP_ENV: production
  APP_PORT: "5000"
  LOG_LEVEL: info

---
apiVersion: v1
kind: Pod
metadata:
  name: app-pod
spec:
  containers:
  - name: app
    image: myapp:1.0

    # Opción A: Importar una clave específica
    env:
    - name: ENVIRONMENT
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: APP_ENV

    - name: PORT
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: APP_PORT

    # Opción B: Importar todas las claves (más limpio)
    envFrom:
    - configMapRef:
        name: app-config

    # Combinación: Importar todas + override
    envFrom:
    - configMapRef:
        name: app-config
    env:
    - name: CUSTOM_VAR
      value: custom_value  # Sobrescribe si existe</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>En tu aplicación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import os

# Acceder a variables de entorno
environment = os.getenv('APP_ENV')  # 'production'
port = os.getenv('APP_PORT')        # '5000'
log_level = os.getenv('LOG_LEVEL')  # 'info'</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_método_2_volúmenes">Método 2: Volúmenes</h5>
<div class="paragraph">
<p>Montar archivos del ConfigMap como volúmenes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
data:
  nginx.conf: |
    server {
      listen 80;
      location / {
        proxy_pass http://backend:5000;
      }
    }

  mime.types: |
    types {
      text/html html htm;
      text/css css;
      application/javascript js;
    }

---
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
spec:
  containers:
  - name: nginx
    image: nginx:1.21

    ports:
    - containerPort: 80

    # Montar ConfigMap como volumen
    volumeMounts:
    - name: config
      mountPath: /etc/nginx/conf.d
      readOnly: true

    - name: config
      mountPath: /etc/nginx/mime.types
      subPath: mime.types  # Archivo específico
      readOnly: true

  # Definir volumen desde ConfigMap
  volumes:
  - name: config
    configMap:
      name: nginx-config
      # Modo de permisos (octal)
      defaultMode: 0644

      # Mapeo de archivos específicos
      items:
      - key: nginx.conf
        path: default.conf
      - key: mime.types
        path: mime.types</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ventaja:</strong> Los cambios en ConfigMap se reflejan automáticamente (con pequeño delay)</p>
</div>
</div>
<div class="sect4">
<h5 id="_método_3_combinación">Método 3: Combinación</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config-complete
data:
  # Variables simples
  APP_ENV: production
  APP_PORT: "5000"

  # Archivo de configuración
  app.conf: |
    server:
      port: 5000
      workers: 4

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: app
        image: myapp:1.0

        # Variables de entorno desde ConfigMap
        envFrom:
        - configMapRef:
            name: app-config-complete

        # Montar archivos de configuración
        volumeMounts:
        - name: config-files
          mountPath: /etc/app
          readOnly: true

      # Volumen desde ConfigMap
      volumes:
      - name: config-files
        configMap:
          name: app-config-complete</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_5_1_4_actualizar_configmaps">5.1.4. 5.1.4 Actualizar ConfigMaps</h4>
<div class="paragraph">
<p><strong>Opción 1: Imperativa (para testing)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver ConfigMap actual
kubectl get configmap app-config -o yaml

# Editar inline
kubectl patch configmap app-config \
  -p '{"data":{"APP_ENV":"staging"}}'

# Reemplazar completamente
kubectl create configmap app-config \
  --from-literal=APP_ENV=production \
  --dry-run=client -o yaml | kubectl apply -f -

# Editar interactivamente
kubectl edit configmap app-config
# Se abre editor, guardas y aplica</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Opción 2: Declarativa (recomendada)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Editar el YAML
kubectl apply -f configmap.yaml

# Ver cambios
kubectl describe configmap app-config

# Rollout de cambios
kubectl rollout restart deployment app-deployment
# (Causa que los Pods se reinicien y carguen nuevo ConfigMap)</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Importante:</strong> Los cambios en ConfigMap <strong>no reinician Pods automáticamente</strong>. Las variables de entorno se cargan al inicio del Pod, así que necesitas:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Opción 1: Reiniciar Deployment
kubectl rollout restart deployment app-deployment

# Opción 2: Usar volúmenes (cambios automáticos)
# Si montas ConfigMap como volumen, se actualiza sin reinicio
# (pero la aplicación debe recargar el archivo)

# Opción 3: Usar webhooks para detectar cambios
# (herramientas como Reloader)</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_1_5_casos_de_uso">5.1.5. 5.1.5 Casos de Uso</h4>
<div class="paragraph">
<p><strong>Aplicación Web:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">- Configuración de servidor (puerto, workers)
- Niveles de logging
- Timeouts y límites</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Microservicios:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">- Endpoints de otros servicios
- Configuración de caché
- Feature flags</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Aplicación de Base de Datos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">- Parámetros de conexión (no contraseñas)
- Tamaño de pool
- Configuración de replicación</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>DevOps:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">- Archivos de configuración (nginx.conf, apache2.conf)
- Scripts de inicialización
- Archivos de estado</code></pre>
</div>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_5_2_secrets">5.2. 5.2 Secrets</h3>
<div class="sect3">
<h4 id="_5_2_1_qué_es_un_secret">5.2.1. 5.2.1 ¿Qué es un Secret?</h4>
<div class="paragraph">
<p>Un <strong>Secret</strong> es un objeto Kubernetes que almacena datos sensibles como pares clave-valor.</p>
</div>
<div class="paragraph">
<p><strong>Características:</strong>
- Datos encriptados <strong>opcionalmente</strong>
- Base64 encoded por defecto (NO es encriptación)
- Máximo 1 MB por Secret
- Para datos sensibles (contraseñas, tokens, certificados)
- Accesible por variables de entorno o volúmenes</p>
</div>
<div class="paragraph">
<p><strong>⚠️ Advertencia Crítica:</strong>
Base64 NO es encriptación. Cualquiera puede decodificarlo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">echo "cGFzc3dvcmQxMjM=" | base64 -d  # → password123</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Para seguridad real</strong>, necesitas:
- Encriptación en reposo (etcd encryption)
- RBAC restrictivo
- Network policies
- Secret management externo (Vault, AWS Secrets Manager)</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_2_2_tipos_de_secrets">5.2.2. 5.2.2 Tipos de Secrets</h4>
<div class="sect4">
<h5 id="_opaque_genérico">Opaque (Genérico)</h5>
<div class="paragraph">
<p>El tipo más común. Almacena datos arbitrarios.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear desde literal
kubectl create secret generic db-secret \
  --from-literal=username=admin \
  --from-literal=password=secret123

# Crear desde archivo
kubectl create secret generic api-key \
  --from-file=api_key.txt

# Ver (nota: está base64 encoded)
kubectl get secret db-secret -o yaml
# data:
#   password: c2VjcmV0MTIz  # base64
#   username: YWRtaW4=      # base64</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_docker_registry">docker-registry</h5>
<div class="paragraph">
<p>Para conectarse a registros privados de Docker:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear Secret para Docker Hub privado
kubectl create secret docker-registry docker-secret \
  --docker-server=docker.io \
  --docker-username=myuser \
  --docker-password=mypassword \
  --docker-email=user@example.com

# Para un registro personalizado
kubectl create secret docker-registry private-registry \
  --docker-server=docker.mycompany.com:5000 \
  --docker-username=user \
  --docker-password=pass</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Usar en Pod:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-with-private-image
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      # ← Especificar imagen pull secret
      imagePullSecrets:
      - name: docker-secret

      containers:
      - name: app
        image: docker.io/myuser/private-app:1.0
        # Desde registro privado</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_basic_auth">basic-auth</h5>
<div class="paragraph">
<p>Para HTTP Basic Authentication:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear Secret de basic auth
kubectl create secret generic basic-auth \
  --from-literal=username=admin \
  --from-literal=password=secretpassword
  --type=kubernetes.io/basic-auth</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_ssh_auth">ssh-auth</h5>
<div class="paragraph">
<p>Para claves SSH privadas:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear Secret de SSH
kubectl create secret generic ssh-key \
  --from-file=ssh-privatekey=~/.ssh/id_rsa \
  --from-file=ssh-publickey=~/.ssh/id_rsa.pub \
  --type=kubernetes.io/ssh-auth</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_tls">tls</h5>
<div class="paragraph">
<p>Para certificados TLS:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear Secret TLS
kubectl create secret tls my-tls \
  --cert=path/to/cert.pem \
  --key=path/to/key.pem

# Ver estructura
kubectl get secret my-tls -o yaml
# data:
#   tls.crt: LS0tLS1...  (certificado base64)
#   tls.key: LS0tLS1...  (clave privada base64)</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_5_2_3_crear_secrets">5.2.3. 5.2.3 Crear Secrets</h4>
<div class="sect4">
<h5 id="_método_1_imperativo">Método 1: Imperativo</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Simple
kubectl create secret generic my-secret \
  --from-literal=key1=value1 \
  --from-literal=key2=value2

# Desde archivo
kubectl create secret generic file-secret \
  --from-file=config.json

# Desde directorio
kubectl create secret generic dir-secret \
  --from-file=./config/</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_método_2_declarativo_yaml">Método 2: Declarativo (YAML)</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: app-secret
  namespace: production
type: Opaque
data:
  # Base64 encoded (echo -n 'value' | base64)
  username: YWRtaW4=         # admin
  password: cGFzc3dvcmQxMjM=  # password123
  api_key: YWJjZGVmMTIzNDU2  # abcdef123456

---
# Alternativa: stringData (se codifica automáticamente)
apiVersion: v1
kind: Secret
metadata:
  name: app-secret-v2
type: Opaque
stringData:
  # No necesita base64, más legible
  username: admin
  password: password123
  api_key: abcdef123456</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_5_2_4_usar_secrets_en_pods">5.2.4. 5.2.4 Usar Secrets en Pods</h4>
<div class="sect4">
<h5 id="_método_1_variables_de_entorno_2">Método 1: Variables de Entorno</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: db-secret
stringData:
  DB_USER: postgres
  DB_PASSWORD: secret_password
  DB_HOST: postgres.default.svc.cluster.local

---
apiVersion: v1
kind: Pod
metadata:
  name: app-with-secrets
spec:
  containers:
  - name: app
    image: myapp:1.0

    # Opción A: Importar variable específica
    env:
    - name: DATABASE_URL
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: DB_HOST

    - name: DB_USER
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: DB_USER

    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: DB_PASSWORD

    # Opción B: Importar todo (más limpio)
    envFrom:
    - secretRef:
        name: db-secret</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_método_2_volúmenes_2">Método 2: Volúmenes</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: tls-secret
type: tls
data:
  tls.crt: LS0tLS1CRUdJTi...  # certificado
  tls.key: LS0tLS1CRUdJTi...  # clave privada

---
apiVersion: v1
kind: Pod
metadata:
  name: web-server
spec:
  containers:
  - name: nginx
    image: nginx:1.21

    volumeMounts:
    # Montar Secret como volumen
    - name: tls-certs
      mountPath: /etc/tls
      readOnly: true

  volumes:
  - name: tls-certs
    secret:
      secretName: tls-secret
      defaultMode: 0600  # Solo lectura
      items:
      - key: tls.crt
        path: server.crt
      - key: tls.key
        path: server.key</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_método_3_ejemplo_completo">Método 3: Ejemplo Completo</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: app-credentials
  namespace: production
stringData:
  # Base de datos
  DB_HOST: postgres.default.svc.cluster.local
  DB_PORT: "5432"
  DB_USER: app_user
  DB_PASSWORD: "complex_password_123!@#"

  # API
  API_KEY: "sk-1234567890abcdef"
  API_SECRET: "secret_key_xyz"

  # AWS
  AWS_ACCESS_KEY: "AKIAIOSFODNN7EXAMPLE"
  AWS_SECRET_KEY: "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-deployment
  namespace: production
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: app
        image: myapp:1.0

        # Cargar todas las credenciales como variables
        envFrom:
        - secretRef:
            name: app-credentials

        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_5_2_5_seguridad_de_secrets">5.2.5. 5.2.5 Seguridad de Secrets</h4>
<div class="sect4">
<h5 id="_encriptación_en_reposo">Encriptación en Reposo</h5>
<div class="paragraph">
<p>Por defecto, etcd NO encripta Secrets. Para habilitarlo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Editar API Server config
sudo vi /etc/kubernetes/manifests/kube-apiserver.yaml

# Agregar:
spec:
  containers:
  - command:
    - kube-apiserver
    - --encryption-provider-config=/etc/kubernetes/enc/encryption.yaml
    # ... resto de flags

# Crear archivo de configuración
cat &gt; /etc/kubernetes/enc/encryption.yaml &lt;&lt; EOF
apiVersion: apiserver.config.k8s.io/v1
kind: EncryptionConfiguration
resources:
  - resources:
    - secrets
    providers:
    - aescbc:
        keys:
        - name: key1
          secret: $(head -c 32 /dev/urandom | base64)
    - identity: {}
EOF

# Reiniciar API Server
kubectl rollout restart -n kube-system deployment/kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_rbac_restrictivo">RBAC Restrictivo</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: secret-reader
  namespace: production
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get", "list"]
  # Restricción: solo ciertos secrets
  resourceNames: ["app-secret", "api-key"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: read-secrets
  namespace: production
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: secret-reader
subjects:
- kind: ServiceAccount
  name: app-sa
  namespace: production</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_audit_logging">Audit Logging</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver acceso a Secrets
kubectl get events --field-selector involvedObject.kind=Secret

# Ver quién leyó qué Secret
kubectl logs -n kube-system -l component=kube-apiserver \
  | grep "get.*secrets"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_5_2_6_secret_management_externo">5.2.6. 5.2.6 Secret Management Externo</h4>
<div class="paragraph">
<p>Para máxima seguridad, usa Vault o servicios en la nube:</p>
</div>
<div class="paragraph">
<p><strong>Con HashiCorp Vault:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-vault
  annotations:
    vault.hashicorp.com/agent-inject: "true"
    vault.hashicorp.com/role: "app-role"
    vault.hashicorp.com/agent-inject-secret-database: "secret/data/database"
spec:
  containers:
  - name: app
    image: myapp:1.0
    # Los secrets se inyectan desde Vault automáticamente</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Con AWS Secrets Manager:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalar AWS Secrets Manager provider
helm install secrets-provider-aws \
  https://github.com/aws/secrets-store-csi-driver-provider-aws/releases/download/v1.0.r2-gce0ba3f/aws-provider-installer.yaml

# Luego usar en Pods</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_5_3_variables_de_entorno">5.3. 5.3 Variables de Entorno</h3>
<div class="sect3">
<h4 id="_5_3_1_pasar_variables_a_pods">5.3.1. 5.3.1 Pasar Variables a Pods</h4>
<div class="paragraph">
<p><strong>Valores literales:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: env-demo
spec:
  containers:
  - name: app
    image: myapp:1.0
    env:
    - name: APP_ENV
      value: "production"
    - name: LOG_LEVEL
      value: "info"
    - name: DATABASE_URL
      value: "postgres://localhost:5432/mydb"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_3_2_usar_valores_de_objetos">5.3.2. 5.3.2 Usar Valores de Objetos</h4>
<div class="paragraph">
<p><strong>Field References (metadatos del Pod):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: field-ref-demo
spec:
  containers:
  - name: app
    image: myapp:1.0
    env:
    # Nombre del Pod
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name

    # Namespace del Pod
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace

    # IP del Pod
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP

    # IP del nodo
    - name: NODE_IP
      valueFrom:
        fieldRef:
          fieldPath: status.hostIP

    # UID del Pod
    - name: POD_UID
      valueFrom:
        fieldRef:
          fieldPath: metadata.uid

    # Labels del Pod
    - name: POD_LABELS
      valueFrom:
        fieldRef:
          fieldPath: metadata.labels['app']

    # Anotaciones del Pod
    - name: POD_ANNOTATIONS
      valueFrom:
        fieldRef:
          fieldPath: metadata.annotations['owner']</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Resource References (límites de recursos):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: resource-ref-demo
spec:
  containers:
  - name: app
    image: myapp:1.0

    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"
        cpu: "500m"

    env:
    # Límite de CPU
    - name: CONTAINER_CPU_LIMIT
      valueFrom:
        resourceFieldRef:
          containerName: app
          resource: limits.cpu

    # Request de CPU
    - name: CONTAINER_CPU_REQUEST
      valueFrom:
        resourceFieldRef:
          containerName: app
          resource: requests.cpu

    # Límite de memoria
    - name: CONTAINER_MEM_LIMIT
      valueFrom:
        resourceFieldRef:
          containerName: app
          resource: limits.memory

    # Request de memoria
    - name: CONTAINER_MEM_REQUEST
      valueFrom:
        resourceFieldRef:
          containerName: app
          resource: requests.memory</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_3_3_combinación_completa">5.3.3. 5.3.3 Combinación Completa</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  APP_ENV: production
  LOG_LEVEL: info
  WORKERS: "4"

---
apiVersion: v1
kind: Secret
metadata:
  name: db-secret
stringData:
  DB_PASSWORD: secret123

---
apiVersion: v1
kind: Pod
metadata:
  name: complete-env-demo
  labels:
    app: myapp
    tier: backend
  annotations:
    owner: "team-backend"
    description: "Complete environment demo"
spec:
  containers:
  - name: app
    image: myapp:1.0

    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"
        cpu: "500m"

    # 1. Variables literales
    env:
    - name: APP_VERSION
      value: "1.0.0"

    # 2. Desde ConfigMap
    - name: APP_ENV
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: APP_ENV

    - name: LOG_LEVEL
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: LOG_LEVEL

    # 3. Desde Secret
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: DB_PASSWORD

    # 4. Desde metadatos del Pod
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name

    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace

    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP

    # 5. Desde recursos
    - name: MEM_LIMIT
      valueFrom:
        resourceFieldRef:
          containerName: app
          resource: limits.memory

    # 6. O importar todo de una vez
    envFrom:
    - configMapRef:
        name: app-config</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_5_4_image_pull_secrets">5.4. 5.4 Image Pull Secrets</h3>
<div class="sect3">
<h4 id="_5_4_1_registros_privados">5.4.1. 5.4.1 Registros Privados</h4>
<div class="paragraph">
<p>Si tu imagen está en un registro privado, necesitas credenciales.</p>
</div>
<div class="paragraph">
<p><strong>Problema:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>docker pull myregistry.com/myapp:1.0
# Error: unauthorized: authentication required</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Solución:</strong>
Crear un Secret y usarlo en el Pod/Deployment.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_4_2_crear_image_pull_secrets">5.4.2. 5.4.2 Crear Image Pull Secrets</h4>
<div class="paragraph">
<p><strong>Para Docker Hub privado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">kubectl create secret docker-registry dockerhub-secret \
  --docker-server=docker.io \
  --docker-username=myuser \
  --docker-password=mypassword \
  --docker-email=user@example.com

# Verificar
kubectl get secret dockerhub-secret -o yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Para registro privado en Google Cloud:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Obtener credenciales
gcloud auth configure-docker gcr.io

# Crear Secret con archivo
kubectl create secret docker-registry gcr-secret \
  --docker-server=gcr.io \
  --docker-username=_json_key \
  --docker-password="$(cat ~/key.json)" \
  --docker-email=user@example.com</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Para registro privado personalizado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">kubectl create secret docker-registry private-registry-secret \
  --docker-server=registry.mycompany.com:5000 \
  --docker-username=reguser \
  --docker-password=regpassword \
  --docker-email=user@company.com</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Declarativo (YAML):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: docker-registry-secret
type: kubernetes.io/dockercfg
data:
  # Generar: cat ~/.docker/config.json | base64 -w0
  .dockercfg: eyJyZWdpc3RyeS5teWNvbXBhbnkuY29tOjUwMDAiOnsidXNlcm5hbWUiOiJ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_4_3_usar_en_deployments">5.4.3. 5.4.3 Usar en Deployments</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-with-private-image
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      # ← Especificar image pull secret
      imagePullSecrets:
      - name: docker-registry-secret

      containers:
      - name: app
        image: registry.mycompany.com:5000/myapp:1.0
        ports:
        - containerPort: 5000</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Múltiples registros:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">spec:
  imagePullSecrets:
  - name: docker-registry-secret
  - name: gcr-secret
  - name: quay-secret

  containers:
  - name: app
    image: registry.mycompany.com:5000/myapp:1.0

  - name: sidecar
    image: gcr.io/myproject/sidecar:1.0

  - name: logging
    image: quay.io/org/logging:1.0</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_4_4_configuración_por_defecto">5.4.4. 5.4.4 Configuración por Defecto</h4>
<div class="paragraph">
<p>Para evitar especificar <code>imagePullSecrets</code> en cada Deployment:</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Usar en ServiceAccount por defecto</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: ServiceAccount
metadata:
  name: default
  namespace: production
imagePullSecrets:
- name: docker-registry-secret

---
# Ahora todos los Pods en este namespace usan el secret automáticamente
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app
  namespace: production
spec:
  # No necesitas imagePullSecrets aquí
  template:
    spec:
      containers:
      - name: app
        image: registry.mycompany.com:5000/myapp:1.0</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Opción 2: Configurar en todos los namespaces</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Script para crear secret en múltiples namespaces
for ns in production staging development; do
  kubectl create secret docker-registry docker-secret \
    --docker-server=registry.mycompany.com:5000 \
    --docker-username=user \
    --docker-password=pass \
    -n $ns
done</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_5_5_proyección_de_secrets">5.5. 5.5 Proyección de Secrets</h3>
<div class="sect3">
<h4 id="_5_5_1_proyección_de_volúmenes">5.5.1. 5.5.1 Proyección de Volúmenes</h4>
<div class="paragraph">
<p>Proyectar Secrets y ConfigMaps en un solo volumen:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  app.conf: |
    server {
      port = 5000
    }

---
apiVersion: v1
kind: Secret
metadata:
  name: app-secret
stringData:
  api_key: "secret_key_123"
  db_password: "db_pass_123"

---
apiVersion: v1
kind: Pod
metadata:
  name: projected-volume-demo
spec:
  containers:
  - name: app
    image: myapp:1.0

    volumeMounts:
    - name: all-in-one
      mountPath: /etc/app
      readOnly: true

  volumes:
  - name: all-in-one
    projected:
      sources:
      # Incluir ConfigMap
      - configMap:
          name: app-config
          items:
          - key: app.conf
            path: config/app.conf

      # Incluir Secret
      - secret:
          name: app-secret
          items:
          - key: api_key
            path: secrets/api.key
          - key: db_password
            path: secrets/db.pass

      # Incluir Service Account Token
      - serviceAccountToken:
          path: token
          expirationSeconds: 3600

      # Incluir downward API
      - downwardAPI:
          items:
          - path: pod_name
            fieldRef:
              fieldPath: metadata.name
          - path: namespace
            fieldRef:
              fieldPath: metadata.namespace

      # Modo de permisos
      defaultMode: 0444</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Resultado en el Pod:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>/etc/app/
├── config/
│   └── app.conf
├── secrets/
│   ├── api.key
│   └── db.pass
├── token
├── pod_name
└── namespace</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_5_5_2_token_automático_de_service_account">5.5.2. 5.5.2 Token Automático de Service Account</h4>
<div class="paragraph">
<p>Cada Pod obtiene automáticamente un token para autenticarse con la API de Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Dentro de un Pod
cat /var/run/secrets/kubernetes.io/serviceaccount/token
# Retorna JWT token

# Usar para autenticarse
curl -H "Authorization: Bearer $(cat /var/run/secrets/kubernetes.io/serviceaccount/token)" \
  https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT/api/v1/namespaces

# También disponible:
# /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
# /var/run/secrets/kubernetes.io/serviceaccount/namespace</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_5_3_casos_de_uso_complejos">5.5.3. 5.5.3 Casos de Uso Complejos</h4>
<div class="paragraph">
<p><strong>Caso 1: Inicialización con secretos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: init-script
type: Opaque
stringData:
  init.sh: |
    #!/bin/bash
    echo "Initializing with secret"
    API_KEY=$(cat /etc/secrets/api_key)
    # Usar API_KEY

---
apiVersion: v1
kind: Pod
metadata:
  name: init-with-secret
spec:
  initContainers:
  - name: init
    image: busybox:latest
    command: ['/bin/sh']
    args: ['/etc/init/init.sh']
    volumeMounts:
    - name: init-scripts
      mountPath: /etc/init
    - name: app-secrets
      mountPath: /etc/secrets

  containers:
  - name: app
    image: myapp:1.0
    volumeMounts:
    - name: app-secrets
      mountPath: /etc/secrets

  volumes:
  - name: init-scripts
    secret:
      secretName: init-script
      defaultMode: 0755

  - name: app-secrets
    secret:
      secretName: app-secret</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Caso 2: Aplicación multiconfig</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: multi-config-app
spec:
  containers:
  - name: app
    image: myapp:1.0
    volumeMounts:
    - name: configs
      mountPath: /etc/app

  volumes:
  - name: configs
    projected:
      sources:
      # Configuración pública
      - configMap:
          name: public-config
          items:
          - key: default.conf
            path: default.conf
          - key: logging.conf
            path: logging.conf

      # Configuración privada
      - secret:
          name: private-config
          items:
          - key: db.conf
            path: db.conf
          - key: ssl.cert
            path: ssl.cert

      # Service account para API
      - serviceAccountToken:
          path: api_token
          expirationSeconds: 3600</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_5_6_ejemplos_completos">5.6. 5.6 Ejemplos Completos</h3>
<div class="sect3">
<h4 id="_ejemplo_1_aplicación_con_configmap_y_secret">5.6.1. Ejemplo 1: Aplicación con ConfigMap y Secret</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># ConfigMap con configuración pública
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production
data:
  APP_ENV: production
  APP_PORT: "5000"
  LOG_LEVEL: info
  CACHE_TTL: "3600"
  WORKERS: "4"

  app.conf: |
    server {
      port = 5000
      workers = 4
      timeout = 30s
    }

    cache {
      ttl = 3600
      size = 1gb
    }

---
# Secret con datos sensibles
apiVersion: v1
kind: Secret
metadata:
  name: app-secret
  namespace: production
stringData:
  DATABASE_URL: postgres://admin:password@postgres.default.svc.cluster.local:5432/mydb
  API_KEY: sk-1234567890abcdef
  JWT_SECRET: your-secret-key-here
  ENCRYPTION_KEY: 32-character-encryption-key-12345

---
# Deployment usando ConfigMap y Secret
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-deployment
  namespace: production
  labels:
    app: myapp
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0

  selector:
    matchLabels:
      app: myapp

  template:
    metadata:
      labels:
        app: myapp
      annotations:
        prometheus.io/scrape: "true"

    spec:
      containers:
      - name: app
        image: myapp:1.0
        imagePullPolicy: IfNotPresent

        ports:
        - containerPort: 5000
          name: http

        # Cargar todas las variables de configuración
        envFrom:
        - configMapRef:
            name: app-config
        - secretRef:
            name: app-secret

        # Variables adicionales
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName

        # Montar archivos de configuración
        volumeMounts:
        - name: config-files
          mountPath: /etc/app
          readOnly: true
        - name: tmp
          mountPath: /tmp

        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi

        livenessProbe:
          httpGet:
            path: /health
            port: 5000
          initialDelaySeconds: 10
          periodSeconds: 10

        readinessProbe:
          httpGet:
            path: /ready
            port: 5000
          initialDelaySeconds: 5
          periodSeconds: 5

      volumes:
      - name: config-files
        configMap:
          name: app-config
      - name: tmp
        emptyDir: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_2_aplicación_con_registro_privado">5.6.2. Ejemplo 2: Aplicación con Registro Privado</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Secret para Docker Registry
apiVersion: v1
kind: Secret
metadata:
  name: docker-registry-secret
  namespace: production
type: kubernetes.io/dockercfg
data:
  .dockercfg: eyJyZWdpc3RyeS5teWNvbXBhbnkuY29tOjUwMDAiOnsidXNlcm5hbWUiOiJkZXBsb3llciIsInBhc3N3b3JkIjoic2VjdXJlcGFzc3dvcmQiLCJlbWFpbCI6ImFkbWluQG15Y29tcGFueS5jb20ifX0=

---
# ServiceAccount con image pull secret
apiVersion: v1
kind: ServiceAccount
metadata:
  name: app-sa
  namespace: production
imagePullSecrets:
- name: docker-registry-secret

---
# Deployment usando registro privado
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-private-image
  namespace: production
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      # Usar service account con credenciales
      serviceAccountName: app-sa

      containers:
      - name: app
        # Imagen desde registro privado
        image: registry.mycompany.com:5000/myapp:1.0
        imagePullPolicy: Always  # Siempre descargar

        ports:
        - containerPort: 5000</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_3_aplicación_con_certificados_y_secretos">5.6.3. Ejemplo 3: Aplicación con Certificados y Secretos</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Generar certificado
# openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes

apiVersion: v1
kind: Secret
metadata:
  name: app-tls
  namespace: production
type: tls
data:
  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0t...  # cat cert.pem | base64 -w0
  tls.key: LS0tLS1CRUdJTiBQUklWQVRFIEtFWS0tLS0t...  # cat key.pem | base64 -w0

---
# Configuração para HTTPS
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-https-config
  namespace: production
data:
  nginx.conf: |
    server {
      listen 443 ssl;
      server_name _;

      ssl_certificate /etc/tls/tls.crt;
      ssl_certificate_key /etc/tls/tls.key;

      location / {
        proxy_pass http://app:5000;
      }
    }

---
# Pod com HTTPS
apiVersion: v1
kind: Pod
metadata:
  name: secure-app
  namespace: production
spec:
  containers:
  - name: app
    image: myapp:1.0
    ports:
    - containerPort: 5000
    - containerPort: 443

  - name: nginx-proxy
    image: nginx:1.21
    ports:
    - containerPort: 443

    volumeMounts:
    - name: tls-certs
      mountPath: /etc/tls
      readOnly: true
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
      readOnly: true

  volumes:
  - name: tls-certs
    secret:
      secretName: app-tls
      defaultMode: 0600
  - name: nginx-config
    configMap:
      name: app-https-config</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_5_7_best_practices">5.7. 5.7 Best Practices</h3>
<div class="paragraph">
<p><strong>1. Usar Secrets para datos sensibles, ConfigMaps para no sensibles</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ Secret: contraseñas, tokens, certificados
✅ ConfigMap: configuración, archivos, variables</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. No encriptación = no seguridad real</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">❌ Base64 no es encriptación
✅ Habilitar encryption-at-rest en etcd
✅ Usar RBAC restrictivo
✅ Considerar Vault o servicio en la nube</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Usar volúmenes para archivos, variables de entorno para valores</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ Volúmenes: nginx.conf, app.conf
✅ Variables: puerto, timeout, flags</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. No guardar Secrets en Git</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">✅ Git: archivos de Deployment
❌ Git: valores en Secrets
✅ Usar: sealed-secrets, kyverno, policies</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>5. Rotar Secrets regularmente</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Cambiar secretos sin downtime
kubectl patch secret app-secret \
  -p '{"data":{"password":"new_encoded_password"}}'

# Luego reiniciar Deployments
kubectl rollout restart deployment app-deployment</code></pre>
</div>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_5_8_resumen_del_módulo_5">5.8. 5.8 Resumen del Módulo 5</h3>
<div class="paragraph">
<p>En este módulo aprendiste:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>ConfigMaps</strong>: Almacenamiento de configuración no sensible</p>
<div class="ulist">
<ul>
<li>
<p>Crear desde valores, archivos, directorios</p>
</li>
<li>
<p>Usar como variables de entorno o volúmenes</p>
</li>
<li>
<p>Actualizar sin downtime</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Secrets</strong>: Almacenamiento seguro de datos sensibles</p>
<div class="ulist">
<ul>
<li>
<p>Tipos: Opaque, docker-registry, basic-auth, ssh-auth, tls</p>
</li>
<li>
<p>Encriptación (en reposo y en tránsito)</p>
</li>
<li>
<p>RBAC y audit logging</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Variables de Entorno</strong>: Múltiples fuentes</p>
<div class="ulist">
<ul>
<li>
<p>Literales, ConfigMap, Secret</p>
</li>
<li>
<p>Field references (metadatos del Pod)</p>
</li>
<li>
<p>Resource references (límites)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Image Pull Secrets</strong>: Registros privados</p>
<div class="ulist">
<ul>
<li>
<p>Docker Hub privado</p>
</li>
<li>
<p>Registros personalizados</p>
</li>
<li>
<p>Configuración por defecto</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Proyección de Secrets</strong>: Casos avanzados</p>
<div class="ulist">
<ul>
<li>
<p>Múltiples fuentes en un volumen</p>
</li>
<li>
<p>Service Account tokens</p>
</li>
<li>
<p>Inicialización compleja</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>Con estos conocimientos, estás listo para aprender sobre <strong>Storage</strong> en el Módulo 6.</p>
</div>
<hr>
<hr>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_6_storage">6. MÓDULO 6: Storage</h2>
<div class="sectionbody">
<div class="paragraph">
<p>El <strong>almacenamiento persistente</strong> es crítico en Kubernetes. A diferencia de los volúmenes ephemeral (que se pierden cuando el Pod termina), necesitamos datos que persistan.</p>
</div>
<div class="paragraph">
<p><strong>Problema:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Pod A escribe archivo.txt → Pod termina → archivo.txt desaparece</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Solución:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Pod A escribe a PersistentVolume → Pod termina → datos permanecen
Pod B lee datos de PersistentVolume</code></pre>
</div>
</div>
<hr>
<div class="sect2">
<h3 id="_6_1_persistent_volumes_pv">6.1. 6.1 Persistent Volumes (PV)</h3>
<div class="sect3">
<h4 id="_6_1_1_qué_es_un_persistent_volume">6.1.1. 6.1.1 ¿Qué es un Persistent Volume?</h4>
<div class="paragraph">
<p>Un <strong>Persistent Volume (PV)</strong> es un recurso de almacenamiento en el cluster que existe independientemente de los Pods.</p>
</div>
<div class="paragraph">
<p><strong>Características:</strong>
- Ciclo de vida separado del Pod
- Existe en el cluster como objeto
- Accesible por múltiples Pods
- Respaldado por almacenamiento real (disco, nube, NFS, etc)
- Admin crea PVs, usuarios crean PVCs</p>
</div>
<div class="paragraph">
<p><strong>Analogía:</strong>
- Pod = Proceso (temporal)
- PersistentVolume = Disco duro (permanente)
- PersistentVolumeClaim = Solicitud para usar el disco</p>
</div>
<div class="paragraph">
<p><strong>Diagrama de ciclo de vida:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>┌─────────────────────────────────────────────────────────────┐
│  1. ADMIN: Crear PV (recursos físicos)                     │
│     ↓                                                        │
│  2. USUARIO: Crear PVC (solicitud)                         │
│     ↓                                                        │
│  3. BINDING: Kubernetes vincula PVC a PV                   │
│     ↓                                                        │
│  4. POD: Usar PVC en Pod (volumen montado)                 │
│     ↓                                                        │
│  5. LIBERACIÓN: Pod termina, PVC liberado                  │
│     ↓                                                        │
│  6. RECLAMACIÓN: Política decide qué hacer con datos       │
└─────────────────────────────────────────────────────────────┘</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_6_1_2_tipos_de_storage_backends">6.1.2. 6.1.2 Tipos de Storage Backends</h4>
<div class="sect4">
<h5 id="_local_nodo">Local (Nodo)</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: local-pv
spec:
  capacity:
    storage: 10Gi  # Capacidad
  accessModes:
    - ReadWriteOnce  # Un nodo puede escribir
  persistentVolumeReclaimPolicy: Delete

  # Storage local en el nodo
  local:
    path: /mnt/data  # Ruta física en el nodo

  # Especificar qué nodo (obligatorio para local)
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - worker-node-1</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ventajas:</strong> Muy rápido (disco directo)
<strong>Desventajas:</strong> No portátil entre nodos, se pierde si nodo falla</p>
</div>
</div>
<div class="sect4">
<h5 id="_nfs_network_file_system">NFS (Network File System)</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv
spec:
  capacity:
    storage: 50Gi
  accessModes:
    - ReadWriteMany  # Múltiples nodos pueden acceder
    - ReadOnlyMany
  persistentVolumeReclaimPolicy: Retain

  # Storage NFS
  nfs:
    server: nfs-server.example.com  # Servidor NFS
    path: "/data/kubernetes"        # Ruta en servidor NFS</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ventajas:</strong> Compartible entre nodos, fácil de usar
<strong>Desventajas:</strong> Requiere servidor NFS externo, rendimiento variable</p>
</div>
</div>
<div class="sect4">
<h5 id="_iscsi">iSCSI</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: iscsi-pv
spec:
  capacity:
    storage: 100Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete

  # Storage iSCSI (block storage)
  iscsi:
    targetPortal: 192.168.1.100:3260
    iqn: iqn.2020-01.com.example:storage.disk1.sys1.xyz
    lun: 0</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Ventajas:</strong> Block storage, buena performance
<strong>Desventajas:</strong> Requiere infraestructura iSCSI compleja</p>
</div>
</div>
<div class="sect4">
<h5 id="_aws_ebs">AWS EBS</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: ebs-pv
spec:
  capacity:
    storage: 20Gi
  accessModes:
    - ReadWriteOnce
  awsElasticBlockStore:
    volumeID: vol-123abc456def78901  # ID del volumen EBS
    fsType: ext4

---
# En AWS EKS, generalmente usan Storage Classes en lugar de PVs manuales
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: ebs-gp3
provisioner: ebs.csi.aws.com
parameters:
  type: gp3
  size: 20
  iops: 3000
  throughput: 125</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_gcp_gce_persistent_disk">GCP GCE Persistent Disk</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: gce-pv
spec:
  capacity:
    storage: 50Gi
  accessModes:
    - ReadWriteOnce
  gcePersistentDisk:
    pdName: gce-disk-1       # Nombre del disk en GCP
    fsType: ext4</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_azure_disk">Azure Disk</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: azure-pv
spec:
  capacity:
    storage: 30Gi
  accessModes:
    - ReadWriteOnce
  azureDisk:
    kind: Managed
    diskName: azure-disk-1
    diskURI: /subscriptions/.../resourceGroups/.../providers/Microsoft.Compute/disks/azure-disk-1
    fsType: ext4</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_6_1_3_crear_persistent_volumes">6.1.3. 6.1.3 Crear Persistent Volumes</h4>
<div class="paragraph">
<p><strong>Método 1: Desde almacenamiento local</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># En el nodo worker, crear directorio
sudo mkdir -p /mnt/data
sudo chmod 777 /mnt/data
echo "persistentvolume-test" | sudo tee /mnt/data/test.txt

# Crear PV que apunta a ese directorio
cat &gt; local-pv.yaml &lt;&lt; EOF
apiVersion: v1
kind: PersistentVolume
metadata:
  name: local-pv-1
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  local:
    path: /mnt/data
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - worker-node-1
EOF

kubectl apply -f local-pv.yaml

# Verificar
kubectl get pv local-pv-1
# NAME          CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM
# local-pv-1    5Gi        RWO            Delete           Available</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Método 2: Desde NFS externo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Asumiendo que hay servidor NFS en nfs.example.com:/data

cat &gt; nfs-pv.yaml &lt;&lt; EOF
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv-1
spec:
  capacity:
    storage: 100Gi
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  nfs:
    server: nfs.example.com
    path: "/data"
EOF

kubectl apply -f nfs-pv.yaml

# Verificar
kubectl get pv nfs-pv-1</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Método 3: Usando Storage Class (dinámico)</strong></p>
</div>
<div class="paragraph">
<p>Para la mayoría de casos modernos, usas Storage Classes en lugar de crear PVs manualmente.</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_1_4_políticas_de_reclamación">6.1.4. 6.1.4 Políticas de Reclamación</h4>
<div class="paragraph">
<p>Define qué pasa cuando un PVC es liberado:</p>
</div>
<div class="sect4">
<h5 id="_delete_predeterminado">Delete (predeterminado)</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">persistentVolumeReclaimPolicy: Delete</code></pre>
</div>
</div>
<div class="paragraph">
<p>El volumen es eliminado automáticamente cuando PVC es liberado.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># 1. Crear y usar PVC
kubectl apply -f pvc.yaml

# 2. Pod usa el PVC

# 3. Eliminar PVC
kubectl delete pvc my-pvc

# → Automáticamente se elimina el PV
# → Los datos se pierden</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_retain">Retain</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">persistentVolumeReclaimPolicy: Retain</code></pre>
</div>
</div>
<div class="paragraph">
<p>El volumen se mantiene, pero no puede ser reclamado automáticamente.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Después de eliminar PVC:
# - PV existe pero está "Released"
# - No puede ser usado por otro PVC automáticamente
# - Datos se conservan

# Para reutilizar:
kubectl patch pv pv-name -p '{"spec":{"claimRef": null}}'
# Ahora puede ser reclamado por otro PVC</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_recycle_deprecado_usar_delete_o_retain">Recycle (deprecado, usar Delete o Retain)</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">persistentVolumeReclaimPolicy: Recycle</code></pre>
</div>
</div>
<div class="paragraph">
<p>Los datos se borran pero el volumen se reutiliza.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_6_1_5_access_modes">6.1.5. 6.1.5 Access Modes</h4>
<div class="paragraph">
<p>Define cómo múltiples Pods pueden acceder al volumen:</p>
</div>
<div class="paragraph">
<p>| Modo | Símbolo | Significado |
|------|---------|-------------|
| ReadWriteOnce | RWO | Un nodo puede leer y escribir |
| ReadOnlyMany | ROX | Múltiples nodos pueden solo leer |
| ReadWriteMany | RWX | Múltiples nodos pueden leer y escribir |
| ReadWriteOncePod | RWOP | Un Pod puede leer y escribir |</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: multi-node-pv
spec:
  capacity:
    storage: 50Gi

  # Múltiples nodos pueden leer y escribir
  accessModes:
    - ReadWriteMany

  nfs:
    server: nfs.example.com
    path: "/data"

---
# Este PVC solo puede ser montado en un nodo
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: single-node-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi

---
# Este PVC puede ser compartido entre múltiples nodos
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: shared-pvc
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 50Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_6_2_persistentvolumeclaims_pvc">6.2. 6.2 PersistentVolumeClaims (PVC)</h3>
<div class="sect3">
<h4 id="_6_2_1_qué_es_un_persistentvolumeclaim">6.2.1. 6.2.1 ¿Qué es un PersistentVolumeClaim?</h4>
<div class="paragraph">
<p>Un <strong>PersistentVolumeClaim (PVC)</strong> es una solicitud de almacenamiento hecha por un usuario.</p>
</div>
<div class="paragraph">
<p><strong>Relación PV ↔ PVC:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>PersistentVolume (PV)     ← Administrador proporciona
        ↑
        │ vinculado (bound)
        ↓
PersistentVolumeClaim (PVC) ← Usuario solicita
        ↑
        │ usado en
        ↓
Pod/Deployment</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Características:</strong>
- Usuario solicita sin conocer detalles físicos
- Kubernetes busca PV que coincida
- Si no hay PV, espera (o crea dinámicamente con Storage Class)
- Multiple Pods pueden usar mismo PVC (si access mode lo permite)</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_2_2_crear_persistentvolumeclaims">6.2.2. 6.2.2 Crear PersistentVolumeClaims</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-claim
  namespace: default
spec:
  # Access mode debe ser soportado por PV
  accessModes:
    - ReadWriteOnce

  # Storage class (vacío = storage class por defecto)
  # storageClassName: standard

  # Capacidad solicitada
  resources:
    requests:
      storage: 10Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Verificar vinculación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver PVCs
kubectl get pvc
# NAME       STATUS   VOLUME        CAPACITY   ACCESS MODES   STORAGECLASS   AGE
# my-claim   Bound    local-pv-1    5Gi        RWO            -              5m

# Ver detalles
kubectl describe pvc my-claim
# Name:          my-claim
# Namespace:     default
# Status:        Bound
# Volume:        local-pv-1
# Labels:        &lt;none&gt;
# Annotations:   &lt;none&gt;
# Capacity:      5Gi
# Access Modes:  RWO</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_2_3_usar_pvc_en_pods">6.2.3. 6.2.3 Usar PVC en Pods</h4>
<div class="paragraph">
<p><strong>Método Simple:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-with-storage
spec:
  containers:
  - name: app
    image: nginx:1.21

    # Montar el volumen
    volumeMounts:
    - name: storage
      mountPath: /data

  # Referencia al PVC
  volumes:
  - name: storage
    persistentVolumeClaim:
      claimName: my-claim</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Uso en Deployment:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: app-storage
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-with-pvc
spec:
  replicas: 1  # Solo 1 con ReadWriteOnce
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: app
        image: myapp:1.0

        volumeMounts:
        - name: app-data
          mountPath: /data

        # Escribir datos
        command: ["/bin/sh"]
        args:
          - -c
          - |
            while true; do
              echo "Data written at $(date)" &gt;&gt; /data/output.log
              sleep 10
            done

      volumes:
      - name: app-data
        persistentVolumeClaim:
          claimName: app-storage</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_2_4_estados_de_pvc">6.2.4. 6.2.4 Estados de PVC</h4>
<div class="paragraph">
<p>| Estado | Significado |
|--------|-------------|
| Pending | Esperando PV disponible |
| Bound | Vinculado a un PV |
| Lost | El PV fue eliminado |</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># PVC en estado Pending (no hay PV disponible)
kubectl get pvc
# NAME           STATUS    VOLUME   CAPACITY   AGE
# waiting-pvc    Pending            -          2m

# Ver por qué está pendiente
kubectl describe pvc waiting-pvc
# Events:
#   Type    Reason         Message
#   Normal  FailedBinding  no persistent volumes available</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_6_3_storage_classes">6.3. 6.3 Storage Classes</h3>
<div class="sect3">
<h4 id="_6_3_1_qué_es_un_storage_class">6.3.1. 6.3.1 ¿Qué es un Storage Class?</h4>
<div class="paragraph">
<p>Un <strong>Storage Class</strong> define cómo el sistema <strong>provisiona automáticamente</strong> volúmenes.</p>
</div>
<div class="paragraph">
<p><strong>Flujo sin Storage Class:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>1. Admin crea PV manualmente → 2. Usuario crea PVC → 3. Vinculación
(lento, manual, limitado)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Flujo con Storage Class:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>1. Usuario crea PVC → 2. Storage Class provisiona PV automáticamente
(rápido, dinámico, escalable)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Características:</strong>
- Provisioning dinámico
- Parámetros personalizables por backend
- Automático para cada PVC
- Escalable y cloud-native</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_3_2_storage_classes_en_diferentes_clouds">6.3.2. 6.3.2 Storage Classes en Diferentes Clouds</h4>
<div class="sect4">
<h5 id="_aws_eks">AWS EKS</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Storage Class para AWS EBS
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: ebs-gp3
provisioner: ebs.csi.aws.com
parameters:
  # Tipo de volumen
  type: gp3

  # Tamaño
  size: "20"

  # IOPS (entrada/salida por segundo)
  iops: "3000"

  # Throughput (MB/s)
  throughput: "125"

  # Encriptación
  encrypted: "true"

  # Zona de disponibilidad
  # availabilityZone: us-east-1a

volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
reclaimPolicy: Delete

---
# Usar en PVC
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: aws-data
spec:
  storageClassName: ebs-gp3
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_google_gke">Google GKE</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: gce-pd-ssd
provisioner: pd.csi.storage.gke.io
parameters:
  # Tipo de disco
  type: pd-ssd

  # Zona
  # replication-type: regional-pd  # Para replicación multi-zona

volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
reclaimPolicy: Delete

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: gcp-data
spec:
  storageClassName: gce-pd-ssd
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_azure_aks">Azure AKS</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: azure-disk-premium
provisioner: disk.csi.azure.com
parameters:
  # SKU del disco
  skuName: Premium_LRS

  # LocationConstraint: Para zonas específicas
  # cachingmode: ReadWrite

volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
reclaimPolicy: Delete

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: azure-data
spec:
  storageClassName: azure-disk-premium
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 30Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_nfs_local_minikubeon_premises">NFS Local (Minikube/On-Premises)</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: nfs-provisioner
provisioner: nfs-provisioner/nfs
parameters:
  # Servidor NFS
  server: nfs.example.com
  # Ruta en servidor
  path: "/data/kubernetes"

allowVolumeExpansion: true
reclaimPolicy: Retain
volumeBindingMode: Immediate

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-data
spec:
  storageClassName: nfs-provisioner
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 100Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_6_3_3_storage_class_predeterminado">6.3.3. 6.3.3 Storage Class Predeterminado</h4>
<div class="paragraph">
<p>Cada cluster tiene un Storage Class por defecto:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver Storage Classes
kubectl get storageclass
# NAME                    PROVISIONER             RECLAIM POLICY   VOLUME BINDING MODE
# standard (default)      kubernetes.io/aws-ebs   Delete           Immediate
# fast                    kubernetes.io/aws-ebs   Delete           Immediate

# Ver cuál es por defecto
kubectl get storageclass standard -o yaml
# provisioner: kubernetes.io/aws-ebs
# metadata:
#   annotations:
#     storageclass.kubernetes.io/is-default-class: "true"

# Crear PVC sin especificar storageClassName usa el por defecto
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: default-storage
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  # Si no especificas storageClassName, usa el por defecto</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_3_4_parámetros_avanzados">6.3.4. 6.3.4 Parámetros Avanzados</h4>
<div class="sect4">
<h5 id="_volume_binding_mode">Volume Binding Mode</h5>
<div class="paragraph">
<p><strong>Immediate:</strong> Vincula PV inmediatamente</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">volumeBindingMode: Immediate
# PVC se vincula tan pronto como se crea
# Puede no coincidir con nodo que usa el PVC</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>WaitForFirstConsumer:</strong> Espera hasta que Pod use el PVC</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">volumeBindingMode: WaitForFirstConsumer
# PVC espera hasta que un Pod la use
# Garantiza que PV está en la misma zona que el Pod
# Recomendado para alta disponibilidad</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_expansion">Expansion</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">allowVolumeExpansion: true

# Luego puedes expandir:
kubectl patch pvc my-pvc -p \
  '{"spec":{"resources":{"requests":{"storage":"50Gi"}}}}'

# O editar:
kubectl edit pvc my-pvc
# Cambiar "storage: 20Gi" a "storage: 50Gi"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_reclaim_policy">Reclaim Policy</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">reclaimPolicy: Delete        # Eliminar datos
reclaimPolicy: Retain        # Mantener datos
reclaimPolicy: Recycle       # Limpiar y reutilizar (deprecado)</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_6_4_statefulsets_y_storage">6.4. 6.4 StatefulSets y Storage</h3>
<div class="sect3">
<h4 id="_6_4_1_por_qué_statefulset_storage">6.4.1. 6.4.1 ¿Por qué StatefulSet + Storage?</h4>
<div class="paragraph">
<p><strong>Problema con Deployment:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Pod-1 usa PVC-A
Pod-1 reinicia → nuevas PVC se crean
→ cada Pod tiene diferentes datos</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Solución con StatefulSet:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Pod-0 usa PVC-0 (siempre)
Pod-1 usa PVC-1 (siempre)
Pod-2 usa PVC-2 (siempre)
→ Identidad persistente + Storage persistente</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_6_4_2_volumeclaimtemplates">6.4.2. 6.4.2 volumeClaimTemplates</h4>
<div class="paragraph">
<p>Define plantillas de PVC para cada Pod:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql-cluster
spec:
  serviceName: mysql
  replicas: 3

  selector:
    matchLabels:
      app: mysql

  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - name: mysql
        image: mysql:8.0

        ports:
        - containerPort: 3306

        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: password

        # Montar volumen
        volumeMounts:
        - name: mysql-storage
          mountPath: /var/lib/mysql

        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 1000m
            memory: 2Gi

  # ← Aquí está lo importante: volumeClaimTemplates
  volumeClaimTemplates:
  - metadata:
      name: mysql-storage
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: gp3-ssd
      resources:
        requests:
          storage: 100Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Qué sucede:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>StatefulSet crea 3 Pods:
├── mysql-cluster-0 → PVC: mysql-cluster-0-mysql-storage → PV
├── mysql-cluster-1 → PVC: mysql-cluster-1-mysql-storage → PV
└── mysql-cluster-2 → PVC: mysql-cluster-2-mysql-storage → PV

Si mysql-cluster-0 reinicia:
├── Pod termina
├── Pod se recrea
├── Usa misma PVC: mysql-cluster-0-mysql-storage
├── PVC vincula al mismo PV
├── Datos recuperados ✓</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver PVCs creadas automáticamente
kubectl get pvc
# NAME                              STATUS   VOLUME   CAPACITY
# mysql-cluster-0-mysql-storage     Bound    pv-1     100Gi
# mysql-cluster-1-mysql-storage     Bound    pv-2     100Gi
# mysql-cluster-2-mysql-storage     Bound    pv-3     100Gi

# Ver Pods con almacenamiento persistente
kubectl get pod
# NAME                READY   STATUS
# mysql-cluster-0     1/1     Running
# mysql-cluster-1     1/1     Running
# mysql-cluster-2     1/1     Running

# Eliminar un Pod (se recrea pero usa misma PVC)
kubectl delete pod mysql-cluster-0

# Ver que se recrea con misma identidad
kubectl get pod
# mysql-cluster-0 reiniciado (0/1 → 1/1)</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_4_3_postgresql_con_statefulset">6.4.3. 6.4.3 PostgreSQL con StatefulSet</h4>
<div class="paragraph">
<p>Ejemplo completo: Base de datos PostgreSQL con almacenamiento:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Secret para credenciales
apiVersion: v1
kind: Secret
metadata:
  name: postgres-secret
stringData:
  POSTGRES_PASSWORD: "super_secure_password_123"
  POSTGRES_USER: postgres
  POSTGRES_DB: appdb

---
# ConfigMap con configuración
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-config
data:
  postgresql.conf: |
    listen_addresses = '*'
    max_connections = 200
    shared_buffers = 256MB
    effective_cache_size = 1GB
    work_mem = 4MB
    maintenance_work_mem = 64MB

---
# Service headless (importante para StatefulSet)
apiVersion: v1
kind: Service
metadata:
  name: postgres
spec:
  clusterIP: None  # ← Headless
  selector:
    app: postgres
  ports:
  - port: 5432
    targetPort: 5432

---
# StatefulSet de PostgreSQL
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres
  replicas: 1  # Una instancia principal (más réplicas con streaming replication)

  selector:
    matchLabels:
      app: postgres

  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:15

        ports:
        - containerPort: 5432
          name: postgres

        # Variables de entorno desde Secret
        envFrom:
        - secretRef:
            name: postgres-secret

        # Montar volumen de datos
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
          subPath: postgres  # PostgreSQL necesita subPath

        - name: config
          mountPath: /etc/postgresql/postgresql.conf
          subPath: postgresql.conf

        # Health checks
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - pg_isready -U postgres
          initialDelaySeconds: 30
          periodSeconds: 10

        readinessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - pg_isready -U postgres
          initialDelaySeconds: 5
          periodSeconds: 5

        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 1Gi

      volumes:
      - name: config
        configMap:
          name: postgres-config

  # PVC automáticas para cada Pod
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: gp3-ssd
      resources:
        requests:
          storage: 50Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Usar la base de datos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Conectarse a PostgreSQL desde dentro del cluster
kubectl run psql-client --image=postgres:15 -it --rm \
  -- psql -h postgres.default.svc.cluster.local -U postgres -d appdb

# Crear tabla
CREATE TABLE users (
  id SERIAL PRIMARY KEY,
  name VARCHAR(100),
  email VARCHAR(100)
);

# Insertar datos
INSERT INTO users (name, email) VALUES ('Alice', 'alice@example.com');

# Verificar persistencia
# Si eliminas el Pod, reinicia y los datos permanecen</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_4_4_escalado_de_statefulsets">6.4.4. 6.4.4 Escalado de StatefulSets</h4>
<div class="paragraph">
<p><strong>Aumentar replicas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Aumentar de 1 a 3 Pods con almacenamiento
kubectl patch statefulset postgres -p '{"spec":{"replicas":3}}'

# Ver progreso
kubectl rollout status statefulset postgres

# Verificar PVCs (se crean automáticamente)
kubectl get pvc
# postgres-0-postgres-storage
# postgres-1-postgres-storage
# postgres-2-postgres-storage</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Reducir replicas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Reducir de 3 a 1 (elimina Pods en orden inverso)
kubectl scale statefulset postgres --replicas=1

# Importante: PVCs NO se eliminan automáticamente
# Puedes reutilizarlas o eliminarlas manualmente
kubectl delete pvc postgres-1-postgres-storage
kubectl delete pvc postgres-2-postgres-storage</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_6_5_snapshots_y_backups">6.5. 6.5 Snapshots y Backups</h3>
<div class="sect3">
<h4 id="_6_5_1_volumesnapshots">6.5.1. 6.5.1 VolumeSnapshots</h4>
<div class="paragraph">
<p>Un <strong>VolumeSnapshot</strong> es una copia de un volumen en un punto en el tiempo.</p>
</div>
<div class="paragraph">
<p><strong>Requisitos:</strong>
- VolumeSnapshotClass definida
- Volume Snapshot Controller instalado</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalar Volume Snapshot CRDs
kubectl apply -f https://github.com/kubernetes-csi/external-snapshotter/raw/master/client/config/crd/

# Verificar
kubectl get crd | grep snapshot
# volumesnapshotclasses.snapshot.storage.k8s.io
# volumesnapshots.snapshot.storage.k8s.io</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_5_2_crear_snapshots">6.5.2. 6.5.2 Crear Snapshots</h4>
<div class="paragraph">
<p><strong>VolumeSnapshotClass (AWS EBS):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshotClass
metadata:
  name: ebs-snapshots
driver: ebs.csi.aws.com
deletionPolicy: Delete  # Delete = eliminar snapshot real también</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Crear Snapshot:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># PVC existente
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: app-data
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: ebs-gp3
  resources:
    requests:
      storage: 20Gi

---
# Snapshot del PVC
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: app-data-snapshot-v1
  namespace: production
spec:
  volumeSnapshotClassName: ebs-snapshots
  source:
    persistentVolumeClaimName: app-data</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear snapshot
kubectl apply -f snapshot.yaml

# Ver snapshots
kubectl get volumesnapshot
# NAME                         READYTOUSE   SOURCEPVC    SOURCESIZE   SNAPSHOTCLASS   AGE
# app-data-snapshot-v1         true         app-data     20Gi         ebs-snapshots   5m

# Ver detalles
kubectl describe volumesnapshot app-data-snapshot-v1</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_5_3_restaurar_desde_snapshot">6.5.3. 6.5.3 Restaurar desde Snapshot</h4>
<div class="paragraph">
<p><strong>Crear PVC desde Snapshot:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Restaurar datos de snapshot anterior
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: app-data-restored
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: ebs-gp3
  resources:
    requests:
      storage: 20Gi

  # ← Restaurar desde snapshot
  dataSource:
    name: app-data-snapshot-v1
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear PVC restaurada
kubectl apply -f pvc-restored.yaml

# Verificar que se crea desde snapshot
kubectl get pvc app-data-restored -o yaml
# dataSource:
#   apiGroup: snapshot.storage.k8s.io
#   kind: VolumeSnapshot
#   name: app-data-snapshot-v1

# Montar en un Pod de prueba
kubectl run restore-test --image=busybox -it --rm \
  -- sh -c "mount /dev/xvdf /data &amp;&amp; cat /data/important-file.txt"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_5_4_estrategias_de_backup">6.5.4. 6.5.4 Estrategias de Backup</h4>
<div class="sect4">
<h5 id="_opción_1_snapshots_periódicos">Opción 1: Snapshots Periódicos</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># CronJob que crea snapshots cada 6 horas
apiVersion: batch/v1
kind: CronJob
metadata:
  name: backup-snapshots
spec:
  schedule: "0 */6 * * *"  # Cada 6 horas
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: backup-sa
          containers:
          - name: snapshot-creator
            image: bitnami/kubectl:latest
            command:
            - /bin/sh
            - -c
            - |
              TIMESTAMP=$(date +%Y%m%d-%H%M%S)
              cat &lt;&lt;EOF | kubectl apply -f -
              apiVersion: snapshot.storage.k8s.io/v1
              kind: VolumeSnapshot
              metadata:
                name: app-data-snapshot-$TIMESTAMP
              spec:
                volumeSnapshotClassName: ebs-snapshots
                source:
                  persistentVolumeClaimName: app-data
              EOF
          restartPolicy: OnFailure

---
# RBAC para CronJob
apiVersion: v1
kind: ServiceAccount
metadata:
  name: backup-sa

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: snapshot-creator
rules:
- apiGroups: ["snapshot.storage.k8s.io"]
  resources: ["volumesnapshots"]
  verbs: ["create", "get", "list"]
- apiGroups: [""]
  resources: ["persistentvolumeclaims"]
  verbs: ["get", "list"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: snapshot-creator-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: snapshot-creator
subjects:
- kind: ServiceAccount
  name: backup-sa</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_opción_2_backup_externo_con_velero">Opción 2: Backup Externo con Velero</h5>
<div class="paragraph">
<p>Para backups completos (Pods, configuración, datos):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalar Velero
wget https://github.com/vmware-tanzu/velero/releases/download/v1.13.0/velero-v1.13.0-linux-amd64.tar.gz
tar -xvf velero-v1.13.0-linux-amd64.tar.gz
sudo mv velero-v1.13.0-linux-amd64/velero /usr/local/bin/

# Configurar para AWS
velero install \
  --provider aws \
  --bucket velero-backups \
  --secret-file ./credentials-velero

# Crear backup
velero backup create prod-backup-20240101

# Ver backups
velero backup get

# Restaurar desde backup
velero restore create --from-backup prod-backup-20240101</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_opción_3_backup_application_level">Opción 3: Backup Application-Level</h5>
<div class="paragraph">
<p>Algunos datos requieren backups a nivel de aplicación:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># CronJob para backup de base de datos
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgres-backup
spec:
  schedule: "0 2 * * *"  # Cada día a las 2 AM
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: postgres-backup
            image: postgres:15
            command:
            - /bin/bash
            - -c
            - |
              BACKUP_DATE=$(date +%Y%m%d_%H%M%S)
              pg_dump -h postgres -U postgres appdb | \
                gzip &gt; /backups/postgres_${BACKUP_DATE}.sql.gz

              # Opcional: enviar a S3
              # aws s3 cp /backups/postgres_${BACKUP_DATE}.sql.gz \
              #   s3://my-backups/postgres/

            volumeMounts:
            - name: backups
              mountPath: /backups

            env:
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: POSTGRES_PASSWORD

          volumes:
          - name: backups
            persistentVolumeClaim:
              claimName: backups-pvc

          restartPolicy: OnFailure</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_6_5_5_disaster_recovery">6.5.5. 6.5.5 Disaster Recovery</h4>
<div class="paragraph">
<p><strong>Caso: Datacenter falla</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>1. Backup en múltiples regiones ✓
2. Restaurar en otra región
3. Actualizar DNS/load balancer</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># En región primaria
velero backup create prod-backup-full \
  --wait

# Esperar a que se sincronice a otra región
# (si usas Velero con S3 cross-region replication)

# En región secundaria
velero backup-location get
# NAME      PROVIDER   BUCKET/PREFIX     ACCESS MODE

# Restaurar
velero restore create --from-backup prod-backup-full

# Verificar que todo funciona
kubectl get pods -A
kubectl get svc -a</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_6_6_ejemplos_completos">6.6. 6.6 Ejemplos Completos</h3>
<div class="sect3">
<h4 id="_ejemplo_1_wordpress_con_storage">6.6.1. Ejemplo 1: WordPress con Storage</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Storage Class para WordPress
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: wordpress-storage
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp3
  iops: "3000"
  throughput: "125"
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
reclaimPolicy: Delete

---
# PVC para WordPress
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: wordpress-pvc
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: wordpress-storage
  resources:
    requests:
      storage: 30Gi

---
# Secret para MySQL
apiVersion: v1
kind: Secret
metadata:
  name: mysql-secret
stringData:
  MYSQL_ROOT_PASSWORD: "secure_mysql_root_pass"
  MYSQL_DATABASE: wordpress
  MYSQL_USER: wordpress
  MYSQL_PASSWORD: "secure_wordpress_pass"

---
# Deployment de WordPress
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wordpress
spec:
  replicas: 2
  selector:
    matchLabels:
      app: wordpress
  template:
    metadata:
      labels:
        app: wordpress
    spec:
      containers:
      - name: wordpress
        image: wordpress:latest

        ports:
        - containerPort: 80

        env:
        - name: WORDPRESS_DB_HOST
          value: "mysql.default.svc.cluster.local"
        - name: WORDPRESS_DB_NAME
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: MYSQL_DATABASE
        - name: WORDPRESS_DB_USER
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: MYSQL_USER
        - name: WORDPRESS_DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: MYSQL_PASSWORD

        volumeMounts:
        - name: wordpress-data
          mountPath: /var/www/html

        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi

      volumes:
      - name: wordpress-data
        persistentVolumeClaim:
          claimName: wordpress-pvc

---
# Service para WordPress
apiVersion: v1
kind: Service
metadata:
  name: wordpress-service
spec:
  type: LoadBalancer
  selector:
    app: wordpress
  ports:
  - port: 80
    targetPort: 80

---
# StatefulSet de MySQL
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
spec:
  serviceName: mysql
  replicas: 1
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - name: mysql
        image: mysql:8.0

        ports:
        - containerPort: 3306

        envFrom:
        - secretRef:
            name: mysql-secret

        volumeMounts:
        - name: mysql-storage
          mountPath: /var/lib/mysql

        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 1Gi

  volumeClaimTemplates:
  - metadata:
      name: mysql-storage
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: wordpress-storage
      resources:
        requests:
          storage: 50Gi

---
# Service headless para MySQL
apiVersion: v1
kind: Service
metadata:
  name: mysql
spec:
  clusterIP: None
  selector:
    app: mysql
  ports:
  - port: 3306
    targetPort: 3306</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_2_backup_y_restauración">6.6.2. Ejemplo 2: Backup y Restauración</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Crear snapshot
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: wordpress-backup-weekly
spec:
  volumeSnapshotClassName: ebs-snapshots
  source:
    persistentVolumeClaimName: wordpress-pvc

---
# Semana siguiente, restaurar si algo falla
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: wordpress-pvc-restored
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: wordpress-storage
  resources:
    requests:
      storage: 30Gi
  dataSource:
    name: wordpress-backup-weekly
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io

---
# Pod con datos restaurados
apiVersion: v1
kind: Pod
metadata:
  name: wordpress-recovery
spec:
  containers:
  - name: restore
    image: busybox:latest
    command: ["/bin/sh"]
    args: ["-c", "ls -la /recovery &amp;&amp; sleep infinity"]
    volumeMounts:
    - name: recovery-data
      mountPath: /recovery

  volumes:
  - name: recovery-data
    persistentVolumeClaim:
      claimName: wordpress-pvc-restored</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_6_7_best_practices">6.7. 6.7 Best Practices</h3>
<div class="paragraph">
<p><strong>1. Usar Storage Classes para provisioning dinámico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">❌ Crear PVs manualmente
✅ Storage Classes + PVCs</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Especificar volumeBindingMode: WaitForFirstConsumer</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ Garantiza PV en la misma zona que el Pod
✅ Evita issues de latencia</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Backups periódicos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">✅ VolumeSnapshots cada 6 horas
✅ Backup application-level (bases de datos)
✅ Disaster recovery plan</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. StatefulSets para datos persistentes</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ StatefulSet con volumeClaimTemplates
✅ Identidad y almacenamiento vinculados</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>5. Monitoreo de storage</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">✅ Alertas cuando PVC usa 80%+ capacidad
✅ Tendencias de crecimiento
✅ Rotación de backups</code></pre>
</div>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_6_8_resumen_del_módulo_6">6.8. 6.8 Resumen del Módulo 6</h3>
<div class="paragraph">
<p>En este módulo aprendiste:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Persistent Volumes</strong>: Almacenamiento cluster-wide</p>
<div class="ulist">
<ul>
<li>
<p>Tipos: local, NFS, iSCSI, cloud</p>
</li>
<li>
<p>Access modes: RWO, ROX, RWX, RWOP</p>
</li>
<li>
<p>Reclaim policies: Delete, Retain, Recycle</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>PersistentVolumeClaims</strong>: Solicitudes de almacenamiento</p>
<div class="ulist">
<ul>
<li>
<p>Vinculación automática con PVs</p>
</li>
<li>
<p>Estados: Pending, Bound, Lost</p>
</li>
<li>
<p>Uso en Pods/Deployments</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Storage Classes</strong>: Provisioning dinámico</p>
<div class="ulist">
<ul>
<li>
<p>AWS EBS, GCP PD, Azure Disk</p>
</li>
<li>
<p>Parameters y selectors</p>
</li>
<li>
<p>Expansion y binding modes</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>StatefulSets + Storage</strong>: Identidad persistente</p>
<div class="ulist">
<ul>
<li>
<p>volumeClaimTemplates</p>
</li>
<li>
<p>PostgreSQL, MySQL examples</p>
</li>
<li>
<p>Escalado seguro</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Snapshots y Backups</strong>: Protección de datos</p>
<div class="ulist">
<ul>
<li>
<p>VolumeSnapshots</p>
</li>
<li>
<p>Restauración</p>
</li>
<li>
<p>Estrategias: periódicas, externas, application-level</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>Con estos conocimientos, estás listo para aprender sobre <strong>Escalado</strong> en el Módulo 7.</p>
</div>
<hr>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_7_scaling_y_autoscaling">7. MÓDULO 7: Scaling y Autoscaling</h2>
<div class="sectionbody">
<div class="paragraph">
<p>El <strong>escalado</strong> es fundamental para aplicaciones en Kubernetes. Hay dos dimensiones:
- <strong>Escalado horizontal</strong>: Más Pods (HPA)
- <strong>Escalado vertical</strong>: Más recursos por Pod (VPA)
- <strong>Escalado de cluster</strong>: Más nodos (Cluster Autoscaler)</p>
</div>
<div class="paragraph">
<p><strong>Diagrama de escalado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>┌─────────────────────────────────────────────┐
│ Tráfico aumenta                             │
│         ↓                                   │
│ HPA detecta CPU &gt; 70%                       │
│         ↓                                   │
│ Crear más Pods (horizontal)                 │
│         ↓                                   │
│ Si no hay recursos → Cluster Autoscaler     │
│         ↓                                   │
│ Crear nuevos nodos                          │
│         ↓                                   │
│ Distribuir Pods en nodos                    │
└─────────────────────────────────────────────┘</code></pre>
</div>
</div>
<hr>
<div class="sect2">
<h3 id="_7_1_escalado_manual">7.1. 7.1 Escalado Manual</h3>
<div class="sect3">
<h4 id="_7_1_1_concepto_básico">7.1.1. 7.1.1 Concepto Básico</h4>
<div class="paragraph">
<p>El <strong>escalado manual</strong> es cambiar el número de replicas sin automatización.</p>
</div>
<div class="paragraph">
<p><strong>Casos de uso:</strong>
- Testing y desarrollo
- Prepararse para evento específico
- Control manual temporal</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_1_2_kubectl_scale">7.1.2. 7.1.2 Kubectl Scale</h4>
<div class="paragraph">
<p><strong>Aumentar replicas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Cambiar Deployment de 2 a 5 replicas
kubectl scale deployment myapp --replicas=5

# Verificar
kubectl get deployment myapp
# NAME    READY   UP-TO-DATE   AVAILABLE   AGE
# myapp   5/5     5            5           10m

# Ver Pods creados
kubectl get pods
# myapp-6c9f4d7f88-1ab2c   1/1   Running
# myapp-6c9f4d7f88-2cd3e   1/1   Running
# myapp-6c9f4d7f88-3ef4g   1/1   Running
# myapp-6c9f4d7f88-4gh5h   1/1   Running
# myapp-6c9f4d7f88-5ij6i   1/1   Running</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Reducir replicas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Reducir de 5 a 2
kubectl scale deployment myapp --replicas=2

# Ver progreso
kubectl rollout status deployment myapp
# deployment "myapp" successfully rolled out

# Verificar estado final
kubectl get deployment myapp
# NAME    READY   UP-TO-DATE   AVAILABLE   AGE
# myapp   2/2     2            2           10m</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_1_3_editar_deployment">7.1.3. 7.1.3 Editar Deployment</h4>
<div class="paragraph">
<p><strong>Método imperativo avanzado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Editar directamente (abre editor)
kubectl edit deployment myapp

# Cambiar spec.replicas: 2 a 5
# Guardar y cerrar editor
# → Deployment se actualiza automáticamente

# Patch directo
kubectl patch deployment myapp -p '{"spec":{"replicas":3}}'

# O con JSON merge
kubectl patch deployment myapp --type merge \
  -p '{"spec":{"replicas":3}}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_1_4_escalado_declarativo">7.1.4. 7.1.4 Escalado Declarativo</h4>
<div class="paragraph">
<p><strong>En YAML (mejor práctica):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 5  # ← Cambiar aquí
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: app
        image: myapp:1.0</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Aplicar cambios
kubectl apply -f deployment.yaml

# Verificar cambios
kubectl get deployment myapp -o yaml | grep replicas
# replicas: 5</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_7_2_horizontal_pod_autoscaler_hpa">7.2. 7.2 Horizontal Pod Autoscaler (HPA)</h3>
<div class="sect3">
<h4 id="_7_2_1_qué_es_hpa">7.2.1. 7.2.1 ¿Qué es HPA?</h4>
<div class="paragraph">
<p>Un <strong>Horizontal Pod Autoscaler</strong> escala automáticamente el número de Pods basándose en métricas.</p>
</div>
<div class="paragraph">
<p><strong>Concepto:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>CPU &gt; 70% → Crear más Pods
CPU &lt; 30% → Reducir Pods</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Diagrama:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>┌──────────────────────────────────┐
│ Metrics Server (monitoreo)       │
│ mide: CPU, memoria, custom       │
│         ↓                        │
│ HPA controller                   │
│ compara con threshold            │
│         ↓                        │
│ Ajusta replicas                  │
│ scale-up o scale-down            │
└──────────────────────────────────┘</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Requisitos:</strong>
- Metrics Server instalado
- Resource requests definidos en Pods
- Métricas disponibles (puede tardar 1-2 min)</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_2_2_instalar_metrics_server">7.2.2. 7.2.2 Instalar Metrics Server</h4>
<div class="paragraph">
<p>En la mayoría de clusters cloud ya está instalado. Para Minikube:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Verificar si Metrics Server existe
kubectl get deployment metrics-server -n kube-system

# Si no existe, instalar
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# Esperar a que esté listo
kubectl wait --for=condition=available --timeout=300s \
  deployment/metrics-server -n kube-system

# Verificar que recolecta métricas
kubectl top nodes
# NAME       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
# minikube   234m         11%    1023Mi          26%

kubectl top pods
# NAME                     CPU(m)   MEMORY(Mi)
# myapp-6c9f4d7f88-1ab2c   45m      128Mi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_2_3_hpa_basado_en_cpu">7.2.3. 7.2.3 HPA Basado en CPU</h4>
<div class="paragraph">
<p><strong>Caso simple: Escalar por CPU:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Deployment con resource requests
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: web-app
  template:
    metadata:
      labels:
        app: web-app
    spec:
      containers:
      - name: app
        image: myapp:1.0

        # IMPORTANTE: Resource requests son requeridos para HPA
        resources:
          requests:
            cpu: 100m        # 100 millicores
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi

        ports:
        - containerPort: 8080

---
# Service
apiVersion: v1
kind: Service
metadata:
  name: web-app
spec:
  selector:
    app: web-app
  ports:
  - port: 80
    targetPort: 8080
  type: ClusterIP

---
# HPA - Escalar basado en CPU
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-app-hpa
spec:
  # Qué escalable
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app

  # Rango de replicas
  minReplicas: 2
  maxReplicas: 10

  # Métricas
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # Escalar cuando CPU &gt; 70%

  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80  # Escalar cuando memoria &gt; 80%

  # Comportamiento
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # Esperar 5 min antes de reducir
      policies:
      - type: Percent
        value: 50  # Reducir max 50% de Pods actuales
        periodSeconds: 60

    scaleUp:
      stabilizationWindowSeconds: 0  # Escalar inmediatamente
      policies:
      - type: Percent
        value: 100  # Duplicar Pods
        periodSeconds: 15
      - type: Pods
        value: 4  # O agregar 4 Pods
        periodSeconds: 15
      selectPolicy: Max  # Usar la política más agresiva</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Verificar HPA:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver HPA
kubectl get hpa web-app-hpa
# NAME             REFERENCE              TARGETS      MINPODS  MAXPODS  REPLICAS  AGE
# web-app-hpa      Deployment/web-app     45%/70%      2        10       2         5m

# Ver detalles
kubectl describe hpa web-app-hpa
# Name:                      web-app-hpa
# Namespace:                 default
# Reference:                 Deployment/web-app
# Metrics:                   ( current / target )
#   resource cpu on pods  (avg):       45% / 70%
#   resource memory on pods  (avg):    60% / 80%
# Min replicas:              2
# Max replicas:              10
# Deployment pods:           2 current / 2 desired
# Conditions:
#   Type            Status  Reason
#   AbleToScale     True    ScaleDownStabilized
#   ScalingActive   True    ValidMetricsFound</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_2_4_hpa_v1_simplificado">7.2.4. 7.2.4 HPA v1 (Simplificado)</h4>
<div class="paragraph">
<p>Para casos simples, puedes usar autoscaling/v1:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: simple-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app

  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 80  # CPU &gt; 80%</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_2_5_métricas_personalizadas">7.2.5. 7.2.5 Métricas Personalizadas</h4>
<div class="paragraph">
<p>Para aplicaciones que exponen métricas propias (no CPU/memoria):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Ejemplo: Escalar por solicitudes HTTP por segundo

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: app-custom-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: app

  minReplicas: 1
  maxReplicas: 20

  metrics:
  # Métrica personalizada de Prometheus
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second  # Métrica custom
      target:
        type: AverageValue
        averageValue: "1k"  # Escalar cuando &gt; 1000 req/s por Pod

  # También pueden ser métricas externas
  - type: External
    external:
      metric:
        name: queue_depth
        selector:
          matchLabels:
            queue_name: tasks
      target:
        type: Value
        value: "30"  # Escalar cuando queue depth &gt; 30</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Para usar métricas personalizadas, necesitas:</strong>
1. Prometheus o similar recolectando métricas
2. Adaptor de métricas instalado (custom-metrics-apiserver)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalar Prometheus Adapter
helm install prometheus-adapter prometheus-community/prometheus-adapter \
  -n prometheus

# Ver métricas disponibles
kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1 | jq .</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_2_6_comportamiento_de_escalado">7.2.6. 7.2.6 Comportamiento de Escalado</h4>
<div class="paragraph">
<p>Define cómo y cuándo escalar:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: controlled-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: app

  minReplicas: 1
  maxReplicas: 100

  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50

  behavior:
    # Escalado hacia abajo (reducir Pods)
    scaleDown:
      # Esperar 5 minutos antes de reducir
      # Evita fluctuaciones
      stabilizationWindowSeconds: 300

      policies:
      # Política 1: Reducir al 50% de Pods actuales
      - type: Percent
        value: 50
        periodSeconds: 60  # Cada minuto

      # Política 2: Reducir máximo 2 Pods
      - type: Pods
        value: 2
        periodSeconds: 60

      # Usar la política menos agresiva (conservador)
      selectPolicy: Min

    # Escalado hacia arriba (crear Pods)
    scaleUp:
      # Escalar inmediatamente sin esperar
      stabilizationWindowSeconds: 0

      policies:
      # Política 1: Duplicar Pods
      - type: Percent
        value: 100
        periodSeconds: 15  # Cada 15 segundos

      # Política 2: Agregar 4 Pods
      - type: Pods
        value: 4
        periodSeconds: 15

      # Usar la política más agresiva (rápido)
      selectPolicy: Max</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Tipos de políticas:</strong>
- <code>Percent</code>: % del número actual de Pods
- <code>Pods</code>: Número absoluto de Pods</p>
</div>
<div class="paragraph">
<p><strong>selectPolicy:</strong>
- <code>Max</code>: Usar la que agregue más Pods (escala rápido)
- <code>Min</code>: Usar la que agregue menos Pods (conservador)</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_7_3_vertical_pod_autoscaler_vpa">7.3. 7.3 Vertical Pod Autoscaler (VPA)</h3>
<div class="sect3">
<h4 id="_7_3_1_qué_es_vpa">7.3.1. 7.3.1 ¿Qué es VPA?</h4>
<div class="paragraph">
<p>El <strong>Vertical Pod Autoscaler</strong> ajusta automáticamente los resource requests/limits de Pods.</p>
</div>
<div class="paragraph">
<p><strong>Diferencia HPA vs VPA:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>HPA: 2 Pods con 100m CPU → CPU alta → 4 Pods con 100m CPU
VPA: 2 Pods con 100m CPU → CPU alta → 2 Pods con 200m CPU</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Casos de uso:</strong>
- Aplicaciones que crecen lentamente
- Right-sizing de recursos
- Aplicaciones con patrón de uso predecible</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_3_2_instalar_vpa">7.3.2. 7.3.2 Instalar VPA</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Clonar repositorio
git clone https://github.com/kubernetes/autoscaler.git
cd autoscaler/vertical-pod-autoscaler

# Instalar
./hack/vpa-up.sh

# Verificar instalación
kubectl get deployment -n kube-system | grep vpa
# vpa-admission-controller
# vpa-recommender
# vpa-updater

# Ver logs
kubectl logs -n kube-system deployment/vpa-recommender</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_3_3_vpa_modes">7.3.3. 7.3.3 VPA Modes</h4>
<div class="paragraph">
<p>VPA tiene cuatro modos de operación:</p>
</div>
<div class="sect4">
<h5 id="_off">Off</h5>
<div class="paragraph">
<p>No hace nada, solo genera recomendaciones:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: app-vpa-off
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: app

  updatePolicy:
    updateMode: "Off"  # Solo recomendaciones</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver recomendaciones sin aplicarlas
kubectl get vpa app-vpa-off --watch
# Ver detalles
kubectl describe vpa app-vpa-off
# Recommendation:
#   Container Recommendations:
#   - Container Name: app
#     Lower Bound:
#       Cpu:     25m
#       Memory:  32Mi
#     Target:
#       Cpu:     50m
#       Memory:  64Mi
#     Upper Bound:
#       Cpu:     100m
#       Memory:  256Mi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_initial">Initial</h5>
<div class="paragraph">
<p>Ajusta recursos solo cuando se crea el Pod (init):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: app-vpa-initial
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: app

  updatePolicy:
    updateMode: "Initial"

  resourcePolicy:
    containerPolicies:
    - containerName: app
      minAllowed:
        cpu: 25m
        memory: 32Mi
      maxAllowed:
        cpu: 1000m
        memory: 1Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Flujo:</strong>
1. Crear Deployment sin VPA
2. Activar VPA-Initial
3. Eliminar Pods (se recrean con nuevos recursos)
4. VPA asigna recursos iniciales
5. No se modifica después</p>
</div>
</div>
<div class="sect4">
<h5 id="_recreate">Recreate</h5>
<div class="paragraph">
<p>Reinicia Pods cuando hay que cambiar recursos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: app-vpa-recreate
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: app

  updatePolicy:
    updateMode: "Recreate"
    minReplicas: 2  # Mantener mínimo

  resourcePolicy:
    containerPolicies:
    - containerName: app
      minAllowed:
        cpu: 50m
        memory: 64Mi
      maxAllowed:
        cpu: 2000m
        memory: 2Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Flujo:</strong>
1. VPA monitorea uso de recursos
2. Si necesita ajustar, termina Pod
3. Nuevo Pod se crea con recursos ajustados
4. Continúa monitoreando y ajustando</p>
</div>
</div>
<div class="sect4">
<h5 id="_auto_predeterminado">Auto (predeterminado)</h5>
<div class="paragraph">
<p>Usa Recreate en la mayoría de casos, Initial para StatefulSets:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: app-vpa-auto
spec:
  targetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: db

  updatePolicy:
    updateMode: "Auto"  # Recomendado

  resourcePolicy:
    containerPolicies:
    - containerName: db
      minAllowed:
        cpu: 500m
        memory: 512Mi
      maxAllowed:
        cpu: 4000m
        memory: 4Gi

      # Controlar comportamiento
      controlledValues: RequestsAndLimits  # Ambos
      # o
      # controlledValues: RequestsOnly       # Solo requests</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_7_3_4_ejemplo_completo_vpa_hpa">7.3.4. 7.3.4 Ejemplo Completo: VPA + HPA</h4>
<div class="paragraph">
<p>Combinar VPA (ajustar tamaño) + HPA (ajustar cantidad):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Deployment sin resource requests especificados
apiVersion: apps/v1
kind: Deployment
metadata:
  name: smart-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: smart-app
  template:
    metadata:
      labels:
        app: smart-app
    spec:
      containers:
      - name: app
        image: myapp:1.0
        # Sin resource requests → VPA las agregará

---
# VPA: Ajusta requests iniciales
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: smart-app-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: smart-app

  updatePolicy:
    updateMode: "Initial"  # O "Auto"

  resourcePolicy:
    containerPolicies:
    - containerName: app
      minAllowed:
        cpu: 50m
        memory: 64Mi
      maxAllowed:
        cpu: 1000m
        memory: 1Gi

---
# HPA: Escala horizontalmente
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: smart-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: smart-app

  minReplicas: 1
  maxReplicas: 10

  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Resultado:</strong>
- VPA asegura que cada Pod tiene los requests correctos
- HPA escala horizontalmente según carga
- Combinación óptima: scaling eficiente</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_7_4_cluster_autoscaler">7.4. 7.4 Cluster Autoscaler</h3>
<div class="sect3">
<h4 id="_7_4_1_qué_es_cluster_autoscaler">7.4.1. 7.4.1 ¿Qué es Cluster Autoscaler?</h4>
<div class="paragraph">
<p>El <strong>Cluster Autoscaler</strong> agrega/elimina <strong>nodos</strong> del cluster basándose en demanda de Pods.</p>
</div>
<div class="paragraph">
<p><strong>Flujo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Pod no puede asignarse (no hay espacio)
         ↓
Cluster Autoscaler lo detecta
         ↓
Solicita nuevo nodo al cloud provider
         ↓
Nodo se une al cluster
         ↓
Pod se asigna al nuevo nodo</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Requisitos:</strong>
- Cloud provider (AWS, GCP, Azure)
- Cluster Autoscaler instalado
- Auto Scaling Group (ASG) o equivalente</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_4_2_instalar_cluster_autoscaler">7.4.2. 7.4.2 Instalar Cluster Autoscaler</h4>
<div class="sect4">
<h5 id="_aws_eks_2">AWS EKS</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># 1. Crear policy IAM
cat &gt; autoscaler-policy.json &lt;&lt; EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "autoscaling:DescribeAutoScalingGroups",
        "autoscaling:DescribeAutoScalingInstances",
        "autoscaling:DescribeLaunchConfigurations",
        "autoscaling:SetDesiredCapacity",
        "autoscaling:TerminateInstanceInAutoScalingGroup",
        "ec2:DescribeLaunchTemplateVersions"
      ],
      "Resource": "*"
    }
  ]
}
EOF

aws iam create-policy \
  --policy-name EKSClusterAutoscalerPolicy \
  --policy-document file://autoscaler-policy.json

# 2. Crear IRSA (IAM Role for Service Account)
eksctl create iamserviceaccount \
  --name cluster-autoscaler \
  --namespace kube-system \
  --cluster=my-cluster \
  --attach-policy-arn=arn:aws:iam::ACCOUNT:policy/EKSClusterAutoscalerPolicy \
  --override-existing-serviceaccounts \
  --approve

# 3. Instalar Cluster Autoscaler
helm repo add autoscaler https://kubernetes.github.io/autoscaler
helm install cluster-autoscaler autoscaler/cluster-autoscaler \
  --namespace kube-system \
  --set awsRegion=us-east-1 \
  --set autoDiscovery.clusterName=my-cluster \
  --set rbac.serviceAccount.create=false \
  --set rbac.serviceAccount.name=cluster-autoscaler

# 4. Verificar
kubectl get deployment cluster-autoscaler -n kube-system
kubectl logs -n kube-system deployment/cluster-autoscaler</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_gke_google_cloud">GKE (Google Cloud)</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># GKE lo instala automáticamente si habilitas autoscaling
gcloud container clusters create my-cluster \
  --enable-autoscaling \
  --min-nodes=1 \
  --max-nodes=10 \
  --zone=us-central1-a

# Verificar en nodos existentes
gcloud container clusters describe my-cluster \
  --zone=us-central1-a \
  --format="value(nodePools[0].autoscaling)"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_azure_aks_2">Azure AKS</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># AKS lo instala automáticamente
az aks create \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --enable-cluster-autoscaler \
  --min-count 1 \
  --max-count 10

# Verificar
kubectl get deployment -n kube-system | grep autoscaler</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_7_4_3_configuración">7.4.3. 7.4.3 Configuración</h4>
<div class="paragraph">
<p><strong>Limites de escalado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver configuración actual
kubectl get nodes -o wide
# NAME                      STATUS   ROLES
# ip-10-0-1-100.ec2.internal   Ready    &lt;none&gt;

# Ver Cluster Autoscaler logs
kubectl logs -n kube-system deployment/cluster-autoscaler | grep "Scaling up"

# Ver eventos de escalado
kubectl get events -n kube-system | grep "cluster-autoscaler"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Node Groups con diferentes configuraciones:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Ejemplo: AWS - Multiple node groups con Cluster Autoscaler
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-autoscaler-status
data:
  nodes.max: "100"      # Máximo 100 nodos total
  nodes.min: "1"        # Mínimo 1 nodo

---
# Pod que DEBE correr (no puede escalarse)
apiVersion: v1
kind: Pod
metadata:
  name: critical-addon
  labels:
    tier: system
spec:
  priorityClassName: system-cluster-critical  # Alta prioridad
  containers:
  - name: addon
    image: critical-app:1.0

---
# Pod que puede ser eviccionado
apiVersion: v1
kind: Pod
metadata:
  name: interruptible-job
spec:
  containers:
  - name: job
    image: batch-job:1.0

  # No puede ser movido (por defecto sí)
  # affinity:
  #   nodeAffinity:
  #     requiredDuringSchedulingIgnoredDuringExecution:
  #       nodeSelectorTerms:
  #       - matchExpressions:
  #         - key: instance-type
  #           operator: In
  #           values:
  #           - t3.medium</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_4_4_combinación_hpa_cluster_autoscaler">7.4.4. 7.4.4 Combinación: HPA + Cluster Autoscaler</h4>
<div class="paragraph">
<p><strong>Flujo completo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: full-auto-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: app

  minReplicas: 2
  maxReplicas: 100  # Puede crecer mucho

  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70

---
# Nodos en cluster:
# Inicialmente: 1 nodo con 4 CPUs
# Capacidad: 40 Pods × 100m = 4000m = 4 CPUs
#
# Si HPA crea 50 Pods (5000m requerido):
# 1. 40 Pods se asignan al nodo existente
# 2. 10 Pods quedan sin asignar (Pending)
# 3. Cluster Autoscaler detecta Pods Pending
# 4. Agrega nuevo nodo
# 5. 10 Pods restantes se asignan</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_4_5_debugging_de_cluster_autoscaler">7.4.5. 7.4.5 Debugging de Cluster Autoscaler</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver logs detallados
kubectl logs -n kube-system deployment/cluster-autoscaler -f

# Ver eventos de cluster
kubectl describe node NODE_NAME

# Verificar si hay Pods pending
kubectl get pods -A --field-selector=status.phase=Pending

# Ver nodos disponibles
kubectl get nodes -o wide

# Ver resource allocation
kubectl describe node NODE_NAME | grep "Allocated resources"

# Forzar evaluación de escalado
# (La mayoría de autoscalers revisan cada 10-15 segundos)
# Crear Pod que no cabe
kubectl run test-pod --image=nginx \
  -n default -- sleep 1000

# Ver si Cluster Autoscaler agrega nodos
kubectl get nodes --watch</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_7_5_pruebas_de_carga">7.5. 7.5 Pruebas de Carga</h3>
<div class="sect3">
<h4 id="_7_5_1_generar_carga">7.5.1. 7.5.1 Generar Carga</h4>
<div class="sect4">
<h5 id="_usando_apache_bench">Usando Apache Bench</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalar
sudo apt-get install apache2-utils

# Obtener URL del servicio
kubectl port-forward svc/web-app 8080:80 &amp;

# Generar tráfico
ab -n 10000 -c 100 http://localhost:8080/

# Interpretación:
# -n: 10000 solicitudes totales
# -c: 100 conexiones concurrentes
#
# Resultado:
# Requests per second: 150
# Documento Length: 2048 bytes</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_usando_siege">Usando Siege</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalar
sudo apt-get install siege

# Test de carga sostenida
siege -b -c 50 -r 100 http://localhost:8080/

# -b: Benchmark mode
# -c 50: 50 usuarios concurrentes
# -r 100: Cada usuario hace 100 peticiones</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_usando_kubench_en_el_cluster">Usando Kubench (en el cluster)</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Pod de testing que genera carga
apiVersion: v1
kind: Pod
metadata:
  name: load-generator
spec:
  containers:
  - name: load-gen
    image: busybox:latest
    command:
    - /bin/sh
    - -c
    - |
      while true; do
        wget -q -O- http://web-app.default.svc.cluster.local/
        sleep 0.1
      done
  restartPolicy: Never</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p>Lanzar múltiples copias:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear varios Pods de carga
for i in {1..10}; do
  kubectl run load-$i --image=busybox -i --tty=false \
    -- /bin/sh -c \
    "while true; do wget -q -O- http://web-app/; done"
done

# Ver Pods creándose
kubectl get pods -w

# Ver HPA escalando
kubectl get hpa -w
# Debe aumentar replicas</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_7_5_2_monitorar_escalado">7.5.2. 7.5.2 Monitorar Escalado</h4>
<div class="paragraph">
<p><strong>En tiempo real:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Terminal 1: Ver HPA
kubectl get hpa -w

# Terminal 2: Ver Pods
kubectl get pods -w

# Terminal 3: Ver nodes
kubectl get nodes -w

# Terminal 4: Ver métricas
kubectl top pods -w

# Terminal 5: Ver eventos
kubectl get events -w --sort-by='.lastTimestamp'</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Con kubectl watch:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Todo en una terminal
watch -n 1 'echo "=== HPA ===" &amp;&amp; kubectl get hpa &amp;&amp; \
            echo "=== PODS ===" &amp;&amp; kubectl get pods | tail -5 &amp;&amp; \
            echo "=== NODES ===" &amp;&amp; kubectl get nodes'</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_5_3_caso_práctico_e_commerce_black_friday">7.5.3. 7.5.3 Caso Práctico: E-Commerce Black Friday</h4>
<div class="paragraph">
<p><strong>Prepararse para pico de tráfico:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># 1. Deployment con requests claros
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ecommerce
  labels:
    app: ecommerce
spec:
  replicas: 5  # Base inicial
  selector:
    matchLabels:
      app: ecommerce
  template:
    metadata:
      labels:
        app: ecommerce
    spec:
      containers:
      - name: api
        image: ecommerce-api:1.0

        ports:
        - containerPort: 8080

        # Resource requests CRÍTICOS
        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi

        # Health checks
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5

        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 2

---
# 2. HPA agresivo para Black Friday
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ecommerce-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ecommerce

  minReplicas: 5     # Mínimo 5 Pods siempre
  maxReplicas: 200   # Puede crecer mucho

  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60  # Más agresivo de lo normal

  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 70

  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100  # Duplicar cada 15 segundos
        periodSeconds: 15
      - type: Pods
        value: 10   # O agregar 10 Pods
        periodSeconds: 15
      selectPolicy: Max

    scaleDown:
      stabilizationWindowSeconds: 600  # Esperar 10 minutos
      policies:
      - type: Percent
        value: 25   # Muy conservador
        periodSeconds: 60

---
# 3. PodDisruptionBudget (No matar Pods durante escalado)
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: ecommerce-pdb
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: ecommerce

---
# 4. Service
apiVersion: v1
kind: Service
metadata:
  name: ecommerce
spec:
  type: LoadBalancer
  selector:
    app: ecommerce
  ports:
  - port: 80
    targetPort: 8080
  sessionAffinity: ClientIP  # Sticky sessions</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Monitoreo durante el evento:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Dashboard en tiempo real
while true; do
  clear
  echo "=== ECOMMERCE BLACK FRIDAY DASHBOARD ==="
  echo "Time: $(date)"
  echo ""

  echo "=== HPA Status ==="
  kubectl get hpa ecommerce-hpa

  echo ""
  echo "=== Pod Count ==="
  kubectl get pods -l app=ecommerce | wc -l

  echo ""
  echo "=== Node Count ==="
  kubectl get nodes | tail -n +2 | wc -l

  echo ""
  echo "=== Top CPU Consumers ==="
  kubectl top pods -l app=ecommerce --no-headers | \
    sort -k2 -nr | head -5

  echo ""
  echo "=== Load Balancer ==="
  kubectl get svc ecommerce

  sleep 5
done</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_5_4_debugging_de_autoscaling">7.5.4. 7.5.4 Debugging de Autoscaling</h4>
<div class="paragraph">
<p><strong>HPA no escala:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Verificar HPA status
kubectl describe hpa myapp-hpa

# Razones comunes:
# 1. Metrics no disponibles
kubectl get hpa myapp-hpa
# Si TARGETS muestra "&lt;unknown&gt;", las métricas no están listos

# Solución:
kubectl get deployment myapp -o yaml | grep -A5 "resources:"
# Debe tener requests definidos

# 2. Metrics Server no instalado
kubectl get deployment metrics-server -n kube-system

# 3. CPU muy baja
kubectl top pods
# Si promedio &lt;&lt; threshold, no escala

# 4. Ya está en maxReplicas
kubectl get hpa myapp-hpa
# Si REPLICAS == MAXPODS, está en el límite</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Cluster Autoscaler no agrega nodos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver logs
kubectl logs -n kube-system deployment/cluster-autoscaler

# Buscar errores comunes:
# - "Failed to increase node group size"
#   → Límite de ASG alcanzado
#   → Aumentar max-size en AWS

# - "No node template found"
#   → Node group mal configurada
#   → Verificar tags de Auto Scaling Group

# Verificar Pods pending
kubectl get pods -A --field-selector=status.phase=Pending

# Ver por qué no se asigna
kubectl describe pod POD_NAME
# Buscar "Events" section</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_7_6_ejemplos_completos">7.6. 7.6 Ejemplos Completos</h3>
<div class="sect3">
<h4 id="_ejemplo_1_stack_completo_de_autoscaling">7.6.1. Ejemplo 1: Stack Completo de Autoscaling</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Full autoscaling stack: HPA + Cluster Autoscaler
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-server
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api-server
  template:
    metadata:
      labels:
        app: api-server
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - api-server
              topologyKey: kubernetes.io/hostname

      containers:
      - name: api
        image: api-server:1.0

        ports:
        - containerPort: 8080

        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi

        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10

        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: api-server
spec:
  type: LoadBalancer
  selector:
    app: api-server
  ports:
  - port: 80
    targetPort: 8080

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-server-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-server

  minReplicas: 3
  maxReplicas: 50

  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70

  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80

  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
      - type: Pods
        value: 5
        periodSeconds: 15
      selectPolicy: Max

    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60

---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: api-server-pdb
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: api-server</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplo_2_stateful_app_con_vpa">7.6.2. Ejemplo 2: Stateful App con VPA</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># StatefulSet (aplicación stateful) + VPA
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: cache-server
spec:
  serviceName: cache
  replicas: 3
  selector:
    matchLabels:
      app: cache-server
  template:
    metadata:
      labels:
        app: cache-server
    spec:
      containers:
      - name: redis
        image: redis:7

        ports:
        - containerPort: 6379

        # Sin requests iniciales → VPA las asignará
        resources:
          limits:
            cpu: 2000m
            memory: 2Gi

---
apiVersion: v1
kind: Service
metadata:
  name: cache
spec:
  clusterIP: None
  selector:
    app: cache-server
  ports:
  - port: 6379
    targetPort: 6379

---
# VPA ajusta automáticamente
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: cache-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: cache-server

  updatePolicy:
    updateMode: "Auto"

  resourcePolicy:
    containerPolicies:
    - containerName: redis
      minAllowed:
        cpu: 100m
        memory: 256Mi
      maxAllowed:
        cpu: 2000m
        memory: 2Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_7_7_best_practices">7.7. 7.7 Best Practices</h3>
<div class="paragraph">
<p><strong>1. Siempre definir resource requests</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">❌ Sin requests → HPA no funciona
✅ requests: cpu: 100m, memory: 128Mi</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Usar HPA v2 (no v1)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">❌ autoscaling/v1 → solo CPU
✅ autoscaling/v2 → CPU, memoria, métricas custom</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Combinar HPA + Cluster Autoscaler</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ HPA escala Pods
✅ Cluster Autoscaler escala nodos
✅ Combinados = escalado completo</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. Usar PodDisruptionBudget</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ Evita apagar Pods críticos durante escalado</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>5. Monitorear y alertar</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">✅ Alertas cuando HPA en maxReplicas
✅ Alertas si escalado no responde</code></pre>
</div>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_7_8_resumen_del_módulo_7">7.8. 7.8 Resumen del Módulo 7</h3>
<div class="paragraph">
<p>En este módulo aprendiste:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Escalado Manual</strong>: kubectl scale, editar replicas</p>
<div class="ulist">
<ul>
<li>
<p>Casos: testing, eventos específicos</p>
</li>
<li>
<p>Imperativo vs declarativo</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>HPA (Horizontal Pod Autoscaler)</strong>: Escalar Pods</p>
<div class="ulist">
<ul>
<li>
<p>Basado en CPU, memoria, métricas custom</p>
</li>
<li>
<p>Comportamiento configurable</p>
</li>
<li>
<p>v1 vs v2</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>VPA (Vertical Pod Autoscaler)</strong>: Ajustar recursos</p>
<div class="ulist">
<ul>
<li>
<p>Modos: Off, Initial, Recreate, Auto</p>
</li>
<li>
<p>Right-sizing automático</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Cluster Autoscaler</strong>: Escalar nodos</p>
<div class="ulist">
<ul>
<li>
<p>AWS, GCP, Azure</p>
</li>
<li>
<p>Detecta Pods Pending</p>
</li>
<li>
<p>Agrega nodos automáticamente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Pruebas de Carga</strong>: Validar escalado</p>
<div class="ulist">
<ul>
<li>
<p>Apache Bench, Siege</p>
</li>
<li>
<p>Monitoreo en tiempo real</p>
</li>
<li>
<p>Casos prácticos: Black Friday</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>Con estos conocimientos, estás listo para aprender sobre <strong>Seguridad</strong> en el Módulo 8.</p>
</div>
<hr>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_8_seguridad">8. MÓDULO 8: Seguridad</h2>
<div class="sectionbody">
<div class="paragraph">
<p>La <strong>seguridad en Kubernetes</strong> es multicapa. No es solo RBAC, sino autenticación, autorización, encriptación, network policies, y más.</p>
</div>
<div class="paragraph">
<p><strong>Capas de seguridad:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>┌──────────────────────────────────────────┐
│ 1. Autenticación: ¿Quién eres?          │
│ 2. Autorización: ¿Qué puedes hacer?     │
│ 3. Admission Control: ¿Cumples políticas?│
│ 4. Pod Security: ¿Eres seguro?          │
│ 5. Network Policies: ¿Dónde comunicas?  │
│ 6. Encriptación: ¿Están seguros datos?  │
└──────────────────────────────────────────┘</code></pre>
</div>
</div>
<hr>
<div class="sect2">
<h3 id="_8_1_autenticación_y_rbac">8.1. 8.1 Autenticación y RBAC</h3>
<div class="sect3">
<h4 id="_8_1_1_usuarios_y_service_accounts">8.1.1. 8.1.1 Usuarios y Service Accounts</h4>
<div class="paragraph">
<p>Hay dos tipos de identidades en Kubernetes:</p>
</div>
<div class="sect4">
<h5 id="_usuarios_normales">Usuarios Normales</h5>
<div class="paragraph">
<p>Usuarios del cluster (personas, equipos, CI/CD):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear usuario con certificado x509
# Generar clave privada
openssl genrsa -out alice.key 2048

# Crear solicitud de firma de certificado (CSR)
openssl req -new -key alice.key -out alice.csr \
  -subj "/CN=alice/O=developers"

# Firma el certificado (como admin)
sudo openssl x509 -req -in alice.csr \
  -CA /etc/kubernetes/pki/ca.crt \
  -CAkey /etc/kubernetes/pki/ca.key \
  -CAcreateserial \
  -out alice.crt -days 365

# Crear contexto kubeconfig para Alice
kubectl config set-credentials alice \
  --client-certificate=alice.crt \
  --client-key=alice.key

kubectl config set-context alice-context \
  --cluster=kubernetes \
  --user=alice

# Alice usa su contexto
kubectl config use-context alice-context
kubectl get pods  # Sin permisos aún
# Error: pods is forbidden</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_service_accounts">Service Accounts</h5>
<div class="paragraph">
<p>Para Pods/aplicaciones dentro del cluster:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: ServiceAccount
metadata:
  name: app-sa
  namespace: production

---
# Usar en Pod
apiVersion: v1
kind: Pod
metadata:
  name: app-pod
  namespace: production
spec:
  serviceAccountName: app-sa  # ← Asignar service account
  containers:
  - name: app
    image: myapp:1.0</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver token del service account
kubectl get secret -n production \
  $(kubectl get secret -n production | grep app-sa | awk '{print $1}') \
  -o jsonpath='{.data.token}' | base64 -d

# Usar token en API calls
TOKEN=$(kubectl get secret -n production \
  $(kubectl get secret -n production | grep app-sa | awk '{print $1}') \
  -o jsonpath='{.data.token}' | base64 -d)

curl -H "Authorization: Bearer $TOKEN" \
  https://kubernetes.default.svc.cluster.local/api/v1/namespaces/production/pods \
  --cacert /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_8_1_2_rbac_role_based_access_control">8.1.2. 8.1.2 RBAC (Role-Based Access Control)</h4>
<div class="paragraph">
<p><strong>Concepto RBAC:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>User → RoleBinding → Role → Permissions
      ↑              ↑
      │              └─ Define acciones (get, create, delete)
      └───────────────── Asigna role al usuario</code></pre>
</div>
</div>
<div class="sect4">
<h5 id="_roles_namespaced">Roles (Namespaced)</h5>
<div class="paragraph">
<p>Permiso dentro de un namespace:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: pod-reader
  namespace: production
rules:
# Regla 1: Leer Pods
- apiGroups: [""]  # API core
  resources: ["pods"]
  verbs: ["get", "list", "watch"]

# Regla 2: Acceder a logs
- apiGroups: [""]
  resources: ["pods/log"]
  verbs: ["get"]

# Regla 3: Ejecutar comandos en Pods
- apiGroups: [""]
  resources: ["pods/exec"]
  verbs: ["create", "get"]

# Regla 4: Crear Deployments (limitado)
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get", "list"]
  resourceNames: ["myapp"]  # Solo myapp, no otros</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_rolebinding_namespaced">RoleBinding (Namespaced)</h5>
<div class="paragraph">
<p>Asignar Role a usuario/grupo/service account:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: pod-reader-binding
  namespace: production
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: pod-reader
subjects:
# Usuario normal
- kind: User
  name: alice
  apiGroup: rbac.authorization.k8s.io

# Grupo de usuarios
- kind: Group
  name: developers
  apiGroup: rbac.authorization.k8s.io

# Service Account
- kind: ServiceAccount
  name: app-sa
  namespace: production</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_clusterroles_cluster_wide">ClusterRoles (Cluster-wide)</h5>
<div class="paragraph">
<p>Permiso a nivel de cluster (no namespaced):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: admin-role
rules:
# Todo en API core
- apiGroups: [""]
  resources: ["*"]
  verbs: ["*"]

# Todo en apps
- apiGroups: ["apps"]
  resources: ["*"]
  verbs: ["*"]

# Recursos no-namespaced
- apiGroups: [""]
  resources: ["nodes", "persistentvolumes"]
  verbs: ["get", "list", "watch"]

# Modificar RBAC
- apiGroups: ["rbac.authorization.k8s.io"]
  resources: ["*"]
  verbs: ["*"]</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_clusterrolebinding">ClusterRoleBinding</h5>
<div class="paragraph">
<p>Asignar ClusterRole a nivel de cluster:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: admin-role
subjects:
- kind: User
  name: alice
  apiGroup: rbac.authorization.k8s.io

---
# Rol de solo lectura
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: read-only
rules:
- apiGroups: [""]
  resources: ["*"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["apps", "batch"]
  resources: ["*"]
  verbs: ["get", "list", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: read-only-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: read-only
subjects:
- kind: User
  name: bob
  apiGroup: rbac.authorization.k8s.io</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_8_1_3_roles_predefinidos">8.1.3. 8.1.3 Roles Predefinidos</h4>
<div class="paragraph">
<p>Kubernetes proporciona roles por defecto:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver roles predefinidos
kubectl get clusterroles | grep system

# Roles comunes:
# - system:basic-user
# - system:discover
# - cluster-admin (acceso total)
# - edit (create, update, delete)
# - view (solo lectura)

# Ver qué permisos tiene un role
kubectl describe clusterrole edit

# Usar roles predefinidos
kubectl create clusterrolebinding dev-binding \
  --clusterrole=edit \
  --user=developer@company.com

# Verificar permisos
kubectl auth can-i create pods --as=alice
# yes/no

kubectl auth can-i delete nodes --as=alice --all-namespaces
# no</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_8_1_4_ejemplo_completo_rbac">8.1.4. 8.1.4 Ejemplo Completo RBAC</h4>
<div class="paragraph">
<p><strong>Escenario:</strong> 3 usuarios con diferentes permisos</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># 1. Alice: Admin del cluster
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: alice-admin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: User
  name: alice

---
# 2. Bob: Desarrollador (solo production namespace)
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: dev-role
  namespace: production
rules:
- apiGroups: [""]
  resources: ["pods", "services", "configmaps", "secrets"]
  verbs: ["get", "list", "create", "update", "patch"]
- apiGroups: ["apps"]
  resources: ["deployments", "statefulsets"]
  verbs: ["get", "list", "create", "update", "patch"]
- apiGroups: [""]
  resources: ["pods/logs", "pods/exec"]
  verbs: ["get", "create"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: dev-binding
  namespace: production
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: dev-role
subjects:
- kind: User
  name: bob

---
# 3. Charlie: CI/CD (solo crear/actualizar, no eliminar)
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: cicd-role
  namespace: production
rules:
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get", "list", "create", "update", "patch"]
- apiGroups: [""]
  resources: ["services"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["secrets", "configmaps"]
  verbs: ["get", "list"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: cicd-binding
  namespace: production
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: cicd-role
subjects:
- kind: ServiceAccount
  name: cicd-sa
  namespace: production

---
# 4. Service Account para CI/CD
apiVersion: v1
kind: ServiceAccount
metadata:
  name: cicd-sa
  namespace: production</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_8_2_pod_security">8.2. 8.2 Pod Security</h3>
<div class="sect3">
<h4 id="_8_2_1_security_context">8.2.1. 8.2.1 Security Context</h4>
<div class="paragraph">
<p>Define permisos de seguridad para Pods y contenedores:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: secure-pod
spec:
  # Pod-level security
  securityContext:
    runAsUser: 1000  # UID del usuario
    runAsGroup: 3000  # GID del grupo
    fsGroup: 2000     # GID para filesystem
    seccompProfile:
      type: RuntimeDefault  # Seccomp profile

  containers:
  - name: app
    image: myapp:1.0

    # Container-level security (override pod-level)
    securityContext:
      allowPrivilegeEscalation: false  # No puede usar sudo
      capabilities:
        drop:
        - ALL  # Drop todas las capabilities
        add:
        - NET_BIND_SERVICE  # Excepto esta

      readOnlyRootFilesystem: true  # Filesystem read-only
      runAsNonRoot: true  # No correr como root
      runAsUser: 2000  # UID específico

    ports:
    - containerPort: 8080

    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: data
      mountPath: /data

  volumes:
  - name: tmp
    emptyDir: {}
  - name: data
    emptyDir: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Explicación:</strong>
- <code>runAsUser</code>: Usuario no-root (UID 2000)
- <code>allowPrivilegeEscalation: false</code>: No puede usar setuid
- <code>capabilities</code>: Permisos específicos del kernel
- <code>readOnlyRootFilesystem</code>: No escribir en /
- <code>fsGroup</code>: Para permisos de volúmenes</p>
</div>
</div>
<div class="sect3">
<h4 id="_8_2_2_pod_security_standards_pss">8.2.2. 8.2.2 Pod Security Standards (PSS)</h4>
<div class="paragraph">
<p>Kubernetes proporciona tres estándares de seguridad:</p>
</div>
<div class="sect4">
<h5 id="_restricted_más_seguro">Restricted (Más seguro)</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Namespace
metadata:
  name: secure-namespace
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted

---
# Pod que cumple Restricted
apiVersion: v1
kind: Pod
metadata:
  name: compliant-pod
  namespace: secure-namespace
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
    seccompProfile:
      type: RuntimeDefault

  containers:
  - name: app
    image: myapp:1.0

    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000

    volumeMounts:
    - name: tmp
      mountPath: /tmp

  volumes:
  - name: tmp
    emptyDir: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_baseline_permisivo">Baseline (Permisivo)</h5>
<div class="paragraph">
<p>Permite algunos riesgos de seguridad:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Namespace
metadata:
  name: baseline-namespace
  labels:
    pod-security.kubernetes.io/enforce: baseline

---
# Pod que cumple Baseline (menos restricciones)
apiVersion: v1
kind: Pod
metadata:
  name: baseline-pod
  namespace: baseline-namespace
spec:
  containers:
  - name: app
    image: legacy-app:1.0
    # Sin securityContext requerido</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_privileged_menos_seguro">Privileged (Menos seguro)</h5>
<div class="paragraph">
<p>Para aplicaciones que lo necesitan:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Namespace
metadata:
  name: privileged-namespace
  labels:
    pod-security.kubernetes.io/enforce: privileged

---
# Pod privilegiado (Docker, kubelet, etc)
apiVersion: v1
kind: Pod
metadata:
  name: privileged-pod
  namespace: privileged-namespace
spec:
  securityContext:
    runAsUser: 0  # root

  containers:
  - name: daemon
    image: privileged-app:1.0

    securityContext:
      privileged: true  # Acceso completo al host
      capabilities:
        add:
        - SYS_ADMIN
        - SYS_TIME</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_8_2_3_policies_de_admisión">8.2.3. 8.2.3 Policies de Admisión</h4>
<div class="paragraph">
<p>Controla qué Pods pueden crearse:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># ValidatingAdmissionPolicy: Validar (v1.27+)
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingAdmissionPolicy
metadata:
  name: require-security-context
spec:
  failurePolicy: fail  # Rechazar si falla validación

  matchResources:
    resourceRules:
    - operations: ["CREATE", "UPDATE"]
      apiGroups: [""]
      apiVersions: ["v1"]
      resources: ["pods"]

  validations:
  - expression: "object.spec.securityContext.runAsNonRoot == true"
    message: "Root containers not allowed"

  - expression: "object.spec.securityContext.fsGroup &gt; 0"
    message: "fsGroup must be set"

---
# MutatingAdmissionPolicy: Modificar (v1.27+)
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingAdmissionPolicy
metadata:
  name: add-security-defaults
spec:
  failurePolicy: fail

  matchResources:
    resourceRules:
    - operations: ["CREATE"]
      apiGroups: [""]
      apiVersions: ["v1"]
      resources: ["pods"]

  mutations:
  # Si no tiene securityContext, agregarlo
  - expression: "!has(object.spec, 'securityContext') ? object.spec.securityContext = {runAsNonRoot: true, fsGroup: 1000} : object.spec"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_8_2_4_ejemplo_deployment_seguro">8.2.4. 8.2.4 Ejemplo: Deployment Seguro</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-app
  namespace: production
spec:
  replicas: 2
  selector:
    matchLabels:
      app: secure-app
  template:
    metadata:
      labels:
        app: secure-app
      annotations:
        container.apparmor.security.beta.kubernetes.io/app: runtime/default

    spec:
      # Pod-level security
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 3000
        fsGroup: 2000
        seccompProfile:
          type: RuntimeDefault
        seLinuxOptions:
          level: "s0:c123,c456"

      serviceAccountName: app-sa

      containers:
      - name: app
        image: secure-app:1.0
        imagePullPolicy: Always

        ports:
        - containerPort: 8080
          name: http

        # Container security
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
            add:
            - NET_BIND_SERVICE
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000

        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi

        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10

        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5

        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: cache
          mountPath: /cache

      volumes:
      - name: tmp
        emptyDir: {}
      - name: cache
        emptyDir: {}

---
# Service Account
apiVersion: v1
kind: ServiceAccount
metadata:
  name: app-sa
  namespace: production</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_8_3_network_policies">8.3. 8.3 Network Policies</h3>
<div class="sect3">
<h4 id="_8_3_1_concepto">8.3.1. 8.3.1 Concepto</h4>
<div class="paragraph">
<p>Una <strong>Network Policy</strong> es un firewall para Pods. Define tráfico permitido (ingress/egress).</p>
</div>
<div class="paragraph">
<p><strong>Sin Network Policy:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Todos los Pods pueden hablar con todos
                ↓
┌─────┐     ┌─────┐     ┌─────┐
│Pod A│←───→│Pod B│←───→│Pod C│
└─────┘     └─────┘     └─────┘
    ↑         ↓         ↑
    │         └─────────┤
    └───────────────────┘</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Con Network Policy (default deny):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Tráfico bloqueado por defecto, solo permitir explícitamente
          ↓
┌─────┐  X  ┌─────┐  X  ┌─────┐
│Pod A│     │Pod B│     │Pod C│
└─────┘     └─────┘     └─────┘
    ↑         ↓
    │    (permitido)
    └─────────┘</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_8_3_2_default_deny">8.3.2. 8.3.2 Default Deny</h4>
<div class="paragraph">
<p>Bloquear todo por defecto:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
  namespace: production
spec:
  # Aplica a todos los Pods
  podSelector: {}

  # Negar todo (no hay reglas)
  policyTypes:
  - Ingress
  - Egress</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p>Ahora <strong>todos los Pods están bloqueados</strong>. Necesitas permitir explícitamente.</p>
</div>
</div>
<div class="sect3">
<h4 id="_8_3_3_allow_tráfico_ingress">8.3.3. 8.3.3 Allow Tráfico Ingress</h4>
<div class="paragraph">
<p>Permitir tráfico <strong>hacia</strong> un Pod:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-web-ingress
  namespace: production
spec:
  # Aplica a Pods con label app=web
  podSelector:
    matchLabels:
      app: web

  policyTypes:
  - Ingress

  ingress:
  # Regla 1: Permitir desde Ingress Controller
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8080

  # Regla 2: Permitir desde otros Pods con label client=api
  - from:
    - podSelector:
        matchLabels:
          client: api
    ports:
    - protocol: TCP
      port: 8080

  # Regla 3: Permitir desde IP específica
  - from:
    - ipBlock:
        cidr: 10.0.0.0/8
        except:
        - 10.1.1.0/24
    ports:
    - protocol: TCP
      port: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_8_3_4_allow_tráfico_egress">8.3.4. 8.3.4 Allow Tráfico Egress</h4>
<div class="paragraph">
<p>Permitir tráfico <strong>desde</strong> un Pod:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-api-egress
  namespace: production
spec:
  podSelector:
    matchLabels:
      app: web

  policyTypes:
  - Egress

  egress:
  # Permitir DNS
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: UDP
      port: 53

  # Permitir hacia backend
  - to:
    - podSelector:
        matchLabels:
          app: backend
    ports:
    - protocol: TCP
      port: 5000

  # Permitir hacia internet
  - to:
    - ipBlock:
        cidr: 0.0.0.0/0
        except:
        - 169.254.169.254/32  # No AWS metadata
    ports:
    - protocol: TCP
      port: 443</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_8_3_5_caso_práctico_3_tier_architecture">8.3.5. 8.3.5 Caso Práctico: 3-Tier Architecture</h4>
<div class="paragraph">
<p>Frontend → Backend → Database</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># 1. Default deny all
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress

---
# 2. Frontend: Permite ingress desde Internet
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-frontend-ingress
  namespace: production
spec:
  podSelector:
    matchLabels:
      tier: frontend

  policyTypes:
  - Ingress

  ingress:
  # Desde Ingress Controller
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 80
    - protocol: TCP
      port: 443

---
# 3. Frontend: Permite egress hacia Backend
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-frontend-egress
  namespace: production
spec:
  podSelector:
    matchLabels:
      tier: frontend

  policyTypes:
  - Egress

  egress:
  # DNS
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: UDP
      port: 53

  # Hacia Backend
  - to:
    - podSelector:
        matchLabels:
          tier: backend
    ports:
    - protocol: TCP
      port: 8080

---
# 4. Backend: Permite ingress desde Frontend
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-backend-ingress
  namespace: production
spec:
  podSelector:
    matchLabels:
      tier: backend

  policyTypes:
  - Ingress

  ingress:
  # Solo desde Frontend
  - from:
    - podSelector:
        matchLabels:
          tier: frontend
    ports:
    - protocol: TCP
      port: 8080

---
# 5. Backend: Permite egress hacia Database
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-backend-egress
  namespace: production
spec:
  podSelector:
    matchLabels:
      tier: backend

  policyTypes:
  - Egress

  egress:
  # DNS
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: UDP
      port: 53

  # Hacia Database
  - to:
    - podSelector:
        matchLabels:
          tier: database
    ports:
    - protocol: TCP
      port: 5432

---
# 6. Database: Permite ingress solo desde Backend
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-database-ingress
  namespace: production
spec:
  podSelector:
    matchLabels:
      tier: database

  policyTypes:
  - Ingress

  ingress:
  # Solo desde Backend
  - from:
    - podSelector:
        matchLabels:
          tier: backend
    ports:
    - protocol: TCP
      port: 5432

---
# 7. Deployment: Frontend
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  namespace: production
spec:
  replicas: 2
  selector:
    matchLabels:
      tier: frontend
  template:
    metadata:
      labels:
        tier: frontend
    spec:
      containers:
      - name: frontend
        image: nginx:1.21
        ports:
        - containerPort: 80

---
# 8. Deployment: Backend
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  namespace: production
spec:
  replicas: 2
  selector:
    matchLabels:
      tier: backend
  template:
    metadata:
      labels:
        tier: backend
    spec:
      containers:
      - name: backend
        image: api:1.0
        ports:
        - containerPort: 8080

---
# 9. StatefulSet: Database
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: database
  namespace: production
spec:
  serviceName: database
  replicas: 1
  selector:
    matchLabels:
      tier: database
  template:
    metadata:
      labels:
        tier: database
    spec:
      containers:
      - name: postgres
        image: postgres:15
        ports:
        - containerPort: 5432

---
# 10. Services
apiVersion: v1
kind: Service
metadata:
  name: frontend
  namespace: production
spec:
  type: LoadBalancer
  selector:
    tier: frontend
  ports:
  - port: 80
    targetPort: 80

---
apiVersion: v1
kind: Service
metadata:
  name: backend
  namespace: production
spec:
  type: ClusterIP
  selector:
    tier: backend
  ports:
  - port: 8080
    targetPort: 8080

---
apiVersion: v1
kind: Service
metadata:
  name: database
  namespace: production
spec:
  clusterIP: None
  selector:
    tier: database
  ports:
  - port: 5432
    targetPort: 5432</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_8_3_6_debugging_network_policies">8.3.6. 8.3.6 Debugging Network Policies</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver Network Policies
kubectl get networkpolicies -n production

# Ver detalles
kubectl describe networkpolicy default-deny -n production

# Verificar conectividad
# 1. Ejecutar dentro de Pod
kubectl exec -it pod-name -n production -- /bin/sh

# 2. Intentar conectar
telnet backend.production.svc.cluster.local 8080
# Si falla → Network Policy bloqueando

# 3. Ver logs de red (si está disponible)
kubectl logs -n kube-system -l app=calico-node | grep -i policy

# Herramientas de testing
kubectl run test-pod --image=busybox -it --rm -n production \
  -- sh -c "wget -O- http://backend:8080"
# Éxito o timeout = Network Policy bloqueando

# Ver flujo exacto
kubectl get networkpolicies -A -o yaml | grep -A 20 "to:"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_8_4_encriptación_y_certificados">8.4. 8.4 Encriptación y Certificados</h3>
<div class="sect3">
<h4 id="_8_4_1_tlsssl_certificates">8.4.1. 8.4.1 TLS/SSL Certificates</h4>
<div class="sect4">
<h5 id="_obtener_certificado_lets_encrypt">Obtener Certificado (Let&#8217;s Encrypt)</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalar cert-manager
helm repo add jetstack https://charts.jetstack.io
helm install cert-manager jetstack/cert-manager \
  --namespace cert-manager --create-namespace \
  --set installCRDs=true

# Crear ClusterIssuer
cat &gt; cluster-issuer.yaml &lt;&lt; EOF
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: admin@example.com
    privateKeySecretRef:
      name: letsencrypt-prod
    solvers:
    - http01:
        ingress:
          class: nginx
EOF

kubectl apply -f cluster-issuer.yaml

# Verificar
kubectl get clusterissuer
# NAME                READY
# letsencrypt-prod    True</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect4">
<h5 id="_usar_certificados_en_ingress">Usar Certificados en Ingress</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: secure-app-ingress
  namespace: production
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  ingressClassName: nginx

  tls:
  - hosts:
    - app.example.com
    secretName: app-tls-cert  # cert-manager crea esto

  rules:
  - host: app.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: app
            port:
              number: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Cert-manager crea Secret automáticamente
kubectl get secret app-tls-cert -n production -o yaml

# Renovación automática (cada 30 días)
kubectl logs -n cert-manager deployment/cert-manager | grep renew

# Ver certificados
kubectl get certificate -n production

# Verificar certificado
kubectl get secret app-tls-cert -n production \
  -o jsonpath='{.data.tls\.crt}' | base64 -d | openssl x509 -text -noout</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_8_4_2_encriptación_en_reposo_etcd">8.4.2. 8.4.2 Encriptación en Reposo (etcd)</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Habilitar encriptación en etcd
# Editar API Server en /etc/kubernetes/manifests/kube-apiserver.yaml

# Crear archivo de configuración
cat &gt; /etc/kubernetes/enc/encryption.yaml &lt;&lt; EOF
apiVersion: apiserver.config.k8s.io/v1
kind: EncryptionConfiguration
resources:
  - resources:
    - secrets
    - configmaps
    providers:
    - aescbc:
        keys:
        - name: key1
          secret: $(head -c 32 /dev/urandom | base64)
    - identity: {}
EOF

# Agregar a API Server
spec:
  containers:
  - command:
    - kube-apiserver
    - --encryption-provider-config=/etc/kubernetes/enc/encryption.yaml
    volumeMounts:
    - name: encryption-config
      mountPath: /etc/kubernetes/enc
      readOnly: true

volumes:
- name: encryption-config
  hostPath:
    path: /etc/kubernetes/enc
    type: DirectoryOrCreate

# Reiniciar
sudo systemctl restart kubelet

# Verificar encriptación (en la base de datos)
# Secrets estarán encriptados en etcd</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_8_4_3_secrets_con_encryption">8.4.3. 8.4.3 Secrets con Encryption</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Secret encriptado automáticamente
apiVersion: v1
kind: Secret
metadata:
  name: app-secret
  namespace: production
stringData:
  database_password: "secure_password_123"
  api_key: "secret_key_xyz"

---
# Usar en Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app
  namespace: production
spec:
  replicas: 1
  selector:
    matchLabels:
      app: app
  template:
    metadata:
      labels:
        app: app
    spec:
      containers:
      - name: app
        image: app:1.0
        env:
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: app-secret
              key: database_password
        - name: API_KEY
          valueFrom:
            secretKeyRef:
              name: app-secret
              key: api_key</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_8_5_auditoría_y_monitoreo">8.5. 8.5 Auditoría y Monitoreo</h3>
<div class="sect3">
<h4 id="_8_5_1_audit_logging">8.5.1. 8.5.1 Audit Logging</h4>
<div class="paragraph">
<p>Registra todas las acciones en el cluster:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear archivo de política de auditoría
cat &gt; /etc/kubernetes/audit-policy.yaml &lt;&lt; EOF
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
  # Log all requests at Metadata level
  - level: Metadata
    omitStages:
    - RequestReceived

  # Log pod exec at RequestResponse level
  - level: RequestResponse
    verbs: ["create"]
    resources:
    - group: ""
      resources: ["pods/exec"]

  # Log secret access
  - level: RequestResponse
    verbs: ["get", "create", "update", "patch", "delete"]
    resources:
    - group: ""
      resources: ["secrets"]

  # Log everything else at Metadata level
  - level: Metadata
EOF

# Configurar en API Server
--audit-policy-file=/etc/kubernetes/audit-policy.yaml
--audit-log-path=/var/log/kubernetes/audit.log
--audit-log-maxage=30
--audit-log-maxbackup=10</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_8_5_2_rbac_auditoría">8.5.2. 8.5.2 RBAC Auditoría</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver quién puede hacer qué
kubectl get clusterrolebindings -A

# Ver acceso negado
kubectl get events -A | grep Forbidden

# Verificar permisos de usuario
kubectl auth can-i list pods --as=alice
kubectl auth can-i delete deployments --as=bob
kubectl auth can-i '*' '*' --as=alice --all-namespaces</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_8_5_3_falco_runtime_security">8.5.3. 8.5.3 Falco (Runtime Security)</h4>
<div class="paragraph">
<p>Monitorea comportamiento anómalo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalar Falco
kubectl create namespace falco
helm repo add falcosecurity https://falcosecurity.github.io/charts
helm install falco falcosecurity/falco \
  --namespace falco \
  --set falco.grpc.enabled=true

# Ver alertas
kubectl logs -n falco -f -l app=falco
# Detectable anomalies:
# - Process running as root
# - Unexpected network connection
# - Unauthorized file access
# - Privilege escalation attempt</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_8_6_ejemplo_completo_aplicación_segura">8.6. 8.6 Ejemplo Completo: Aplicación Segura</h3>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Namespace seguro
apiVersion: v1
kind: Namespace
metadata:
  name: secure-app
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted

---
# Service Account
apiVersion: v1
kind: ServiceAccount
metadata:
  name: app-sa
  namespace: secure-app

---
# Role limitado
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: app-role
  namespace: secure-app
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get"]
  resourceNames: ["app-secret"]

---
# RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: app-role-binding
  namespace: secure-app
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: app-role
subjects:
- kind: ServiceAccount
  name: app-sa
  namespace: secure-app

---
# Secret
apiVersion: v1
kind: Secret
metadata:
  name: app-secret
  namespace: secure-app
stringData:
  db_password: "secure_password"
  api_key: "secret_key"

---
# Network Policy: Default Deny
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny
  namespace: secure-app
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress

---
# Network Policy: Allow Ingress
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-ingress
  namespace: secure-app
spec:
  podSelector:
    matchLabels:
      app: secure-app

  policyTypes:
  - Ingress

  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8080

---
# Network Policy: Allow Egress
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-egress
  namespace: secure-app
spec:
  podSelector:
    matchLabels:
      app: secure-app

  policyTypes:
  - Egress

  egress:
  # DNS
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: UDP
      port: 53

  # Externa API
  - to:
    - ipBlock:
        cidr: 0.0.0.0/0
        except:
        - 169.254.169.254/32
    ports:
    - protocol: TCP
      port: 443

---
# Deployment Seguro
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-app
  namespace: secure-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: secure-app
  template:
    metadata:
      labels:
        app: secure-app

    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 3000
        fsGroup: 2000
        seccompProfile:
          type: RuntimeDefault

      serviceAccountName: app-sa

      containers:
      - name: app
        image: secure-app:1.0
        imagePullPolicy: Always

        ports:
        - containerPort: 8080
          name: http

        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
            add:
            - NET_BIND_SERVICE
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000

        env:
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: app-secret
              key: db_password
        - name: API_KEY
          valueFrom:
            secretKeyRef:
              name: app-secret
              key: api_key

        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi

        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10

        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5

        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: cache
          mountPath: /cache

      volumes:
      - name: tmp
        emptyDir: {}
      - name: cache
        emptyDir: {}

---
# Service
apiVersion: v1
kind: Service
metadata:
  name: secure-app
  namespace: secure-app
spec:
  type: LoadBalancer
  selector:
    app: secure-app
  ports:
  - port: 8080
    targetPort: 8080
    name: http

---
# PodDisruptionBudget
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: secure-app-pdb
  namespace: secure-app
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: secure-app</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_8_7_best_practices">8.7. 8.7 Best Practices</h3>
<div class="paragraph">
<p><strong>1. Principio de Menor Privilegio</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">❌ runAsUser: 0 (root)
✅ runAsUser: 1000 (non-root)
✅ allowPrivilegeEscalation: false</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. RBAC Restrictivo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">❌ cluster-admin para todos
✅ Roles específicos por función
✅ Service Accounts con permisos limitados</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Network Policies Defaut Deny</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">❌ Sin Network Policies
✅ Default deny all + explicit allow</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. Secrets Encriptados</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">❌ Passwords en ConfigMaps
✅ Secrets con encryption-at-rest
✅ Secret management externo (Vault)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>5. Auditoría y Monitoreo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">✅ Audit logging habilitado
✅ Falco para runtime security
✅ Alertas en acciones sospechosas</code></pre>
</div>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_8_8_resumen_del_módulo_8">8.8. 8.8 Resumen del Módulo 8</h3>
<div class="paragraph">
<p>En este módulo aprendiste:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Autenticación y RBAC</strong>: Control de acceso</p>
<div class="ulist">
<ul>
<li>
<p>Usuarios y Service Accounts</p>
</li>
<li>
<p>Roles, RoleBindings, ClusterRoles</p>
</li>
<li>
<p>RBAC granular</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Pod Security</strong>: Hardening de Pods</p>
<div class="ulist">
<ul>
<li>
<p>Security Context (runAsUser, capabilities)</p>
</li>
<li>
<p>Pod Security Standards (Restricted, Baseline)</p>
</li>
<li>
<p>Admission Policies</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Network Policies</strong>: Firewall para Pods</p>
<div class="ulist">
<ul>
<li>
<p>Default deny</p>
</li>
<li>
<p>Ingress/Egress rules</p>
</li>
<li>
<p>3-tier architecture example</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Encriptación</strong>: Proteger datos</p>
<div class="ulist">
<ul>
<li>
<p>TLS/SSL Certificates</p>
</li>
<li>
<p>Encryption-at-rest en etcd</p>
</li>
<li>
<p>Secrets management</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Auditoría y Monitoreo</strong>: Detección de amenazas</p>
<div class="ulist">
<ul>
<li>
<p>Audit logging</p>
</li>
<li>
<p>RBAC auditoría</p>
</li>
<li>
<p>Falco runtime security</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>Con estos conocimientos, estás listo para aprender sobre <strong>Monitoreo y Logging</strong> en el Módulo 9.</p>
</div>
<hr>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_9_monitoreo_y_logging">9. MÓDULO 9: Monitoreo y Logging</h2>
<div class="sectionbody">
<div class="paragraph">
<p><strong>Observabilidad</strong> es la capacidad de entender qué está pasando en tu cluster. Se basa en <strong>3 pilares</strong>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>┌──────────────────────────────────────────────┐
│       OBSERVABILIDAD EN KUBERNETES           │
├──────────────────────────────────────────────┤
│ 1. MÉTRICAS: ¿Cuál es el estado actual?     │
│    (CPU, memoria, requests/segundo)         │
│                                              │
│ 2. LOGS: ¿Qué eventos ocurrieron?           │
│    (errores, warnings, info)                │
│                                              │
│ 3. TRAZAS: ¿Cuál es el flujo exacto?        │
│    (distributed tracing, latencia)          │
└──────────────────────────────────────────────┘</code></pre>
</div>
</div>
<hr>
<div class="sect2">
<h3 id="_9_1_metrics_server_y_recolección_de_métricas">9.1. 9.1 Metrics Server y Recolección de Métricas</h3>
<div class="sect3">
<h4 id="_9_1_1_qué_es_metrics_server">9.1.1. 9.1.1 ¿Qué es Metrics Server?</h4>
<div class="paragraph">
<p>Recolecta métricas de CPU y memoria de Pods y Nodes. Es el base para HPA y kubectl top.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalar Metrics Server
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# Verificar instalación
kubectl get deployment metrics-server -n kube-system
kubectl get apiservice v1beta1.metrics.k8s.io -o yaml

# Ver métricas
kubectl top nodes
# NAME       CPU(cores)   CPU%   MEMORY(Mi)   MEMORY%
# worker-1   500m         25%    1024Mi       50%

kubectl top pods -n production
# NAME          CPU(cores)   MEMORY(Mi)
# app-pod       100m         256Mi
# db-pod        200m         512Mi

# Ver métricas de un namespace específico
kubectl top pods -n kube-system --sort-by=memory</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_9_1_2_fuentes_de_métricas">9.1.2. 9.1.2 Fuentes de Métricas</h4>
<div class="paragraph">
<p><strong>Kubelet</strong> (en cada Node) expone métricas:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver endpoint de métricas (puerto 10250)
curl -k --cert /etc/kubernetes/pki/apiserver.crt \
     --key /etc/kubernetes/pki/apiserver.key \
     https://10.0.0.10:10250/metrics

# Métricas expuestas:
# - container_cpu_usage_seconds_total
# - container_memory_usage_bytes
# - container_network_transmit_bytes_total
# - pod_network_receive_bytes_total
# - etc.</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_9_1_3_scrapers_de_métricas_personalizadas">9.1.3. 9.1.3 Scrapers de Métricas Personalizadas</h4>
<div class="paragraph">
<p>Exponer métricas desde tu aplicación:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Deployment con actuator para Prometheus
apiVersion: apps/v1
kind: Deployment
metadata:
  name: metrics-app
  namespace: production
spec:
  replicas: 1
  selector:
    matchLabels:
      app: metrics-app
  template:
    metadata:
      labels:
        app: metrics-app
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      containers:
      - name: app
        image: my-app:1.0

        ports:
        - containerPort: 8080
          name: metrics

        env:
        - name: MANAGEMENT_ENDPOINTS_WEB_EXPOSURE_INCLUDE
          value: "health,metrics,prometheus"

        livenessProbe:
          httpGet:
            path: /actuator/health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10

---
# Service con Service Monitor (para Prometheus)
apiVersion: v1
kind: Service
metadata:
  name: metrics-app
  namespace: production
  labels:
    app: metrics-app
spec:
  type: ClusterIP
  selector:
    app: metrics-app
  ports:
  - port: 8080
    targetPort: 8080
    name: metrics</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Verificar que la aplicación expone métricas
kubectl port-forward -n production svc/metrics-app 8080:8080
curl http://localhost:8080/metrics | head -20

# OUTPUT:
# # HELP jvm_memory_used_bytes The amount of used memory
# # TYPE jvm_memory_used_bytes gauge
# jvm_memory_used_bytes{area="heap"} 256000000
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_9_2_prometheus">9.2. 9.2 Prometheus</h3>
<div class="sect3">
<h4 id="_9_2_1_arquitectura_de_prometheus">9.2.1. 9.2.1 Arquitectura de Prometheus</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>┌────────────────────────────────────────┐
│   Prometheus Server                    │
│  ┌──────────────────────────────────┐  │
│  │ Time Series Database (TSDB)      │  │
│  │ Almacena: métrica, labels, valor │  │
│  │ Ejemplo: cpu_usage{pod=app}=50%  │  │
│  └──────────────────────────────────┘  │
│  ┌──────────────────────────────────┐  │
│  │ Alert Manager                    │  │
│  │ Envia alertas (email, Slack, etc)│  │
│  └──────────────────────────────────┘  │
└────────────────────────────────────────┘
         ↑                    ↓
    PULL Metrics         Send Alerts
         ↑                    ↓
   ┌──────────┐         ┌──────────┐
   │ Kubelet  │         │ AlertMgr │
   │Exporters │         │ Routes   │
   │ Apps     │         │ Webhooks │
   └──────────┘         └──────────┘</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_9_2_2_instalación_de_prometheus">9.2.2. 9.2.2 Instalación de Prometheus</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Opción 1: Con Helm (recomendado)
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring --create-namespace \
  --set prometheus.prometheusSpec.retention=7d

# Verificar instalación
kubectl get pods -n monitoring
# prometheus-kube-prom-prometheus-0
# prometheus-grafana-xxxxx
# prometheus-kube-prom-operator-xxxxx

# Acceder a Prometheus (port-forward)
kubectl port-forward -n monitoring svc/prometheus-kube-prom-prometheus 9090:9090
# http://localhost:9090</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_9_2_3_configuración_de_prometheus">9.2.3. 9.2.3 Configuración de Prometheus</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># ConfigMap con scrape config
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    # AlertManager config
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          - alertmanager:9093

    rule_files:
    - '/etc/prometheus/rules/*.yml'

    scrape_configs:

    # Kubernetes API Server
    - job_name: 'kubernetes-apiservers'
      kubernetes_sd_configs:
      - role: endpoints
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https

    # Kubernetes Nodes
    - job_name: 'kubernetes-nodes'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)

    # Kubernetes Pods (con anotaciones)
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name

    # aplicaciones custom
    - job_name: 'custom-app'
      scrape_interval: 30s
      static_configs:
      - targets: ['app-metrics:8080']
        labels:
          app: 'my-app'</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_9_2_4_promql_prometheus_query_language">9.2.4. 9.2.4 PromQL (Prometheus Query Language)</h4>
<div class="paragraph">
<p>Querías básicas:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># En Prometheus UI: http://localhost:9090

# 1. Métrica simple
container_cpu_usage_seconds_total

# 2. Con filtro de label
container_cpu_usage_seconds_total{pod="app-pod"}

# 3. Multiplos labels
container_cpu_usage_seconds_total{pod="app-pod", namespace="production"}

# 4. Rate (cambio por segundo, últimos 5 minutos)
rate(container_cpu_usage_seconds_total[5m])

# 5. Aumento (incremento total)
increase(http_requests_total[5m])

# 6. Promedio
avg(container_memory_usage_bytes)

# 7. Percentil
histogram_quantile(0.95, http_request_duration_seconds_bucket)

# 8. Sum by labels
sum(rate(http_requests_total[5m])) by (status_code)

# 9. Top 5 pods por CPU
topk(5, container_cpu_usage_seconds_total)

# 10. Predicción (trending)
predict_linear(disk_free_bytes[1h], 3600)  # Predicción 1 hora</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_9_2_5_alert_rules">9.2.5. 9.2.5 Alert Rules</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># PrometheusRule
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: app-alerts
  namespace: monitoring
spec:
  groups:

  # Grupo 1: CPU
  - name: cpu.rules
    interval: 30s
    rules:
    - alert: HighCPUUsage
      expr: rate(container_cpu_usage_seconds_total[5m]) &gt; 0.8
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "High CPU usage: {{ $labels.pod }}"
        description: "Pod {{ $labels.pod }} CPU: {{ $value | humanizePercentage }}"

    - alert: CriticalCPUUsage
      expr: rate(container_cpu_usage_seconds_total[5m]) &gt; 0.95
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "Critical CPU: {{ $labels.pod }}"
        description: "Pod CPU: {{ $value | humanizePercentage }}"

  # Grupo 2: Memoria
  - name: memory.rules
    interval: 30s
    rules:
    - alert: HighMemoryUsage
      expr: container_memory_usage_bytes / container_spec_memory_limit_bytes &gt; 0.8
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "High memory: {{ $labels.pod }}"
        description: "Memory {{ $value | humanizePercentage }}"

    - alert: OOMKilled
      expr: increase(container_last_seen[1m]) == 0 and container_memory_usage_bytes &gt; 0
      for: 1m
      labels:
        severity: critical

  # Grupo 3: Disponibilidad
  - name: availability.rules
    interval: 30s
    rules:
    - alert: PodNotReady
      expr: kube_pod_status_ready{condition="false"} == 1
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Pod not ready: {{ $labels.pod }}"

    - alert: DeploymentReplicasMismatch
      expr: kube_deployment_spec_replicas != kube_deployment_status_replicas_available
      for: 5m
      labels:
        severity: warning</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_9_2_6_alertmanager">9.2.6. 9.2.6 AlertManager</h4>
<div class="paragraph">
<p>Enrutar alertas a diferentes canales:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># AlertManager config
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m
      slack_api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'

    route:
      # Receptor por defecto
      receiver: 'default'
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h

      # Sub-rutas
      routes:

      # Alertas críticas → oncall team
      - match:
          severity: critical
        receiver: 'oncall-pagerduty'
        continue: true
        group_wait: 0s

      # Warnings → engineering channel
      - match:
          severity: warning
        receiver: 'slack-engineering'
        group_wait: 30s

      # Database alerts → DBA
      - match:
          component: database
        receiver: 'email-dba'

    receivers:

    # Default: Slack
    - name: 'default'
      slack_configs:
      - channel: '#alerts'
        title: 'Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

    # PagerDuty (oncall)
    - name: 'oncall-pagerduty'
      pagerduty_configs:
      - service_key: 'YOUR_PAGERDUTY_KEY'
        description: '{{ .GroupLabels.alertname }}'

    # Engineering channel
    - name: 'slack-engineering'
      slack_configs:
      - channel: '#engineering'
        title: 'Warning: {{ .GroupLabels.alertname }}'

    # Email DBA
    - name: 'email-dba'
      email_configs:
      - to: 'dba@company.com'
        from: 'alertmanager@company.com'
        smarthost: 'smtp.company.com:587'
        auth_username: 'alertmanager'
        auth_password: 'password'
        headers:
          Subject: 'Database Alert: {{ .GroupLabels.alertname }}'

    inhibit_rules:
    # Si hay alerta crítica, suprimir warning del mismo pod
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['pod', 'namespace']</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_9_3_grafana">9.3. 9.3 Grafana</h3>
<div class="sect3">
<h4 id="_9_3_1_instalación_de_grafana">9.3.1. 9.3.1 Instalación de Grafana</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ya incluido en el Helm chart de Prometheus
# O instalarlo específicamente:

helm repo add grafana https://grafana.github.io/helm-charts
helm install grafana grafana/grafana \
  --namespace monitoring \
  --set adminPassword=admin \
  --set persistence.enabled=true

# Port-forward
kubectl port-forward -n monitoring svc/grafana 3000:80
# http://localhost:3000
# Admin / admin

# Obtener contraseña
kubectl get secret grafana -n monitoring -o jsonpath="{.data.admin-password}" | base64 -d</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_9_3_2_conectar_prometheus_como_data_source">9.3.2. 9.3.2 Conectar Prometheus como Data Source</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Datasource de Prometheus
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasource-prometheus
  namespace: monitoring
data:
  prometheus.yaml: |
    apiVersion: 1
    datasources:
    - name: Prometheus
      type: prometheus
      access: proxy
      url: http://prometheus-kube-prom-prometheus:9090
      isDefault: true
      jsonData:
        timeInterval: 30s
      editable: true</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_9_3_3_dashboard_personalizado_json">9.3.3. 9.3.3 Dashboard Personalizado (JSON)</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># ConfigMap con Dashboard JSON
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboard-app
  namespace: monitoring
data:
  app-dashboard.json: |
    {
      "dashboard": {
        "title": "Application Performance",
        "timezone": "UTC",
        "panels": [
          {
            "id": 1,
            "title": "CPU Usage",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(container_cpu_usage_seconds_total{pod=~\"$pod\"}[5m])",
                "refId": "A"
              }
            ],
            "yaxes": [
              {
                "format": "short",
                "label": "CPU (cores)"
              }
            ]
          },
          {
            "id": 2,
            "title": "Memory Usage",
            "type": "graph",
            "targets": [
              {
                "expr": "container_memory_usage_bytes{pod=~\"$pod\"} / 1024 / 1024",
                "refId": "A"
              }
            ],
            "yaxes": [
              {
                "format": "short",
                "label": "Memory (MB)"
              }
            ]
          },
          {
            "id": 3,
            "title": "Network In",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(container_network_receive_bytes_total{pod=~\"$pod\"}[5m])",
                "refId": "A"
              }
            ]
          },
          {
            "id": 4,
            "title": "Network Out",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(container_network_transmit_bytes_total{pod=~\"$pod\"}[5m])",
                "refId": "A"
              }
            ]
          },
          {
            "id": 5,
            "title": "HTTP Requests",
            "type": "stat",
            "targets": [
              {
                "expr": "sum(rate(http_requests_total{pod=~\"$pod\"}[5m])) by (status_code)",
                "refId": "A"
              }
            ]
          },
          {
            "id": 6,
            "title": "Request Duration (p95)",
            "type": "graph",
            "targets": [
              {
                "expr": "histogram_quantile(0.95, http_request_duration_seconds_bucket{pod=~\"$pod\"})",
                "refId": "A"
              }
            ]
          }
        ],
        "templating": {
          "list": [
            {
              "name": "pod",
              "type": "query",
              "datasource": "Prometheus",
              "query": "label_values(container_cpu_usage_seconds_total, pod)",
              "includeAll": true,
              "multi": true,
              "allValue": ".*"
            }
          ]
        }
      }
    }</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_9_3_4_alertas_en_grafana">9.3.4. 9.3.4 Alertas en Grafana</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Notification Channel
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-notification-slack
  namespace: monitoring
data:
  slack-notification.yaml: |
    apiVersion: 1
    notificationChannels:
    - name: Slack
      type: slack
      uid: slack-channel
      isDefault: false
      settings:
        url: https://hooks.slack.com/services/YOUR/WEBHOOK
        channel: "#alerts"
        username: "Grafana Bot"
        mentionGroups: "@oncall"

---
# Alert Rule en Grafana
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-alert-rule
  namespace: monitoring
data:
  alert-rule.yaml: |
    uid: app-cpu-alert
    title: High CPU Alert
    condition: B
    data:
    - refId: A
      queryType: ""
      relativeTimeRange:
        from: 10m
        to: now
      datasourceUid: prometheus-uid
      model:
        expr: 'rate(container_cpu_usage_seconds_total[5m]) &gt; 0.8'
    - refId: B
      queryType: ""
      datasourceUid: "-100"
      model:
        conditions:
        - evaluator:
            params:
            - 0
            type: gt
          operator:
            type: and
          query:
            params:
            - A
          reducer:
            params: []
            type: last
          type: query
        datasourceUid: "-100"
        expression: A
    noDataState: NoData
    execErrState: Alerting
    for: 5m
    annotations:
      description: Pod CPU usage is &gt; 80%
      summary: High CPU Alert
    labels:
      severity: warning</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_9_4_elk_stack_elasticsearch_logstash_kibana">9.4. 9.4 ELK Stack: Elasticsearch, Logstash, Kibana</h3>
<div class="sect3">
<h4 id="_9_4_1_arquitectura_de_logging">9.4.1. 9.4.1 Arquitectura de Logging</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Pod Logs → Fluentd → Elasticsearch → Kibana
                            ↑
                         (Search)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_9_4_2_instalación_de_elk_stack">9.4.2. 9.4.2 Instalación de ELK Stack</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Helm chart para ECK (Elasticsearch Cloud on Kubernetes)
helm repo add elastic https://helm.elastic.co
helm repo update

# Instalar operator
helm install elastic-operator elastic/eck-operator \
  --namespace elastic-system --create-namespace

# Crear Elasticsearch cluster
cat &gt; elasticsearch.yaml &lt;&lt; EOF
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: quickstart
  namespace: elastic-system
spec:
  version: 8.10.0
  nodeSets:
  - name: default
    count: 1
    config:
      node.store.allow_mmap: false
    podTemplate:
      spec:
        containers:
        - name: elasticsearch
          resources:
            requests:
              memory: 512Mi
              cpu: 250m
            limits:
              memory: 2Gi
              cpu: 1000m
EOF

kubectl apply -f elasticsearch.yaml

# Ver Elasticsearch
kubectl get elasticsearch -n elastic-system
kubectl port-forward -n elastic-system svc/quickstart-es-http 9200:9200</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_9_4_3_fluentd_para_recolectar_logs">9.4.3. 9.4.3 Fluentd para Recolectar Logs</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># ConfigMap para Fluentd
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: logging
data:
  fluent.conf: |
    &lt;source&gt;
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      read_from_head true
      &lt;parse&gt;
        @type json
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      &lt;/parse&gt;
    &lt;/source&gt;

    &lt;filter kubernetes.**&gt;
      @type kubernetes_metadata
      kubernetes_url "#{ENV['FLUENT_FILTER_KUBERNETES_URL'] || 'https://' + ENV.fetch('KUBERNETES_SERVICE_HOST') + ':' + ENV.fetch('KUBERNETES_SERVICE_PORT') + '/api'}"
      verify_ssl "#{ENV['KUBERNETES_VERIFY_SSL'] || true}"
      ca_file "#{ENV['KUBERNETES_CA_FILE']}"
    &lt;/filter&gt;

    &lt;match **&gt;
      @type elasticsearch
      @id output_elasticsearch
      @log_level info
      include_tag_key true
      host elasticsearch.elastic-system.svc.cluster.local
      port 9200
      path /
      logstash_format true
      logstash_prefix kubernetes
      &lt;buffer&gt;
        @type file
        path /var/log/fluentd-buffers/kubernetes.system.buffer
        flush_mode interval
        retry_type exponential_backoff
        flush_interval 5s
        retry_forever false
        retry_max_interval 30
        chunk_limit_size "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_CHUNK_LIMIT_SIZE'] || '8M'}"
      &lt;/buffer&gt;
    &lt;/match&gt;

---
# DaemonSet para Fluentd
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: logging
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
    spec:
      serviceAccountName: fluentd
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule

      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch.elastic-system.svc.cluster.local"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        - name: FLUENT_ELASTICSEARCH_LOGSTASH_PREFIX
          value: "kubernetes"

        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: config
          mountPath: /fluentd/etc/fluent.conf
          subPath: fluent.conf

      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: config
        configMap:
          name: fluentd-config

---
# ServiceAccount y RBAC para Fluentd
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluentd
  namespace: logging

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fluentd
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - namespaces
  verbs:
  - get
  - list
  - watch

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: fluentd
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: fluentd
subjects:
- kind: ServiceAccount
  name: fluentd
  namespace: logging</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_9_4_4_kibana">9.4.4. 9.4.4 Kibana</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear Kibana
cat &gt; kibana.yaml &lt;&lt; EOF
apiVersion: kibana.k8s.elastic.co/v1
kind: Kibana
metadata:
  name: quickstart
  namespace: elastic-system
spec:
  version: 8.10.0
  count: 1
  elasticsearchRef:
    name: quickstart
  podTemplate:
    spec:
      containers:
      - name: kibana
        resources:
          requests:
            memory: 512Mi
            cpu: 250m
          limits:
            memory: 1Gi
            cpu: 500m
EOF

kubectl apply -f kibana.yaml

# Ver Kibana
kubectl get kibana -n elastic-system

# Port-forward
kubectl port-forward -n elastic-system svc/quickstart-kb-http 5601:5601
# http://localhost:5601</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_9_4_5_búsqueda_en_kibana_kql">9.4.5. 9.4.5 Búsqueda en Kibana (KQL)</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Kibana Query Language (KQL) - búsquedas comunes

# 1. Pod específico
kubernetes.pod_name : "app-pod"

# 2. Namespace específico
kubernetes.namespace_name : "production"

# 3. Nivel de log
level : "ERROR"

# 4. Rango de tiempo
@timestamp &gt;= now-1h

# 5. Combinaciones
kubernetes.pod_name : "app-*" AND level : "ERROR"

# 6. Mensajes que contengan
message : "*timeout*"

# 7. Excluir
NOT kubernetes.pod_name : "debug-pod"

# 8. Status codes
http.status_code : 500

# 9. CPU alto
system.cpu.system.pct &gt; 0.8

# 10. Análisis por Pod
kibana.alert.rule.uuid : "*" | stats count() by kubernetes.pod_name</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_9_5_distributed_tracing_con_jaeger">9.5. 9.5 Distributed Tracing con Jaeger</h3>
<div class="sect3">
<h4 id="_9_5_1_concepto">9.5.1. 9.5.1 Concepto</h4>
<div class="paragraph">
<p>Tracer el camino de una request a través del cluster:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Cliente → API Gateway → Microservicio A → Microservicio B → Base de datos
          [Span 1]         [Span 2]         [Span 3]         [Span 4]</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_9_5_2_instalación_de_jaeger">9.5.2. 9.5.2 Instalación de Jaeger</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Helm chart para Jaeger
helm repo add jaegertracing https://jaegertracing.github.io/helm-charts
helm repo update

helm install jaeger jaegertracing/jaeger \
  --namespace observability --create-namespace \
  --set collector.service.type=ClusterIP

# Verificar instalación
kubectl get pods -n observability | grep jaeger

# Port-forward
kubectl port-forward -n observability svc/jaeger 6831:6831/udp
kubectl port-forward -n observability svc/jaeger-query 16686:16686
# http://localhost:16686</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_9_5_3_instrumentar_aplicación_opentelemetry">9.5.3. 9.5.3 Instrumentar Aplicación (OpenTelemetry)</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Pod con OpenTelemetry agent
apiVersion: apps/v1
kind: Deployment
metadata:
  name: traced-app
  namespace: production
spec:
  replicas: 1
  selector:
    matchLabels:
      app: traced-app
  template:
    metadata:
      labels:
        app: traced-app
    spec:
      containers:
      - name: app
        image: my-traced-app:1.0

        ports:
        - containerPort: 8080

        # Variables de entorno para Jaeger
        env:
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: "http://jaeger-collector:4318"
        - name: OTEL_EXPORTER_OTLP_HEADERS
          value: "authorization=Bearer token123"
        - name: OTEL_SERVICE_NAME
          value: "traced-app"
        - name: OTEL_TRACES_SAMPLER
          value: "always_on"
        - name: OTEL_TRACES_SAMPLER_ARG
          value: "0.1"  # 10% sampling
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: "service.namespace=production,service.version=1.0"

---
# Service para tracing
apiVersion: v1
kind: Service
metadata:
  name: traced-app
  namespace: production
spec:
  type: ClusterIP
  selector:
    app: traced-app
  ports:
  - port: 8080
    targetPort: 8080</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_9_5_4_análisis_en_jaeger">9.5.4. 9.5.4 Análisis en Jaeger</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># En Jaeger UI: http://localhost:16686

# 1. Buscar por service
Service: traced-app

# 2. Ver traces de operación
Operation: GET /api/users

# 3. Filter por tags
tags: http.status_code=200

# 4. Análisis de latencia
duration &gt; 100ms

# 5. Error traces
tags: error=true

# 6. Ver spans
Click en trace → expandir spans → ver duración, tags, logs</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_9_6_observabilidad_completa_stack_integrado">9.6. 9.6 Observabilidad Completa: Stack Integrado</h3>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Namespace para observabilidad
apiVersion: v1
kind: Namespace
metadata:
  name: observability
  labels:
    pod-security.kubernetes.io/enforce: baseline

---
# ServiceAccount para apps
apiVersion: v1
kind: ServiceAccount
metadata:
  name: app-observability
  namespace: observability

---
# Deployment con todas las características
apiVersion: apps/v1
kind: Deployment
metadata:
  name: observable-app
  namespace: observability
spec:
  replicas: 2
  selector:
    matchLabels:
      app: observable-app
  template:
    metadata:
      labels:
        app: observable-app
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: app-observability

      containers:
      - name: app
        image: observable-app:1.0
        imagePullPolicy: Always

        ports:
        - containerPort: 8080
          name: http
        - containerPort: 8081
          name: metrics

        env:
        # Prometheus metrics
        - name: METRICS_PORT
          value: "8081"

        # Jaeger tracing
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: "http://jaeger-collector.observability:4318"
        - name: OTEL_SERVICE_NAME
          value: "observable-app"
        - name: OTEL_TRACES_SAMPLER
          value: "parentbased_traceidratio"
        - name: OTEL_TRACES_SAMPLER_ARG
          value: "0.1"

        # Logging structured
        - name: LOG_LEVEL
          value: "INFO"
        - name: LOG_FORMAT
          value: "json"

        # Resource metadata
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: "service.namespace=observability,service.instance.id=$(POD_NAME)"
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace

        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi

        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10

        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5

        volumeMounts:
        - name: logs
          mountPath: /var/log

      volumes:
      - name: logs
        emptyDir: {}

---
# Service
apiVersion: v1
kind: Service
metadata:
  name: observable-app
  namespace: observability
  labels:
    app: observable-app
spec:
  type: ClusterIP
  selector:
    app: observable-app
  ports:
  - port: 8080
    targetPort: 8080
    name: http
  - port: 8081
    targetPort: 8081
    name: metrics

---
# ServiceMonitor para Prometheus
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: observable-app
  namespace: observability
spec:
  selector:
    matchLabels:
      app: observable-app
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics

---
# PrometheusRule para alertas
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: observable-app-alerts
  namespace: observability
spec:
  groups:
  - name: observable-app
    interval: 30s
    rules:
    - alert: AppHighLatency
      expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) &gt; 0.5
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "App latency is high"
        description: "p95 latency: {{ $value }}s"

    - alert: AppHighErrorRate
      expr: rate(http_requests_total{status=~"5.."}[5m]) &gt; 0.01
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "App error rate is high"
        description: "Error rate: {{ $value | humanizePercentage }}"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_9_7_best_practices">9.7. 9.7 Best Practices</h3>
<div class="paragraph">
<p><strong>1. Retention Policies</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">❌ Guardar todo indefinidamente (caro)
✅ Prometheus: 7-30 días de retención
✅ Elasticsearch: rotación por índices (1 día)
✅ Archiving a S3/GCS para análisis histórico</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Sampling</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">❌ Tracer el 100% de requests (sobrecarga)
✅ Sampling inteligente:
   - 100% para errores
   - 10% para requests normales
   - 1% para background tasks</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Labels Importantes</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ Pod name, namespace, cluster
✅ Service, environment, version
✅ Http status, error type
❌ Datos sensibles (passwords, tokens)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. Alertas Significativas</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">❌ Alerta por cada Pod caído
✅ Alerta por multiple Pod failures
✅ Alerta por error rate &gt; threshold</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>5. Dashboards</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ Una métrica por panel (no abarrotado)
✅ Usar color rojo para warnings
✅ Incluir contexto (avg, p95, max)</code></pre>
</div>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_9_8_resumen_del_módulo_9">9.8. 9.8 Resumen del Módulo 9</h3>
<div class="paragraph">
<p>En este módulo aprendiste:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Metrics Server</strong>: Recolección de métricas de CPU/memoria</p>
<div class="ulist">
<ul>
<li>
<p>Metrics Server architecture</p>
</li>
<li>
<p>Kubectl top pods/nodes</p>
</li>
<li>
<p>Custom metrics exporters</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Prometheus</strong>: Sistema de alerting basado en métricas</p>
<div class="ulist">
<ul>
<li>
<p>TSDB (Time Series Database)</p>
</li>
<li>
<p>PromQL queries</p>
</li>
<li>
<p>Alert rules</p>
</li>
<li>
<p>AlertManager routing</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Grafana</strong>: Visualización de datos</p>
<div class="ulist">
<ul>
<li>
<p>Dashboards personalizados</p>
</li>
<li>
<p>Datasources</p>
</li>
<li>
<p>Alertas en Grafana</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>ELK Stack</strong>: Agregación de logs</p>
<div class="ulist">
<ul>
<li>
<p>Elasticsearch (almacenamiento)</p>
</li>
<li>
<p>Kibana (búsqueda)</p>
</li>
<li>
<p>Fluentd (recolección)</p>
</li>
<li>
<p>KQL queries</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Jaeger</strong>: Distributed tracing</p>
<div class="ulist">
<ul>
<li>
<p>OpenTelemetry instrumentation</p>
</li>
<li>
<p>Análisis de latencia</p>
</li>
<li>
<p>Debugging de microservicios</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Observabilidad Completa</strong>: Integración de todos los pillares</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Con estos conocimientos, estás listo para aprender sobre <strong>GitOps y CI/CD</strong> en el Módulo 10.</p>
</div>
<hr>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_10_gitops_y_cicd">10. MÓDULO 10: GitOps y CI/CD</h2>
<div class="sectionbody">
<div class="paragraph">
<p><strong>GitOps</strong> es el conjunto de prácticas para gestionar infraestructura y aplicaciones usando Git como fuente única de verdad.</p>
</div>
<div class="paragraph">
<p><strong>Diferencia clave:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Imperativo (Tradicional)          Declarativo (GitOps)

kubectl apply ...                 git push
kubectl scale ...        VS       git merge
kubectl set image ...             (Reconciliación automática)
kubectl delete ...</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Flujo GitOps:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>┌─────────────┐
│  Git Repo   │
│ (Source of  │
│   Truth)    │
└─────────────┘
       ↑
       │ (Push o Pull)
       │
┌──────────────────────────────────┐
│ GitOps Operator (Flux/ArgoCD)   │
│ - Monitorea cambios en Git       │
│ - Aplica cambios automáticamente │
│ - Sincroniza estado real vs Git  │
└──────────────────────────────────┘
       ↓
┌─────────────────────┐
│ Kubernetes Cluster  │
│ (Estado deseado)    │
└─────────────────────┘</code></pre>
</div>
</div>
<hr>
<div class="sect2">
<h3 id="_10_1_conceptos_fundamentales">10.1. 10.1 Conceptos Fundamentales</h3>
<div class="sect3">
<h4 id="_10_1_1_git_como_fuente_de_verdad">10.1.1. 10.1.1 Git como Fuente de Verdad</h4>
<div class="paragraph">
<p>Todo debe estar en Git:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">❌ Manejar cluster manualmente
❌ kubectl apply sin guardar en Git
❌ Secrets hardcodeados en YAML

✅ Todo versionado en Git
✅ Auditoría completa de cambios
✅ Secrets encriptados (Sealed Secrets, SOPS)
✅ Rollback a cualquier commit</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_10_1_2_declarativo_vs_imperativo">10.1.2. 10.1.2 Declarativo vs Imperativo</h4>
<div class="paragraph">
<p><strong>Imperativo</strong> (orden qué hacer):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">kubectl set image deployment/app app=myapp:v2
kubectl scale deployment app --replicas=3</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Declarativo</strong> (describir estado deseado):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: app
        image: myapp:v2</code></pre>
</div>
</div>
<div class="paragraph">
<p>GitOps usa <strong>declarativo</strong> con repositorios Git.</p>
</div>
</div>
<div class="sect3">
<h4 id="_10_1_3_push_vs_pull">10.1.3. 10.1.3 Push vs Pull</h4>
<div class="paragraph">
<p><strong>Push Model (CI/CD tradicional):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Git Push → Jenkins → Build → Push to Registry → kubectl apply
(problema: si Jenkins falla, cluster desincronizado)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Pull Model (GitOps, recomendado):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Git Push → Operator en cluster (Flux/ArgoCD)
                ↓
           Monitorea cambios
                ↓
           kubectl apply automático
(ventaja: operador siempre sincroniza)</code></pre>
</div>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_10_2_flux_cd">10.2. 10.2 Flux CD</h3>
<div class="sect3">
<h4 id="_10_2_1_instalación_de_flux">10.2.1. 10.2.1 Instalación de Flux</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalar Flux CLI
curl -s https://fluxcd.io/install.sh | sudo bash

# Verificar instalación
flux --version

# Instalar Flux en cluster
flux bootstrap github \
  --owner=&lt;GITHUB_USER&gt; \
  --repo=&lt;REPO_NAME&gt; \
  --path=clusters/production \
  --personal \
  --private=false

# Flux crea:
# - Namespace flux-system
# - Controllers (source-controller, kustomize-controller, helm-controller)
# - Secret con credenciales Git

# Verificar
kubectl get pods -n flux-system</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_10_2_2_gitrepository_monitorear_cambios">10.2.2. 10.2.2 GitRepository (Monitorear cambios)</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># GitRepository: Monitorear repositorio Git
apiVersion: source.toolkit.fluxcd.io/v1
kind: GitRepository
metadata:
  name: app-repo
  namespace: flux-system
spec:
  interval: 30s  # Comprobar cambios cada 30s
  url: https://github.com/my-company/app-config
  ref:
    branch: main

  # Usar token para repos privados
  secretRef:
    name: github-credentials

  # Ignorar archivos
  ignore: |
    # Flux ignora estos archivos
    /.*
    /**/*.md
    **/charts/**

---
# Secret con credenciales (GitHub token)
apiVersion: v1
kind: Secret
metadata:
  name: github-credentials
  namespace: flux-system
stringData:
  username: git
  password: ghp_xxxxxxxxxxxxxxxx  # GitHub Personal Access Token</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_10_2_3_kustomization_aplicar_configuración">10.2.3. 10.2.3 Kustomization (Aplicar configuración)</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Kustomization: Aplicar configuración del Git repo
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: app-deployment
  namespace: flux-system
spec:
  interval: 10m

  # Repositorio fuente
  sourceRef:
    kind: GitRepository
    name: app-repo

  # Ruta dentro del repo
  path: ./deploy/production

  # Prioridad (si hay múltiples Kustomizations)
  prune: true
  wait: true

  # Validación
  validation: client

  # Salud
  healthChecks:
  - apiVersion: apps/v1
    kind: Deployment
    name: app
    namespace: production
  - apiVersion: v1
    kind: Service
    name: app
    namespace: production

  # Hacer antes de aplicar
  patchStrategicMergePatches:
  - target:
      kind: Deployment
      name: app
    patch: |
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: app
      spec:
        replicas: 3

---
# ConfigMap actualizado automáticamente
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production
data:
  config.yaml: |
    environment: production
    replicas: 3
    version: "1.0"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_10_2_4_helmrelease_gestionar_helm_charts">10.2.4. 10.2.4 HelmRelease (Gestionar Helm Charts)</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># HelmRelease: Instalar/actualizar Helm charts con Flux
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: postgres
  namespace: production
spec:
  interval: 5m

  # Fuente del chart
  chart:
    spec:
      chart: postgresql
      sourceRef:
        kind: HelmRepository
        name: bitnami
        namespace: flux-system
      version: "12.x"

  # Valores personalizados
  values:
    global:
      postgresql:
        auth:
          username: app_user
          password: secure_password
          database: app_db

    primary:
      persistence:
        enabled: true
        size: 10Gi
        storageClassName: fast-ssd

    metrics:
      enabled: true
      serviceMonitor:
        enabled: true

  # Estrategia de actualización
  upgrade:
    remediation:
      retries: 3

  # Salud
  healthChecks:
  - apiVersion: apps/v1
    kind: Deployment
    name: postgres
    namespace: production

---
# HelmRepository: Fuente de Helm charts
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: bitnami
  namespace: flux-system
spec:
  interval: 10m
  url: https://charts.bitnami.com/bitnami</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_10_2_5_automatización_de_actualizaciones">10.2.5. 10.2.5 Automatización de Actualizaciones</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># ImageRepository: Monitorear nuevas imágenes
apiVersion: image.toolkit.fluxcd.io/v1beta2
kind: ImageRepository
metadata:
  name: app-images
  namespace: flux-system
spec:
  image: myregistry/app
  interval: 5m

  # Credenciales (si es privado)
  secretRef:
    name: registry-credentials

---
# ImagePolicy: Seleccionar qué versión usar
apiVersion: image.toolkit.fluxcd.io/v1beta2
kind: ImagePolicy
metadata:
  name: app-latest
  namespace: flux-system
spec:
  imageRepositoryRef:
    name: app-images

  # Estrategia: semver, alphabetical, timestamp
  policy:
    semver:
      range: '1.x'  # v1.0, v1.1, v1.2, etc

---
# ImageUpdateAutomation: Actualizar Git cuando hay nueva imagen
apiVersion: image.toolkit.fluxcd.io/v1beta1
kind: ImageUpdateAutomation
metadata:
  name: app-update
  namespace: flux-system
spec:
  interval: 5m

  sourceRef:
    kind: GitRepository
    name: app-repo

  # Qué actualizar
  update:
    strategy: Setters
    path: ./deploy

  # Git commit
  git:
    commit:
      author:
        email: flux@company.com
        name: Flux Automation
      messageTemplate: |
        Automated image update

        {{range .Updated.Images -}}
        {{println .}}
        {{- end}}

---
# En deploy/app-deployment.yaml, marcar para auto-update:
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app
  namespace: production
spec:
  template:
    spec:
      containers:
      - name: app
        image: myregistry/app:v1.2.3  # {image-update}</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_10_2_6_notificaciones">10.2.6. 10.2.6 Notificaciones</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Alert: Monitorear cambios en repositorio
apiVersion: notification.toolkit.fluxcd.io/v1beta3
kind: Alert
metadata:
  name: repo-changes
  namespace: flux-system
spec:
  providerRef:
    name: slack
  eventSeverity: info
  eventSources:
  - kind: GitRepository
    name: '*'
  - kind: Kustomization
    name: '*'
  - kind: HelmRelease
    name: '*'
  suspend: false

---
# Provider: Destino de notificaciones
apiVersion: notification.toolkit.fluxcd.io/v1beta3
kind: Provider
metadata:
  name: slack
  namespace: flux-system
spec:
  type: slack
  address: https://hooks.slack.com/services/YOUR/WEBHOOK/URL

---
# Receptor: Webhook para alertas
apiVersion: notification.toolkit.fluxcd.io/v1beta3
kind: Receiver
metadata:
  name: github-webhooks
  namespace: flux-system
spec:
  type: github
  secretRef:
    name: webhook-token
  resources:
  - kind: GitRepository
    name: app-repo</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_10_3_argocd">10.3. 10.3 ArgoCD</h3>
<div class="sect3">
<h4 id="_10_3_1_instalación_de_argocd">10.3.1. 10.3.1 Instalación de ArgoCD</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear namespace
kubectl create namespace argocd

# Instalar ArgoCD
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# Verificar instalación
kubectl get pods -n argocd

# Port-forward para acceder UI
kubectl port-forward svc/argocd-server -n argocd 8080:443

# Obtener contraseña inicial
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d

# URL: https://localhost:8080
# User: admin
# Password: (del comando anterior)

# CLI
curl -sSL -o /usr/local/bin/argocd https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64
chmod +x /usr/local/bin/argocd

argocd login localhost:8080 --insecure</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_10_3_2_application_declarar_aplicación">10.3.2. 10.3.2 Application (Declarar aplicación)</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># ArgoCD Application
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: myapp
  namespace: argocd
spec:
  # Proyecto (namespace lógico)
  project: default

  # Fuente: donde está el código
  source:
    repoURL: https://github.com/my-company/app-config
    targetRevision: main
    path: deploy/production

    # Si usa Helm
    helm:
      releaseName: myapp
      values: |
        replicas: 3
        image:
          tag: v1.2.3

      # O usar file
      # valuesObject:
      #   replicas: 3

    # Si usa Kustomize
    # kustomize:
    #   commonLabels:
    #     version: v1
    #   replicas:
    #   - name: app
    #     count: 3

    # Si usa plugin
    # plugin:
    #   name: my-plugin
    #   env:
    #   - name: CONFIG
    #     value: /path/to/config

  # Destino: dónde deployar
  destination:
    server: https://kubernetes.default.svc  # Cluster actual
    namespace: production

  # Sincronización automática
  syncPolicy:
    automated:
      prune: true      # Eliminar recursos no en Git
      selfHeal: true   # Resincronizar si alguien cambia manualmente
      allowEmpty: false # No permitir borrar todos los recursos

    syncOptions:
    - CreateNamespace=true

    retry:
      limit: 5
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 3m

  # Health (obligatorio que estos Pods estén ready)
  ignoreDifferences:
  - group: apps
    kind: Deployment
    jsonPointers:
    - /spec/replicas

---
# Otro ejemplo: multi-fuente
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: complex-app
  namespace: argocd
spec:
  project: default

  # Múltiples fuentes
  sources:

  # Fuente 1: Base de datos (Helm)
  - repoURL: https://charts.bitnami.com/bitnami
    targetRevision: 12.x
    chart: postgresql
    helm:
      releaseName: postgres
      values: |
        primary:
          persistence:
            size: 20Gi

  # Fuente 2: Aplicación (Git)
  - repoURL: https://github.com/my-company/app
    targetRevision: main
    path: deploy

  destination:
    server: https://kubernetes.default.svc
    namespace: production

  syncPolicy:
    automated:
      prune: true
      selfHeal: true</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_10_3_3_sincronización">10.3.3. 10.3.3 Sincronización</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver aplicaciones
argocd app list
# NAME           CLUSTER                         STATUS      SYNC STATUS
# myapp          https://kubernetes.default.svc  Healthy     Synced

# Ver detalles
argocd app get myapp
# Name:               myapp
# Status:             Healthy
# Sync Status:        Synced
# Repo:               https://github.com/my-company/app
# Target Branch:      main
# Sync Policy:        Automated
# Last Sync:          2024-01-15 10:30:00

# Sincronizar manualmente
argocd app sync myapp

# Forzar resincronización
argocd app sync myapp --force

# Ver historial
argocd app history myapp
# VERSION   DEPLOYED AT             REVISION
# 0         2024-01-15 10:30:00     abc123
# 1         2024-01-16 14:20:00     def456

# Revertir a versión anterior
argocd app rollback myapp 0

# Actualizar valores
argocd app set myapp -p image.tag=v2.0.0</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_10_3_4_appproject_rbac">10.3.4. 10.3.4 AppProject (RBAC)</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># AppProject: Control de acceso
apiVersion: argoproj.io/v1alpha1
kind: AppProject
metadata:
  name: team-a
  namespace: argocd
spec:
  # Descripción
  description: Team A project

  # Fuentes permitidas
  sourceRepos:
  - 'https://github.com/team-a/*'
  - 'https://charts.bitnami.com/bitnami'

  # Destinos permitidos
  destinations:
  - namespace: 'team-a-*'
    server: 'https://kubernetes.default.svc'
  - namespace: 'shared'
    server: 'https://kubernetes.default.svc'

  # Roles RBAC
  roles:
  - name: developers
    description: Developers can deploy to staging
    policies:
    - p, proj:team-a:developers, applications, get, team-a/*, allow
    - p, proj:team-a:developers, applications, sync, team-a/*, allow

  - name: ops
    description: Ops can manage everything
    policies:
    - p, proj:team-a:ops, applications, *, team-a/*, allow
    - p, proj:team-a:ops, repositories, *, *, allow

---
# Asociar usuario a role
apiVersion: v1
kind: ConfigMap
metadata:
  name: argocd-rbac-cm
  namespace: argocd
data:
  policy.default: |
    g, admins, role:admin
    g, team-a-developers, proj:team-a:developers
    g, team-a-ops, proj:team-a:ops

  policy.csv: |
    # Roles (qué puede hacer)
    p, role:developer, applications, get, team-a/*, allow
    p, role:developer, applications, sync, team-a/*, allow

    p, role:ops, applications, *, *, allow
    p, role:ops, repositories, *, *, allow

    # User mappings (OIDC/LDAP)
    g, alice@company.com, role:developer
    g, bob@company.com, role:ops</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_10_3_5_notifications">10.3.5. 10.3.5 Notifications</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># ArgoCD Notification
apiVersion: v1
kind: ConfigMap
metadata:
  name: argocd-notifications-cm
  namespace: argocd
data:
  trigger.on-deployed: |
    - when: app.status.operationState.finishedAt != '' and app.status.operationState.phase in ['Succeeded']
      oncePer: app.status.operationState.finishedAt
      send: [app-deployed]

  trigger.on-health-degraded: |
    - when: app.status.health.status == 'Degraded'
      send: [app-health-degraded]

  template.app-deployed: |
    message: |
      {{if eq .app.status.operationState.phase "Succeeded"}}✅{{else}}❌{{end}}
      Application {{.app.metadata.name}} {{.app.status.operationState.phase}}
      {{if eq .app.status.sync.status "Synced"}}(Synced){{else}}(OutOfSync){{end}}
      {{- if .commitMessage}}

      {{.commitMessage}}{{end}}

  service.slack: |
    token: $slack-token

  service.email: |
    host: smtp.gmail.com
    port: 587
    from: argocd@company.com
    username: $email-username
    password: $email-password

---
# Subscription (Enviar notificaciones a Slack)
apiVersion: v1
kind: Secret
metadata:
  name: argocd-notifications-secret
  namespace: argocd
stringData:
  slack-token: xoxb-xxxxxxxxxxxxx

---
# Trigger para aplicación
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: myapp
  namespace: argocd
  annotations:
    notifications.argoproj.io/subscribe.on-deployed.slack: "#deployments"
    notifications.argoproj.io/subscribe.on-health-degraded.slack: "#alerts"
spec:
  # ... resto de config</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_10_4_cicd_pipelines">10.4. 10.4 CI/CD Pipelines</h3>
<div class="sect3">
<h4 id="_10_4_1_github_actions">10.4.1. 10.4.1 GitHub Actions</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># .github/workflows/build-and-deploy.yaml
name: Build and Deploy

on:
  push:
    branches:
      - main
    paths:
      - 'src/**'
      - 'Dockerfile'
      - '.github/workflows/build-and-deploy.yaml'

jobs:
  build:
    runs-on: ubuntu-latest

    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      with:
        fetch-depth: 0  # Para obtener historial de commits

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    - name: Login to Docker Hub
      uses: docker/login-action@v2
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}

    - name: Docker meta
      id: meta
      uses: docker/metadata-action@v4
      with:
        images: ${{ secrets.DOCKER_USERNAME }}/myapp
        tags: |
          type=ref,event=branch
          type=semver,pattern={{version}}
          type=sha,prefix=sha-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push Docker image
      uses: docker/build-push-action@v4
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=registry,ref=${{ secrets.DOCKER_USERNAME }}/myapp:buildcache
        cache-to: type=registry,ref=${{ secrets.DOCKER_USERNAME }}/myapp:buildcache,mode=max

  test:
    runs-on: ubuntu-latest
    needs: build

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Run tests
      run: |
        docker run --rm ${{ needs.build.outputs.image-tag }} pytest

    - name: Run security scan
      run: |
        docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
          aquasec/trivy image ${{ needs.build.outputs.image-tag }}

  deploy:
    runs-on: ubuntu-latest
    needs: [build, test]
    if: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'

    steps:
    - name: Checkout config repo
      uses: actions/checkout@v3
      with:
        repository: my-company/app-config
        token: ${{ secrets.CONFIG_REPO_TOKEN }}
        path: config

    - name: Update image tag in config
      working-directory: config
      run: |
        sed -i "s|image: .*|image: ${{ needs.build.outputs.image-tag }}|" deploy/production/deployment.yaml

    - name: Commit and push
      working-directory: config
      run: |
        git config user.email "ci@company.com"
        git config user.name "CI/CD Bot"
        git add deploy/production/deployment.yaml
        git commit -m "Update image: ${{ needs.build.outputs.image-tag }}"
        git push origin main

    - name: Verify deployment (opcional)
      run: |
        echo "GitOps tool (Flux/ArgoCD) detectará el cambio y desplegará"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_10_4_2_tekton_pipelines">10.4.2. 10.4.2 Tekton Pipelines</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Tekton: CI/CD nativo de Kubernetes
apiVersion: v1
kind: Namespace
metadata:
  name: tekton-pipelines

---
# Task: Clonar repositorio
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: git-clone
  namespace: tekton-pipelines
spec:
  params:
  - name: url
    description: Git repository URL
  - name: revision
    description: Git revision (branch, tag, commit)
    default: main

  results:
  - name: commit
    description: Commit SHA

  steps:
  - name: clone
    image: alpine/git:latest
    script: |
      #!/bin/sh
      git clone --depth 1 --branch $(params.revision) $(params.url) /workspace/repo
      cd /workspace/repo
      git rev-parse HEAD &gt; $(results.commit.path)

---
# Task: Build Docker image
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: build-image
  namespace: tekton-pipelines
spec:
  params:
  - name: image
    description: Image name
  - name: dockerfile
    default: Dockerfile

  steps:
  - name: build-and-push
    image: gcr.io/kaniko-project/executor:latest
    args:
    - --destination=$(params.image)
    - --dockerfile=/workspace/repo/$(params.dockerfile)
    - --context=/workspace/repo

---
# Task: Run tests
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: run-tests
  namespace: tekton-pipelines
spec:
  steps:
  - name: test
    image: python:3.11
    workingDir: /workspace/repo
    script: |
      #!/bin/bash
      pip install -r requirements.txt
      pytest tests/

---
# Pipeline: Orquestar tasks
apiVersion: tekton.dev/v1
kind: Pipeline
metadata:
  name: build-and-deploy
  namespace: tekton-pipelines
spec:
  params:
  - name: git-url
  - name: git-revision
  - name: image-name

  tasks:

  # Task 1: Clone
  - name: clone
    taskRef:
      name: git-clone
    params:
    - name: url
      value: $(params.git-url)
    - name: revision
      value: $(params.git-revision)

  # Task 2: Test (dependencia en clone)
  - name: test
    taskRef:
      name: run-tests
    runAfter:
    - clone

  # Task 3: Build (dependencia en test)
  - name: build
    taskRef:
      name: build-image
    runAfter:
    - test
    params:
    - name: image
      value: $(params.image-name)

---
# PipelineRun: Ejecutar pipeline
apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  name: build-app-run
  namespace: tekton-pipelines
spec:
  pipelineRef:
    name: build-and-deploy

  params:
  - name: git-url
    value: https://github.com/my-company/app
  - name: git-revision
    value: main
  - name: image-name
    value: myregistry/app:v1.2.3

  workspaces:
  - name: shared-workspace
    volumeClaimTemplate:
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: 1Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_10_4_3_webhook_para_cicd_automático">10.4.3. 10.4.3 Webhook para CI/CD automático</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># EventListener: Recibir webhooks de Git
apiVersion: triggers.tekton.dev/v1beta1
kind: EventListener
metadata:
  name: github-push
  namespace: tekton-pipelines
spec:
  serviceAccountName: tekton-trigger-sa

  triggers:
  - name: github-trigger
    interceptors:
    - ref:
        name: "github"
      params:
      - name: "secretRef"
        value:
          secretName: github-webhook-secret
          secretKey: token

    bindings:
    - ref: github-binding

    template:
      ref: pipeline-template

---
# TriggerBinding: Extraer datos del webhook
apiVersion: triggers.tekton.dev/v1beta1
kind: TriggerBinding
metadata:
  name: github-binding
  namespace: tekton-pipelines
spec:
  params:
  - name: git-url
    value: $(body.repository.clone_url)
  - name: git-revision
    value: $(body.ref)
  - name: pr-number
    value: $(body.number)

---
# TriggerTemplate: Crear PipelineRun
apiVersion: triggers.tekton.dev/v1beta1
kind: TriggerTemplate
metadata:
  name: pipeline-template
  namespace: tekton-pipelines
spec:
  params:
  - name: git-url
  - name: git-revision

  resourcetemplates:
  - apiVersion: tekton.dev/v1
    kind: PipelineRun
    metadata:
      generateName: build-app-
      namespace: tekton-pipelines
    spec:
      pipelineRef:
        name: build-and-deploy

      params:
      - name: git-url
        value: $(tt.params.git-url)
      - name: git-revision
        value: $(tt.params.git-revision)
      - name: image-name
        value: myregistry/app:latest

---
# Secret para webhook
apiVersion: v1
kind: Secret
metadata:
  name: github-webhook-secret
  namespace: tekton-pipelines
stringData:
  token: ghp_xxxxxxxxxxxxxxxx

---
# RBAC para Tekton triggers
apiVersion: v1
kind: ServiceAccount
metadata:
  name: tekton-trigger-sa
  namespace: tekton-pipelines

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: tekton-triggers-role
rules:
- apiGroups: ["tekton.dev"]
  resources: ["pipelineruns", "taskruns"]
  verbs: ["create", "get", "list"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: tekton-triggers-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: tekton-triggers-role
subjects:
- kind: ServiceAccount
  name: tekton-trigger-sa
  namespace: tekton-pipelines</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_10_5_versionado_y_releases">10.5. 10.5 Versionado y Releases</h3>
<div class="sect3">
<h4 id="_10_5_1_semantic_versioning">10.5.1. 10.5.1 Semantic Versioning</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>MAJOR.MINOR.PATCH
  ↓     ↓      ↓
  2.    1.     3

MAJOR: Breaking changes (1.0 → 2.0)
MINOR: New features, backwards compatible (2.0 → 2.1)
PATCH: Bug fixes (2.1 → 2.1.1)

Ejemplos:
1.0.0  → 1.0.1  (bug fix)
1.0.1  → 1.1.0  (new feature)
1.1.0  → 2.0.0  (breaking change)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_10_5_2_changelog_automático">10.5.2. 10.5.2 Changelog Automático</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Usar conventional commits
# Format: &lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;
#
# type: feat, fix, docs, style, refactor, test, chore
# scope: optional, e.g., "api", "web", "db"
# subject: brief description

# Ejemplos:
# feat(api): add user endpoint
# fix(web): resolve navbar styling issue
# docs(readme): update installation steps

# Tool: standard-version (genera changelog)
npm install -g standard-version

# Crear versión (actualiza package.json, CHANGELOG.md, git tag)
standard-version --release-as minor

# Ver cambios
git log --oneline | head -10

# Publicar
git push origin main
git push origin v1.1.0</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_10_5_3_github_releases">10.5.3. 10.5.3 GitHub Releases</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># .github/workflows/release.yaml
name: Release

on:
  push:
    tags:
      - 'v*'

jobs:
  release:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout
      uses: actions/checkout@v3
      with:
        fetch-depth: 0

    - name: Get changelog
      id: changelog
      run: |
        CHANGELOG=$(git log --pretty=format:"%h - %s" $(git describe --tags --abbrev=0 HEAD~1)..HEAD)
        echo "CHANGELOG=$CHANGELOG" &gt;&gt; $GITHUB_OUTPUT

    - name: Create Release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ github.ref }}
        release_name: Release ${{ github.ref }}
        body: ${{ steps.changelog.outputs.CHANGELOG }}
        draft: false
        prerelease: false

    - name: Build and push image
      run: |
        docker build -t myregistry/app:${{ github.ref }} .
        docker push myregistry/app:${{ github.ref }}

    - name: Update deployment config
      run: |
        # Actualizar imagen en config repo
        sed -i "s|image: .*|image: myregistry/app:${{ github.ref }}|" deploy/deployment.yaml
        git config user.email "ci@company.com"
        git config user.name "CI/CD Bot"
        git add deploy/deployment.yaml
        git commit -m "Update image for release: ${{ github.ref }}"
        git push https://github.com/my-company/app-config main</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_10_6_ejemplo_completo_gitops_workflow">10.6. 10.6 Ejemplo Completo: GitOps Workflow</h3>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Estructura Git repo:
# app-config/
# ├── clusters/
# │   ├── production/
# │   │   ├── kustomization.yaml
# │   │   └── apps/
# │   │       ├── app-deployment.yaml
# │   │       ├── app-service.yaml
# │   │       └── app-configmap.yaml
# │   └── staging/
# └── apps/
#     └── app/
#         ├── kustomization.yaml
#         └── base/
#             ├── deployment.yaml
#             ├── service.yaml
#             └── configmap.yaml

# 1. Namespace
apiVersion: v1
kind: Namespace
metadata:
  name: production

---
# 2. Aplicación (Flux)
apiVersion: source.toolkit.fluxcd.io/v1
kind: GitRepository
metadata:
  name: app-config
  namespace: flux-system
spec:
  interval: 30s
  url: https://github.com/my-company/app-config
  ref:
    branch: main

---
# 3. Sincronizar con Kustomization
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: app-production
  namespace: flux-system
spec:
  interval: 10m
  sourceRef:
    kind: GitRepository
    name: app-config
  path: ./clusters/production
  prune: true
  wait: true

---
# 4. Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: app
  template:
    metadata:
      labels:
        app: app
    spec:
      containers:
      - name: app
        image: myregistry/app:v1.2.3
        ports:
        - containerPort: 8080
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi

---
# 5. Service
apiVersion: v1
kind: Service
metadata:
  name: app
  namespace: production
spec:
  type: LoadBalancer
  selector:
    app: app
  ports:
  - port: 8080
    targetPort: 8080

---
# 6. ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production
data:
  app.yaml: |
    environment: production
    replicas: 3
    log_level: info

---
# Flujo:
# 1. Cambio en código → Push a main
# 2. GitHub Actions build imagen + tests
# 3. Imagen pushed a registry
# 4. Actions actualiza image tag en app-config repo
# 5. Flux detecta cambio en Git (cada 30s)
# 6. Flux aplica cambios automáticamente
# 7. ArgoCD sincroniza (si está configurado)
# 8. Cluster en estado deseado</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_10_7_best_practices">10.7. 10.7 Best Practices</h3>
<div class="paragraph">
<p><strong>1. Git como única fuente de verdad</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ Todo versionado en Git
✅ Commits atómicos con mensajes descriptivos
✅ PRs para cambios (no push directo a main)
❌ Cambios manuales con kubectl</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Separar CI y CD</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">CI Pipeline:
  - Clone repo
  - Build
  - Test
  - Scan (seguridad)
  - Push image

CD Pipeline (GitOps):
  - Flux/ArgoCD detecta Git change
  - Aplica cambios automáticamente</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Secrets management</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">❌ Secrets en repositorio
✅ Sealed Secrets / SOPS
✅ Vault para secrets
✅ CI secret management (GitHub Secrets, etc)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. Deployments sin downtime</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: Deployment
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    spec:
      terminationGracePeriodSeconds: 30</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>5. Health checks y rollback automático</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ Liveness probes
✅ Readiness probes
✅ Kustomization healthChecks
✅ ArgoCD auto-rollback si falla</code></pre>
</div>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_10_8_resumen_del_módulo_10">10.8. 10.8 Resumen del Módulo 10</h3>
<div class="paragraph">
<p>En este módulo aprendiste:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>GitOps Fundamentals</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Git como fuente única de verdad</p>
</li>
<li>
<p>Declarativo vs Imperativo</p>
</li>
<li>
<p>Push vs Pull model</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Flux CD</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>GitRepository para monitorear cambios</p>
</li>
<li>
<p>Kustomization para aplicar configuración</p>
</li>
<li>
<p>HelmRelease para gestionar Helm charts</p>
</li>
<li>
<p>Automatización de actualizaciones de imagen</p>
</li>
<li>
<p>Notificaciones (Slack, Email, etc)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>ArgoCD</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Instalación y configuración</p>
</li>
<li>
<p>Applications y sincronización</p>
</li>
<li>
<p>AppProject para RBAC</p>
</li>
<li>
<p>Health checks y rollback</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>CI/CD Pipelines</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>GitHub Actions (build, test, push, deploy)</p>
</li>
<li>
<p>Tekton Pipelines (CI/CD nativo de Kubernetes)</p>
</li>
<li>
<p>Webhooks para automatización</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Versionado y Releases</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Semantic Versioning</p>
</li>
<li>
<p>Conventional commits</p>
</li>
<li>
<p>Changelog automático</p>
</li>
<li>
<p>GitHub Releases</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>GitOps Workflow Completo</strong>: Integración end-to-end</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Con estos conocimientos, estás listo para aprender sobre <strong>Helm</strong> en el Módulo 11.</p>
</div>
<hr>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_11_helm_package_manager">11. MÓDULO 11: Helm Package Manager</h2>
<div class="sectionbody">
<div class="paragraph">
<p><strong>Helm</strong> es el package manager de Kubernetes. Como apt para Linux, npm para Node.js, pip para Python.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>┌─────────────────────────────────────────┐
│  Helm: Package Manager para Kubernetes  │
├─────────────────────────────────────────┤
│                                         │
│ Chart (package)  →  Release (instancia)│
│  nginx.tgz                 nginx-prod  │
│  postgres.tgz              postgres-dev│
│  prometheus.tgz            prom-1      │
│                                         │
│ Como: .deb → instalación en Linux      │
│       .rar → Release en github          │
└─────────────────────────────────────────┘</code></pre>
</div>
</div>
<hr>
<div class="sect2">
<h3 id="_11_1_helm_basics">11.1. 11.1 Helm Basics</h3>
<div class="sect3">
<h4 id="_11_1_1_instalación">11.1.1. 11.1.1 Instalación</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Descargar e instalar Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# Verificar instalación
helm version
# version.BuildInfo{Version:"v3.13.0", GitCommit:"..."}

# Completar shell
helm completion bash | sudo tee /etc/bash_completion.d/helm

# Agregar repositorios
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo add elastic https://helm.elastic.co

# Listar repos
helm repo list
# NAME                    URL
# bitnami                 https://charts.bitnami.com/bitnami
# prometheus-community    https://prometheus-community.github.io/helm-charts

# Actualizar catálogo
helm repo update

# Buscar charts
helm search repo nginx
helm search repo postgres
helm search repo --versions prometheus</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_11_1_2_chart_qué_es">11.1.2. 11.1.2 Chart: Qué es</h4>
<div class="paragraph">
<p>Un <strong>Chart</strong> es un paquete que contiene:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>my-app-chart/
├── Chart.yaml              (metadatos del chart)
├── values.yaml             (valores por defecto)
├── values-production.yaml  (valores override)
├── charts/                 (sub-charts dependientes)
├── templates/              (YAML templates)
│   ├── deployment.yaml
│   ├── service.yaml
│   ├── configmap.yaml
│   ├── NOTES.txt           (instrucciones post-install)
│   └── _helpers.tpl        (funciones reutilizables)
├── README.md
└── LICENSE</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_11_1_3_release_instalación_de_chart">11.1.3. 11.1.3 Release: Instalación de Chart</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalar chart (crear release)
helm install my-nginx bitnami/nginx

# Ver releases
helm list
# NAME      NAMESPACE   STATUS    APP VERSION
# my-nginx  default     deployed  1.25.0

# Ver detalles de release
helm get values my-nginx
helm get manifest my-nginx
helm get notes my-nginx

# Instalar con valores personalizados
helm install my-app bitnami/nginx \
  --set replicaCount=3 \
  --set image.tag=1.24.0 \
  --namespace production \
  --create-namespace

# Instalar desde archivo de valores
helm install my-app my-app-chart \
  -f values-production.yaml \
  -f values-secrets.yaml

# Dry-run (simular sin aplicar)
helm install my-app bitnami/nginx --dry-run --debug

# Ver qué se aplicaría
helm get manifest my-nginx</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_11_1_4_actualizar_y_rollback">11.1.4. 11.1.4 Actualizar y Rollback</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Upgrade: actualizar release
helm upgrade my-nginx bitnami/nginx --set replicaCount=5

# Upgrade + install (si no existe)
helm upgrade --install my-nginx bitnami/nginx --set replicaCount=3

# Ver historial
helm history my-nginx
# REVISION   UPDATED                     STATUS       CHART          DESCRIPTION
# 1          2024-01-15 10:30:00 +0000   superseded   nginx-15.1.1   Install complete
# 2          2024-01-16 14:20:00 +0000   deployed     nginx-15.2.0   Upgrade complete

# Rollback a revisión anterior
helm rollback my-nginx 1

# Rollback a revisión anterior (penúltima)
helm rollback my-nginx

# Desinstalar release
helm uninstall my-nginx
# release "my-nginx" uninstalled

# Desinstalar pero mantener ConfigMaps (para datos)
helm uninstall my-app --keep-history</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_11_2_estructura_de_chart">11.2. 11.2 Estructura de Chart</h3>
<div class="sect3">
<h4 id="_11_2_1_chart_yaml">11.2.1. 11.2.1 Chart.yaml</h4>
<div class="paragraph">
<p>Metadatos del chart:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: v2
name: myapp
description: A Helm chart for deploying MyApp on Kubernetes
type: application

# Versión del chart (puede cambiar sin afectar app)
version: 1.2.3

# Versión de la aplicación
appVersion: "2.0.1"

# Información del mantenedor
maintainers:
- name: John Doe
  email: john@company.com
  url: https://github.com/johndoe

# Dependencias (otros charts)
dependencies:
- name: postgresql
  version: 12.x
  repository: "https://charts.bitnami.com/bitnami"
  condition: postgresql.enabled
  alias: postgres  # Nombre alternativo
- name: redis
  version: 17.x
  repository: "https://charts.bitnami.com/bitnami"

# Home page
home: https://github.com/my-company/myapp

# Repositorio del código
sources:
- https://github.com/my-company/myapp

# Palabras clave
keywords:
- app
- kubernetes
- helm

# Licencia
license: Apache-2.0

# Icono
icon: https://raw.githubusercontent.com/my-company/myapp/main/logo.png</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_11_2_2_values_yaml">11.2.2. 11.2.2 values.yaml</h4>
<div class="paragraph">
<p>Valores por defecto:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Global values (accesibles a todos los templates)
global:
  environment: production
  domain: example.com

# Aplicación
replicaCount: 3

image:
  repository: myregistry/myapp
  tag: "1.0.0"
  pullPolicy: IfNotPresent

# Imagen para init containers
initImage:
  repository: busybox
  tag: "1.35"

# Pull secrets para imágenes privadas
imagePullSecrets: []
# - name: myregistrykey

# Service Account
serviceAccount:
  create: true
  annotations: {}
  name: ""

# Pod annotations
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "8080"
  prometheus.io/path: "/metrics"

# Pod security context
podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000

# Container security context
securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
    - ALL
  readOnlyRootFilesystem: true
  runAsNonRoot: true

# Service
service:
  type: ClusterIP
  port: 8080
  targetPort: 8080
  annotations: {}

# Ingress
ingress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  hosts:
  - host: app.example.com
    paths:
    - path: /
      pathType: Prefix
  tls:
  - secretName: app-tls
    hosts:
    - app.example.com

# Resources
resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 100m
    memory: 128Mi

# Autoscaling
autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

# Node selector (afinidad)
nodeSelector: {}
  # kubernetes.io/os: linux

# Tolerations
tolerations: []

# Affinity
affinity: {}
  # nodeAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:

# Health checks
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 10

readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 5

# Environment variables
env:
- name: ENV
  value: "production"
- name: LOG_LEVEL
  value: "info"

# ConfigMap data
configMap:
  enabled: true
  data:
    app.yaml: |
      environment: production
      debug: false

# Secrets
secrets:
  enabled: true
  # En producción, usar Sealed Secrets o SOPS
  database:
    username: app_user
    password: "change-me"

# Persistence
persistence:
  enabled: true
  storageClassName: "standard"
  accessMode: ReadWriteOnce
  size: 10Gi
  # mountPath: /data

# Database subchart
postgresql:
  enabled: true
  auth:
    username: app_user
    password: "secure-password"
    database: app_db

# Redis subchart
redis:
  enabled: false
  replica:
    replicaCount: 2</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_11_2_3_templates">11.2.3. 11.2.3 templates/</h4>
<div class="paragraph">
<p>Plantillas de Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "myapp.fullname" . }}
  labels:
    {{- include "myapp.labels" . | nindent 4 }}
  annotations:
    {{- toYaml .Values.deployment.annotations | nindent 4 }}
spec:
  {{- if not .Values.autoscaling.enabled }}
  replicas: {{ .Values.replicaCount }}
  {{- end }}
  selector:
    matchLabels:
      {{- include "myapp.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      {{- with .Values.podAnnotations }}
      annotations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      labels:
        {{- include "myapp.selectorLabels" . | nindent 8 }}
    spec:
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      serviceAccountName: {{ include "myapp.serviceAccountName" . }}
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      containers:
      - name: {{ .Chart.Name }}
        securityContext:
          {{- toYaml .Values.securityContext | nindent 12 }}
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        ports:
        - name: http
          containerPort: {{ .Values.service.targetPort }}
          protocol: TCP
        livenessProbe:
          {{- toYaml .Values.livenessProbe | nindent 12 }}
        readinessProbe:
          {{- toYaml .Values.readinessProbe | nindent 12 }}
        resources:
          {{- toYaml .Values.resources | nindent 12 }}
        env:
        {{- toYaml .Values.env | nindent 12 }}
        {{- if .Values.configMap.enabled }}
        volumeMounts:
        - name: config
          mountPath: /etc/config
          readOnly: true
        {{- end }}
        {{- if .Values.persistence.enabled }}
        - name: data
          mountPath: {{ .Values.persistence.mountPath | default "/data" }}
        {{- end }}
      {{- if .Values.configMap.enabled }}
      volumes:
      - name: config
        configMap:
          name: {{ include "myapp.fullname" . }}-config
      {{- end }}
      {{- if .Values.persistence.enabled }}
      - name: data
        persistentVolumeClaim:
          claimName: {{ include "myapp.fullname" . }}-pvc
      {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}

---
# templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: {{ include "myapp.fullname" . }}
  labels:
    {{- include "myapp.labels" . | nindent 4 }}
  {{- with .Values.service.annotations }}
  annotations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
spec:
  type: {{ .Values.service.type }}
  ports:
  - port: {{ .Values.service.port }}
    targetPort: http
    protocol: TCP
    name: http
  selector:
    {{- include "myapp.selectorLabels" . | nindent 4 }}

---
# templates/configmap.yaml
{{- if .Values.configMap.enabled }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "myapp.fullname" . }}-config
  labels:
    {{- include "myapp.labels" . | nindent 4 }}
data:
  {{- range $key, $value := .Values.configMap.data }}
  {{ $key }}: |
    {{ $value | nindent 4 }}
  {{- end }}
{{- end }}

---
# templates/_helpers.tpl (funciones reutilizables)
{{/*
Expand the name of the chart.
*/}}
{{- define "myapp.name" -}}
{{- default .Chart.Name .Values.nameOverride | trunc 63 | trimSuffix "-" }}
{{- end }}

{{/*
Create a default fully qualified app name.
*/}}
{{- define "myapp.fullname" -}}
{{- if .Values.fullnameOverride }}
{{- .Values.fullnameOverride | trunc 63 | trimSuffix "-" }}
{{- else }}
{{- $name := default .Chart.Name .Values.nameOverride }}
{{- if contains $name .Release.Name }}
{{- .Release.Name | trunc 63 | trimSuffix "-" }}
{{- else }}
{{- printf "%s-%s" .Release.Name $name | trunc 63 | trimSuffix "-" }}
{{- end }}
{{- end }}
{{- end }}

{{/*
Create chart name and version as used by the chart label.
*/}}
{{- define "myapp.chart" -}}
{{- printf "%s-%s" .Chart.Name .Chart.Version | replace "+" "_" | trunc 63 | trimSuffix "-" }}
{{- end }}

{{/*
Common labels
*/}}
{{- define "myapp.labels" -}}
helm.sh/chart: {{ include "myapp.chart" . }}
{{ include "myapp.selectorLabels" . }}
{{- if .Chart.AppVersion }}
app.kubernetes.io/version: {{ .Chart.AppVersion | quote }}
{{- end }}
app.kubernetes.io/managed-by: {{ .Release.Service }}
{{- end }}

{{/*
Selector labels
*/}}
{{- define "myapp.selectorLabels" -}}
app.kubernetes.io/name: {{ include "myapp.name" . }}
app.kubernetes.io/instance: {{ .Release.Name }}
{{- end }}

{{/*
Create the name of the service account to use
*/}}
{{- define "myapp.serviceAccountName" -}}
{{- if .Values.serviceAccount.create }}
{{- default (include "myapp.fullname" .) .Values.serviceAccount.name }}
{{- else }}
{{- default "default" .Values.serviceAccount.name }}
{{- end }}
{{- end }}</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_11_3_templating_con_helm">11.3. 11.3 Templating con Helm</h3>
<div class="sect3">
<h4 id="_11_3_1_funciones_básicas">11.3.1. 11.3.1 Funciones Básicas</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Variables y funciones básicas

# 1. Variables
{{ .Chart.Name }}           # Nombre del chart
{{ .Chart.Version }}        # Versión del chart
{{ .Chart.AppVersion }}     # Versión de la app
{{ .Release.Name }}         # Nombre del release
{{ .Release.Namespace }}    # Namespace
{{ .Values.replicaCount }}  # Valor de values.yaml

# 2. Default value (si no existe)
{{ .Values.replicaCount | default 3 }}

# 3. Condiciones
{{ if .Values.ingress.enabled }}
  # Crear Ingress
{{ else }}
  # No crear Ingress
{{ end }}

# 4. Con negación
{{ if not .Values.postgresql.enabled }}
  # PostgreSQL deshabilitado
{{ end }}

# 5. Loops
{{ range .Values.replicas }}
  - {{ . }}
{{ end }}

# 6. Dictionary (objeto)
{{ range $key, $value := .Values.env }}
- name: {{ $key }}
  value: {{ $value | quote }}
{{ end }}

# 7. Transformación de tipos
{{ .Values.image.tag | quote }}           # Entre comillas
{{ .Values.port | int }}                  # Convertir a entero
{{ .Values.replicaCount | default 3 }}    # Valor por defecto
{{ .Values.name | upper }}                # Mayúsculas
{{ .Values.name | lower }}                # Minúsculas
{{ .Values.email | contains "@" }}        # Contiene

# 8. Pipeline (encadenamiento)
{{ .Values.name | upper | quote }}        # NOMBRE entre comillas

# 9. Indentación
{{ .Values.config | toYaml | nindent 4 }} # Indentar YAML
{{ .Values.labels | toJson }}              # Convertir a JSON

# 10. Include (reutilizar template)
{{ include "myapp.labels" . }}</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_11_3_2_condicionales_avanzados">11.3.2. 11.3.2 Condicionales Avanzados</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># templates/deployment.yaml - Sección condicional compleja

spec:
  {{- if not .Values.autoscaling.enabled }}
  # Si autoscaling está deshabilitado, fijar replicas
  replicas: {{ .Values.replicaCount }}
  {{- end }}

  {{- if .Values.persistence.enabled }}
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: {{ .Values.persistence.storageClassName }}
      resources:
        requests:
          storage: {{ .Values.persistence.size }}
  {{- end }}

  {{- with .Values.securityContext }}
  securityContext:
    {{- toYaml . | nindent 4 }}
  {{- end }}

  {{- if eq .Values.environment "production" }}
  # Solo en producción
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - myapp
        topologyKey: kubernetes.io/hostname
  {{- else if eq .Values.environment "staging" }}
  # En staging
  affinity:
    podAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
  {{- end }}</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_11_3_3_bucles">11.3.3. 11.3.3 Bucles</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># templates/deployment.yaml - Loops

containers:
- name: app
  env:
  # Loop sobre variables
  {{- range $key, $value := .Values.env }}
  - name: {{ $key | upper }}
    value: {{ $value | quote }}
  {{- end }}

  volumeMounts:
  # Loop sobre montajes
  {{- range .Values.volumeMounts }}
  - name: {{ .name }}
    mountPath: {{ .mountPath }}
    readOnly: {{ .readOnly | default false }}
  {{- end }}

volumes:
# Loop sobre volúmenes
{{- range .Values.volumes }}
- name: {{ .name }}
  {{- if .configMap }}
  configMap:
    name: {{ .configMap }}
  {{- end }}
  {{- if .secret }}
  secret:
    secretName: {{ .secret }}
  {{- end }}
{{- end }}

# Counter loop
{{- range $i, $e := until (int .Values.replicaCount) }}
- name: instance-{{ $i }}
  value: "{{ add $i 1 }}"
{{- end }}

# Condicional en loop
{{- range .Values.mounts }}
{{- if .enabled }}
- name: {{ .name }}
  mountPath: {{ .path }}
{{- end }}
{{- end }}</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_11_4_crear_chart_personalizado">11.4. 11.4 Crear Chart Personalizado</h3>
<div class="sect3">
<h4 id="_11_4_1_crear_chart">11.4.1. 11.4.1 Crear Chart</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear estructura base
helm create myapp

# Esto genera:
myapp/
├── Chart.yaml
├── values.yaml
├── charts/
├── templates/
│   ├── deployment.yaml
│   ├── service.yaml
│   ├── ingress.yaml
│   ├── hpa.yaml
│   ├── pdb.yaml
│   ├── serviceaccount.yaml
│   ├── configmap.yaml
│   ├── secret.yaml
│   ├── NOTES.txt
│   ├── _helpers.tpl
│   └── tests/
└── .helmignore

# Editar Chart.yaml
vi myapp/Chart.yaml

# Editar values.yaml
vi myapp/values.yaml

# Crear templates personalizados
vi myapp/templates/custom-resource.yaml

# Linting (validar sintaxis)
helm lint myapp

# Dry-run para verificar rendering
helm template myapp ./myapp

# Con valores custom
helm template myapp ./myapp -f values-production.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_11_4_2_dependencias">11.4.2. 11.4.2 Dependencias</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Chart.yaml con dependencias
cat &gt; myapp/Chart.yaml &lt;&lt; EOF
apiVersion: v2
name: myapp
version: 1.0.0
appVersion: "1.0"
dependencies:
- name: postgresql
  version: "12.x"
  repository: "https://charts.bitnami.com/bitnami"
  condition: postgresql.enabled
- name: redis
  version: "17.x"
  repository: "https://charts.bitnami.com/bitnami"
  condition: redis.enabled
EOF

# Descargar dependencias
helm dependency update myapp

# Esto descarga charts en myapp/charts/

# Ver dependencias
helm dependency list myapp

# Valores para dependencias en values.yaml
postgresql:
  enabled: true
  auth:
    username: app
    password: mypassword
    database: myapp

redis:
  enabled: false</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_11_4_3_testing_de_charts">11.4.3. 11.4.3 Testing de Charts</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "{{ include "myapp.fullname" . }}-test-connection"
  labels:
    {{- include "myapp.labels" . | nindent 4 }}
  annotations:
    "helm.sh/hook": test
spec:
  containers:
  - name: wget
    image: busybox
    command: ['wget']
    args: ['{{ include "myapp.fullname" . }}:{{ .Values.service.port }}']
  restartPolicy: Never

---
# templates/tests/test-health.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "{{ include "myapp.fullname" . }}-test-health"
  labels:
    {{- include "myapp.labels" . | nindent 4 }}
  annotations:
    "helm.sh/hook": test
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
spec:
  containers:
  - name: test
    image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
    command:
    - /app/health-check.sh
  restartPolicy: Never</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ejecutar tests
helm test myapp

# Ver resultados
kubectl get pods | grep test

# Ver logs del test
kubectl logs -l app=myapp-test</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_11_4_4_hooks_pre_install_post_install_etc">11.4.4. 11.4.4 Hooks (Pre-install, Post-install, etc.)</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># templates/pre-install-hook.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: "{{ .Release.Name }}-pre-install-job"
  labels:
    {{- include "myapp.labels" . | nindent 4 }}
  annotations:
    "helm.sh/hook": pre-install
    "helm.sh/hook-weight": "-5"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  template:
    spec:
      serviceAccountName: {{ include "myapp.serviceAccountName" . }}
      containers:
      - name: setup
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        command:
        - /app/setup-database.sh
      restartPolicy: Never

---
# templates/post-install-hook.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: "{{ .Release.Name }}-post-install-job"
  annotations:
    "helm.sh/hook": post-install
    "helm.sh/hook-weight": "0"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  template:
    spec:
      containers:
      - name: verify
        image: busybox
        command:
        - /bin/sh
        - -c
        - echo "Installation completed successfully"
      restartPolicy: Never

---
# templates/pre-upgrade-hook.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: "{{ .Release.Name }}-pre-upgrade-job"
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  template:
    spec:
      containers:
      - name: backup
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        command:
        - /app/backup-database.sh
      restartPolicy: Never</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p>Tipos de hooks:
- <code>pre-install</code>: Antes de instalar
- <code>post-install</code>: Después de instalar
- <code>pre-upgrade</code>: Antes de actualizar
- <code>post-upgrade</code>: Después de actualizar
- <code>pre-delete</code>: Antes de desinstalar
- <code>post-delete</code>: Después de desinstalar
- <code>pre-rollback</code>: Antes de hacer rollback
- <code>post-rollback</code>: Después de hacer rollback
- <code>test</code>: Pruebas</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_11_5_gestión_de_releases">11.5. 11.5 Gestión de Releases</h3>
<div class="sect3">
<h4 id="_11_5_1_instalación_avanzada">11.5.1. 11.5.1 Instalación Avanzada</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalar con valores múltiples
helm install myapp ./myapp-chart \
  -f values.yaml \
  -f values-production.yaml \
  --set replicaCount=5 \
  --set image.tag=v2.0.0 \
  --set postgresql.enabled=true \
  --namespace production \
  --create-namespace

# Instalar con archivo de valores JSON
helm install myapp ./myapp-chart \
  --values values.json

# Instalar con valores literales (strings)
helm install myapp ./myapp-chart \
  --set-string image.tag=v1.2.3 \
  --set-string env.DATABASE_URL="postgresql://..."

# Validar chart antes de instalar
helm lint myapp-chart
helm template myapp myapp-chart --debug

# Instalar con espera a que esté listo
helm install myapp myapp-chart \
  --wait \
  --timeout 5m \
  --atomic  # Rollback si falla</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_11_5_2_upgrades">11.5.2. 11.5.2 Upgrades</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Upgrade simple
helm upgrade myapp ./myapp-chart

# Upgrade con valores nuevos
helm upgrade myapp ./myapp-chart \
  --set replicaCount=10 \
  --set image.tag=v2.0.0

# Upgrade con merge de valores anteriores
helm upgrade myapp ./myapp-chart \
  --reuse-values \
  --set replicaCount=5

# Upgrade + install (si no existe)
helm upgrade --install myapp ./myapp-chart

# Upgrade con estrategia
helm upgrade myapp ./myapp-chart \
  --set strategy.type=RollingUpdate \
  --set strategy.rollingUpdate.maxSurge=1 \
  --set strategy.rollingUpdate.maxUnavailable=0

# Upgrade atomático (rollback si falla)
helm upgrade myapp ./myapp-chart --atomic --timeout 5m

# Upgrade con fuerza
helm upgrade myapp ./myapp-chart --force

# Ver cambios antes de aplicar
helm diff upgrade myapp ./myapp-chart</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_11_5_3_rollback">11.5.3. 11.5.3 Rollback</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver historial de upgrades
helm history myapp
# REVISION   UPDATED                     STATUS       CHART           DESCRIPTION
# 1          Mon Jan 15 10:30:00 2024    superseded   myapp-1.0.0     Install complete
# 2          Tue Jan 16 14:20:00 2024    superseded   myapp-1.1.0     Upgrade complete
# 3          Wed Jan 17 09:15:00 2024    deployed     myapp-1.2.0     Upgrade complete

# Rollback a revisión anterior
helm rollback myapp 2

# Rollback a penúltima revisión
helm rollback myapp

# Rollback y crear nueva revisión
helm rollback myapp 2 --cleanup-on-fail

# Ver status después de rollback
helm status myapp</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_11_5_4_valores_override">11.5.4. 11.5.4 Valores Override</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Precedencia (de menor a mayor)
# 1. Default en values.yaml
# 2. -f values-custom.yaml (archivo de valores)
# 3. --set key=value (línea de comandos)
# 4. --set-string key="value" (string literal)

# Archivo de valores
cat &gt; values-prod.yaml &lt;&lt; EOF
replicaCount: 5
image:
  tag: v2.0.0
postgresql:
  enabled: true
  auth:
    password: prod-password
EOF

# Instalar con múltiples override
helm install myapp ./myapp-chart \
  -f values-prod.yaml \
  --set nodeSelector."disktype"="ssd" \
  --set persistence.size=50Gi \
  --set-json resources='{"limits":{"cpu":"1","memory":"1Gi"}}'

# Ver valores finales
helm get values myapp

# Ver valores con defaults
helm get values myapp --all</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_11_6_repositorios_helm">11.6. 11.6 Repositorios Helm</h3>
<div class="sect3">
<h4 id="_11_6_1_crear_y_publicar_chart">11.6.1. 11.6.1 Crear y Publicar Chart</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Packagizar chart
helm package myapp-chart

# Esto genera: myapp-chart-1.2.3.tgz

# Crear índice de repositorio
helm repo index . --url https://charts.my-company.com

# Esto genera: index.yaml con hash y URL de charts

# Subir a servidor (S3, GitHub Pages, etc)
aws s3 cp myapp-chart-1.2.3.tgz s3://my-helm-charts/
aws s3 cp index.yaml s3://my-helm-charts/

# O con GitHub Pages
git add myapp-chart-1.2.3.tgz index.yaml
git commit -m "Release myapp chart v1.2.3"
git push origin main

# Agregar repo personalizad
helm repo add myrepo https://s3.amazonaws.com/my-helm-charts
helm repo add myrepo https://raw.githubusercontent.com/my-company/helm-charts/main

# Actualizar repo
helm repo update myrepo

# Usar chart del repo
helm install myapp myrepo/myapp-chart

# Ver disponibles
helm search repo myrepo</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_11_6_2_repositorio_privado">11.6.2. 11.6.2 Repositorio Privado</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Crear secret para repo privado
kubectl create secret docker-registry my-repo-secret \
  --docker-username=user \
  --docker-password=pass \
  --docker-server=private-repo.company.com

# Usar en Helm (con pull secret en imagePullSecrets)
helm install myapp myrepo/myapp \
  --set imagePullSecrets[0].name=my-repo-secret

# O con credenciales en Helm
helm repo add myrepo https://user:pass@private-repo.company.com/helm
helm repo update myrepo
helm search repo myrepo</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_11_7_ejemplo_completo_wordpress_con_helm">11.7. 11.7 Ejemplo Completo: WordPress con Helm</h3>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># values-wordpress.yaml
replicaCount: 2

image:
  repository: wordpress
  tag: "6.0"
  pullPolicy: IfNotPresent

service:
  type: LoadBalancer
  port: 80

ingress:
  enabled: true
  className: nginx
  hosts:
  - host: wordpress.example.com
    paths:
    - path: /
      pathType: Prefix
  tls:
  - secretName: wordpress-tls
    hosts:
    - wordpress.example.com

persistence:
  enabled: true
  size: 20Gi
  storageClassName: fast-ssd

resources:
  requests:
    cpu: 250m
    memory: 256Mi
  limits:
    cpu: 500m
    memory: 512Mi

# MySQL con Bitnami chart
mysql:
  enabled: true
  auth:
    rootPassword: root-password
    database: wordpress
    username: wordpress
    password: wp-password
  primary:
    persistence:
      size: 20Gi

# Variables de WordPress
env:
- name: WORDPRESS_DB_HOST
  value: "myapp-mysql:3306"
- name: WORDPRESS_DB_USER
  valueFrom:
    secretKeyRef:
      name: mysql-credentials
      key: username
- name: WORDPRESS_DB_PASSWORD
  valueFrom:
    secretKeyRef:
      name: mysql-credentials
      key: password
- name: WORDPRESS_DB_NAME
  value: wordpress

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 5
  targetCPUUtilizationPercentage: 70</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Instalar
helm install wordpress ./wordpress-chart \
  -f values-wordpress.yaml \
  --namespace wordpress \
  --create-namespace

# Verificar instalación
helm list -n wordpress
kubectl get pods -n wordpress
kubectl get svc -n wordpress

# Ver notas
helm get notes wordpress -n wordpress

# Upgradee a nueva versión
helm upgrade wordpress ./wordpress-chart \
  --set image.tag=6.1 \
  -n wordpress

# Rollback si hay problemas
helm rollback wordpress -n wordpress</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_11_8_best_practices">11.8. 11.8 Best Practices</h3>
<div class="paragraph">
<p><strong>1. Versionado</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ Usar semantic versioning
✅ Documentar cambios en CHANGELOG
❌ Reutilizar versiones</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Templates</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ Usar helpers (_helpers.tpl)
✅ Documentar valores complejos
✅ Validar con helm lint
❌ Hardcodear valores</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Valores</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ Valores por defecto sensatos
✅ Valores override en archivos
✅ Secrets separados
❌ Secrets en values.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. Testing</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ Usar helm test
✅ Pre-install/post-install hooks
✅ Dry-run antes de aplicar
❌ Aplicar sin validar</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>5. Documentación</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ README.md con ejemplos
✅ NOTES.txt con instrucciones
✅ Comentarios en templates
❌ Charts sin documentación</code></pre>
</div>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_11_9_resumen_del_módulo_11">11.9. 11.9 Resumen del Módulo 11</h3>
<div class="paragraph">
<p>En este módulo aprendiste:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Helm Basics</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Instalación y repositorios</p>
</li>
<li>
<p>Charts y releases</p>
</li>
<li>
<p>Upgrade, rollback, uninstall</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Estructura de Chart</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Chart.yaml (metadatos)</p>
</li>
<li>
<p>values.yaml (valores por defecto)</p>
</li>
<li>
<p>templates/ (YAML templates)</p>
</li>
<li>
<p>Subcharts y dependencias</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Templating</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Variables, funciones, condicionales</p>
</li>
<li>
<p>Bucles y pipeline</p>
</li>
<li>
<p>Indentación y transformación</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Crear Charts</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>helm create</p>
</li>
<li>
<p>Validación con helm lint</p>
</li>
<li>
<p>Testing de charts</p>
</li>
<li>
<p>Hooks (pre-install, post-install, etc.)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Gestión de Releases</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Instalación avanzada</p>
</li>
<li>
<p>Upgrades con estrategias</p>
</li>
<li>
<p>Rollbacks</p>
</li>
<li>
<p>Override de valores</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Repositorios</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Crear y publicar charts</p>
</li>
<li>
<p>Repositorios privados</p>
</li>
<li>
<p>Búsqueda y actualización</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Ejemplo Práctico</strong>: WordPress con MySQL</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Con estos conocimientos, estás listo para aprender sobre <strong>Service Mesh</strong> en el Módulo 12.</p>
</div>
<hr>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_12_service_mesh_con_istio">12. MÓDULO 12: Service Mesh con Istio</h2>
<div class="sectionbody">
<div class="paragraph">
<p><strong>Service Mesh</strong> es una capa de infraestructura dedicada a gestionar la comunicación entre servicios (service-to-service communication) en aplicaciones distribuidas.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>ANTES (sin Service Mesh):
┌─────────┐         ┌─────────┐
│ Service │────────▶│ Service │
│    A    │         │    B    │
└─────────┘         └─────────┘
(Lógica: reintentos, timeouts, circuit breaker, tracing, etc.)

DESPUÉS (con Service Mesh):
┌─────────┐ ┌─────────┐ ┌─────────┐
│ Service │─│ Envoy   │─│ Service │
│    A    │ │ Sidecar │ │    B    │
└─────────┘ └─────────┘ └─────────┘
             ↓ (Infraestructura maneja: reintentos, timeouts,
               circuit breaker, tracing, encryption, etc.)</code></pre>
</div>
</div>
<hr>
<div class="sect2">
<h3 id="_12_1_conceptos_de_service_mesh">12.1. 12.1 Conceptos de Service Mesh</h3>
<div class="sect3">
<h4 id="_12_1_1_qué_es_un_service_mesh">12.1.1. 12.1.1 ¿Qué es un Service Mesh?</h4>
<div class="paragraph">
<p>Un <strong>Service Mesh</strong> es una capa de infraestructura que maneja la comunicación entre servicios:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sin Service Mesh</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Con Service Mesh</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lógica en cada microservicio</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lógica centralizada en malla</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Código repetido en N servicios</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Una sola configuración</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Difícil de actualizar</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Fácil de evolucionar</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Difícil de observar</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Observabilidad completa</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Problema que resuelve:</strong>
- <strong>Reintentos</strong>: ¿Si falla, cuántas veces reintentar?
- <strong>Timeouts</strong>: ¿Cuánto esperar antes de fallar?
- <strong>Circuit Breaker</strong>: ¿Cómo evitar cascadas de fallos?
- <strong>Load Balancing</strong>: ¿Cómo distribuir tráfico?
- <strong>Encryption</strong>: ¿Cómo cifrar comunicación?
- <strong>Rate Limiting</strong>: ¿Cómo controlar tráfico?
- <strong>Tracing</strong>: ¿Cómo debuggear peticiones?</p>
</div>
</div>
<div class="sect3">
<h4 id="_12_1_2_sidecar_proxies">12.1.2. 12.1.2 Sidecar Proxies</h4>
<div class="paragraph">
<p>Cada pod obtiene un proxy adicional (sidecar):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">Pod:
┌─────────────────────────┐
│ Container: myapp:8080   │
├─────────────────────────┤
│ Container: envoy-proxy  │
│ (intercepta tráfico)    │
└─────────────────────────┘
     ↓ (intercepta)
Todas las peticiones HTTP/TCP
pasan por Envoy</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver sidecars inyectados
kubectl describe pod myapp-pod-xyz
kubectl get pods -o jsonpath='{.items[*].spec.containers[*].name}'

# Ver recursos del sidecar
kubectl top pods -c istio-proxy

# Ver logs del sidecar
kubectl logs myapp-pod-xyz -c istio-proxy</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_12_1_3_control_plane_vs_data_plane">12.1.3. 12.1.3 Control Plane vs Data Plane</h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Control Plane (Istiod)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Data Plane (Envoy Proxies)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Gestiona configuración</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ejecuta tráfico</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Valida policies</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Aplica policies</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Distribución de certificados</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maneja encryption</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ofrece APIs</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Intercepta peticiones</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 por cluster</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 por pod</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>┌──────────────────────────────────┐
│   Control Plane (Istiod)         │
│  ┌─────────────────────────────┐ │
│  │ API: VirtualService         │ │
│  │ API: DestinationRule        │ │
│  │ API: Gateway                │ │
│  │ API: PeerAuthentication     │ │
│  │ Certificate Manager         │ │
│  └─────────────────────────────┘ │
│            ↓ (configura)          │
└──────────────────────────────────┘
         ↓
┌──────────────────────────────────┐
│   Data Plane (Envoy Proxies)     │
│  ┌────────────┐ ┌────────────┐   │
│  │ Pod 1      │ │ Pod 2      │   │
│  │  +Envoy    │ │  +Envoy    │   │
│  └────────────┘ └────────────┘   │
│  ┌────────────┐ ┌────────────┐   │
│  │ Pod 3      │ │ Pod 4      │   │
│  │  +Envoy    │ │  +Envoy    │   │
│  └────────────┘ └────────────┘   │
└──────────────────────────────────┘</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_12_1_4_casos_de_uso">12.1.4. 12.1.4 Casos de Uso</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Gestión de Tráfico</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Canary deployments</p>
</li>
<li>
<p>A/B testing</p>
</li>
<li>
<p>Blue-green deployments</p>
</li>
<li>
<p>Load balancing inteligente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Seguridad</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>mTLS automático</p>
</li>
<li>
<p>Autorización entre servicios</p>
</li>
<li>
<p>Encriptación end-to-end</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Observabilidad</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Tracing distribuido</p>
</li>
<li>
<p>Métricas de tráfico</p>
</li>
<li>
<p>Visualización en Kiali</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Resiliencia</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Circuit breaking</p>
</li>
<li>
<p>Retry policies</p>
</li>
<li>
<p>Timeouts</p>
</li>
<li>
<p>Bulkhead pattern</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_12_2_istio_instalación_y_arquitectura">12.2. 12.2 Istio: Instalación y Arquitectura</h3>
<div class="sect3">
<h4 id="_12_2_1_instalación_de_istio">12.2.1. 12.2.1 Instalación de Istio</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Descargar Istio
curl -L https://istio.io/downloadIstio | sh -
cd istio-1.19.0

# Agregar a PATH
export PATH=$PWD/bin:$PATH

# Verificar instalación
istioctl version

# Verificar requisitos del cluster
istioctl analyze

# Instalar Istio en default mode
istioctl install --set profile=demo -y

# Opciones de profile:
# - default: Producción
# - demo: Desarrollo/laboratorio
# - minimal: Solo istiod
# - remote: Para clusters remotos

# Verificar instalación
kubectl get pods -n istio-system
# istio-ingressgateway-xxxx
# istio-egressgateway-xxxx
# istiod-xxxx

# Inyectar sidecars automáticamente en namespace
kubectl label namespace default istio-injection=enabled

# Verificar label
kubectl get namespace default --show-labels

# Inyectar en pods existentes (redeploy)
kubectl rollout restart deployment/myapp -n default

# Verificar que tengan sidecar
kubectl get pods -o jsonpath='{.items[*].spec.containers[*].name}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_12_2_2_arquitectura_de_istio">12.2.2. 12.2.2 Arquitectura de Istio</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Componentes de Istio

# 1. Istiod (Control Plane)
# - Proporciona APIs: VirtualService, DestinationRule, etc.
# - Gestiona certificados mTLS
# - Configura proxies

# 2. Envoy (Data Plane)
# - Proxy en cada pod
# - Intercepta tráfico
# - Aplica políticas

# 3. Ingress Gateway
# - Punto de entrada al cluster
# - Reemplaza Ingress de K8s
# - Routing avanzado

# 4. Egress Gateway
# - Punto de salida del cluster
# - Tráfico a servicios externos
# - Filtrado y control

# Estructura de Istio CRDs:
# - VirtualService: Routing (A dónde va tráfico)
# - DestinationRule: Cómo llega (circuit break, lb strategy)
# - Gateway: Punto de entrada/salida
# - ServiceEntry: Servicios externos
# - PeerAuthentication: mTLS
# - AuthorizationPolicy: Quién puede acceder
# - RequestAuthentication: JWT validation
# - Telemetry: Métricas y tracing</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver recursos de Istio
kubectl get virtualservices
kubectl get destinationrules
kubectl get gateways
kubectl get peerauthentications
kubectl get authorizationpolicies

# Ver con namespace
kubectl get vs -n production
kubectl get dr -n production

# Describe de recurso
kubectl describe vs myapp-vs

# Editar
kubectl edit vs myapp-vs

# Borrar
kubectl delete vs myapp-vs</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_12_2_3_envoy_proxies">12.2.3. 12.2.3 Envoy Proxies</h4>
<div class="paragraph">
<p>Cada sidecar Envoy:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Ver configuración de Envoy
istioctl analyze

# Debug de proxy
istioctl proxy-config cluster my-pod-xyz -n default

# Ver rutas
istioctl proxy-config routes my-pod-xyz -n default

# Ver listeners (puertos que escucha)
istioctl proxy-config listeners my-pod-xyz -n default

# Ver secretos (certificados mTLS)
istioctl proxy-config secret my-pod-xyz -n default

# Logs del proxy
kubectl logs my-pod-xyz -c istio-proxy
kubectl logs my-pod-xyz -c istio-proxy -f  # realtime

# Stats del proxy
istioctl dashboard envoy my-pod-xyz
# Abre http://localhost:15000 con stats detalladas</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_12_2_4_validación_de_configuración">12.2.4. 12.2.4 Validación de Configuración</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Validar configuración global
istioctl analyze

# Validar en namespace específico
istioctl analyze -n production

# Validar archivo YAML antes de aplicar
istioctl analyze --ignore-unknown-crds my-config.yaml

# Ver configuración que se genera
istioctl analyze -o json

# Validar y reparar automáticamente
istioctl analyze --recursive=/path/to/files

# Debug de un pod
istioctl describe pod my-pod-xyz -n default

# Ver si está inyectado correctamente
kubectl get pods -o jsonpath='{.items[0].spec.containers[*].name}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_12_3_traffic_management">12.3. 12.3 Traffic Management</h3>
<div class="sect3">
<h4 id="_12_3_1_virtualservice_routing">12.3.1. 12.3.1 VirtualService: Routing</h4>
<div class="paragraph">
<p><strong>VirtualService</strong> define A DÓNDE va el tráfico.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp-vs
spec:
  # Host: servicio K8s que queremos configurar
  hosts:
  - myapp

  # HTTP: reglas de routing
  http:
  # Regla 1: Rutas que matchean /admin van a version v2
  - match:
    - uri:
        prefix: "/admin"
    route:
    - destination:
        host: myapp
        subset: v2
      weight: 100

  # Regla 2: Headers específicos van a version v3
  - match:
    - headers:
        user-type:
          exact: "premium"
    route:
    - destination:
        host: myapp
        subset: v3
      weight: 100

  # Regla 3: Default (todas las demás)
  - route:
    - destination:
        host: myapp
        subset: v1
      weight: 60
    - destination:
        host: myapp
        subset: v2
      weight: 40
    timeout: 10s
    retries:
      attempts: 3
      perTryTimeout: 2s</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Conceptos:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>hosts</code>: Servicio K8s que configuras</p>
</li>
<li>
<p><code>match</code>: Condiciones (path, header, method, etc.)</p>
</li>
<li>
<p><code>route</code>: Destinos (subsets del servicio)</p>
</li>
<li>
<p><code>weight</code>: Porcentaje de tráfico (canary)</p>
</li>
<li>
<p><code>timeout</code>: Máximo tiempo de espera</p>
</li>
<li>
<p><code>retries</code>: Reintentos automáticos</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_12_3_2_destinationrule_cómo_conectar">12.3.2. 12.3.2 DestinationRule: Cómo conectar</h4>
<div class="paragraph">
<p><strong>DestinationRule</strong> define CÓMO conectar al servicio.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: myapp-dr
spec:
  host: myapp

  # TLS: mTLS para este servicio
  trafficPolicy:
    tls:
      mode: ISTIO_MUTUAL

    # Connection pool: límites de conexiones
    connectionPool:
      tcp:
        maxConnections: 100
      http:
        http1MaxPendingRequests: 100
        http2MaxRequests: 100
        maxRequestsPerConnection: 2

    # Outlier detection: circuit breaker
    outlierDetection:
      consecutiveErrors: 5
      interval: 30s
      baseEjectionTime: 30s
      maxEjectionPercent: 50
      splitExternalLocalOriginErrors: true

    # Load balancing
    loadBalancer:
      simple: LEAST_REQUEST
      # Opciones: ROUND_ROBIN, LEAST_REQUEST, RANDOM, PASSTHROUGH

  # Subsets: versiones del servicio
  subsets:
  - name: v1
    labels:
      version: v1
    trafficPolicy:
      connectionPool:
        http:
          http1MaxPendingRequests: 50

  - name: v2
    labels:
      version: v2
    trafficPolicy:
      connectionPool:
        http:
          http1MaxPendingRequests: 100

  - name: v3
    labels:
      version: v3
    trafficPolicy:
      tls:
        mode: DISABLE  # Disable mTLS para v3</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="paragraph">
<p><strong>Conceptos:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>host</code>: Servicio destino</p>
</li>
<li>
<p><code>trafficPolicy</code>: Políticas globales</p>
</li>
<li>
<p><code>connectionPool</code>: Límites de conexiones</p>
</li>
<li>
<p><code>outlierDetection</code>: Circuit breaker</p>
</li>
<li>
<p><code>loadBalancer</code>: Estrategia de balanceo</p>
</li>
<li>
<p><code>subsets</code>: Versiones del servicio</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_12_3_3_gateway_punto_de_entrada">12.3.3. 12.3.3 Gateway: Punto de Entrada</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.istio.io/v1beta1
kind: Gateway
metadata:
  name: myapp-gateway
spec:
  selector:
    istio: ingressgateway  # Usar ingress gateway

  servers:
  # HTTPS
  - port:
      number: 443
      name: https
      protocol: HTTPS
    tls:
      mode: SIMPLE
      credentialName: myapp-tls
    hosts:
    - "myapp.example.com"
    - "app.example.com"

  # HTTP
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - "myapp.example.com"
    - "app.example.com"

---
# VirtualService vinculado a Gateway
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp-routes
spec:
  hosts:
  - "myapp.example.com"
  gateways:
  - myapp-gateway  # Usar el gateway

  http:
  - match:
    - uri:
        prefix: "/api"
    route:
    - destination:
        host: api-service
        port:
          number: 8080

  - route:
    - destination:
        host: web-service
        port:
          number: 80</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Ver gateways
kubectl get gateways

# Ver qué están escuchando
kubectl get svc -n istio-system istio-ingressgateway

# Obtener IP/hostname del gateway
kubectl get svc istio-ingressgateway -n istio-system -o jsonpath='{.status.loadBalancer.ingress[0].ip}'

# Testar acceso
curl -H "Host: myapp.example.com" http://&lt;gateway-ip&gt;/api/v1/users</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_12_3_4_canary_deployments">12.3.4. 12.3.4 Canary Deployments</h4>
<div class="paragraph">
<p>Desplegar gradualmente nueva versión:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Deployments: v1 y v2 corriendo simultáneamente
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-v1
spec:
  replicas: 9  # 90%
  selector:
    matchLabels:
      app: myapp
      version: v1
  template:
    metadata:
      labels:
        app: myapp
        version: v1
    spec:
      containers:
      - name: app
        image: myapp:1.0.0

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-v2
spec:
  replicas: 1  # 10% (canary)
  selector:
    matchLabels:
      app: myapp
      version: v2
  template:
    metadata:
      labels:
        app: myapp
        version: v2
    spec:
      containers:
      - name: app
        image: myapp:2.0.0

---
# VirtualService: envía 90% a v1, 10% a v2
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp-canary
spec:
  hosts:
  - myapp
  http:
  - route:
    - destination:
        host: myapp
        subset: v1
      weight: 90
    - destination:
        host: myapp
        subset: v2
      weight: 10  # Canary: solo 10% a v2

---
# DestinationRule: define subsets
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: myapp-canary-dr
spec:
  host: myapp
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2</code></pre>
</div>
</div>
<div class="paragraph">
<p>Proceso de canary:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Día 1: v1 90% + v2 10%
Día 2: v1 75% + v2 25%
Día 3: v1 50% + v2 50%
Día 4: v1 25% + v2 75%
Día 5: v1 0% + v2 100%
Si hay errores → Rollback inmediato</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_12_3_5_ab_testing">12.3.5. 12.3.5 A/B Testing</h4>
<div class="paragraph">
<p>Enviar usuarios específicos a versión A o B:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp-ab-test
spec:
  hosts:
  - myapp
  http:
  # Usuarios logueados → Nueva UI (v2)
  - match:
    - sourceLabels:
        user-type: "premium"
    route:
    - destination:
        host: myapp
        subset: v2

  # Usuarios anónimos → UI actual (v1)
  - match:
    - sourceLabels:
        user-type: "free"
    route:
    - destination:
        host: myapp
        subset: v1

  # Por header específico
  - match:
    - headers:
        x-test-version:
          exact: "new-ui"
    route:
    - destination:
        host: myapp
        subset: v2

  # Default
  - route:
    - destination:
        host: myapp
        subset: v1
      weight: 50
    - destination:
        host: myapp
        subset: v2
      weight: 50</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_12_4_seguridad_en_istio">12.4. 12.4 Seguridad en Istio</h3>
<div class="sect3">
<h4 id="_12_4_1_mtls_mutual_tls">12.4.1. 12.4.1 mTLS: Mutual TLS</h4>
<div class="paragraph">
<p>Encriptación automática entre servicios:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
spec:
  # Modo STRICT: mTLS es obligatorio
  mtls:
    mode: STRICT

---
# Alternative: PERMISSIVE (permite también HTTP)
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: allow-http
spec:
  mtls:
    mode: PERMISSIVE

---
# Seleccionar namespaces específicos
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: production-strict
spec:
  selector:
    matchLabels:
      security: high
  mtls:
    mode: STRICT

---
# Port-level mTLS (diferente por puerto)
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: mixed-mtls
spec:
  selector:
    matchLabels:
      app: myapp
  mtls:
    mode: PERMISSIVE
  portLevelMtls:
    8080:
      mode: DISABLE    # Puerto 8080: sin mTLS
    8443:
      mode: STRICT     # Puerto 8443: mTLS obligatorio</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Verificar certificados mTLS
istioctl proxy-config secret my-pod-xyz -n default

# Ver si mTLS está activo
kubectl logs pod-name -c istio-proxy | grep -i "tls"

# Listar PeerAuthentication
kubectl get peerauthentication

# Describir configuración
kubectl describe pa default</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_12_4_2_authorizationpolicy_control_de_acceso">12.4.2. 12.4.2 AuthorizationPolicy: Control de Acceso</h4>
<div class="paragraph">
<p>Definir quién puede acceder a qué:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: allow-frontend
spec:
  selector:
    matchLabels:
      app: backend
  rules:
  # Permitir peticiones desde frontend
  - from:
    - source:
        principals: ["cluster.local/ns/default/sa/frontend"]
    to:
    - operation:
        methods: ["GET"]
        paths: ["/api/v1/users"]

---
# Deny all (default deny)
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: deny-all
spec:
  selector:
    matchLabels:
      app: database
  rules: []  # Vacío = deny all

---
# Allow all
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: allow-all
spec:
  selector:
    matchLabels:
      app: public-api
  rules:
  - {}  # Vacío = allow all

---
# Autorización basada en JWT
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: jwt-authz
spec:
  selector:
    matchLabels:
      app: api
  rules:
  - from:
    - source:
        requestPrincipals: ["issuer@company.com/*"]
    to:
    - operation:
        methods: ["POST"]
        paths: ["/api/v1/admin/*"]

---
# Autorización por namespace
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: cross-namespace-allow
spec:
  selector:
    matchLabels:
      app: service-a
  rules:
  - from:
    - source:
        namespaces: ["production", "staging"]
    to:
    - operation:
        methods: ["GET"]</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_12_4_3_requestauthentication_jwt_validation">12.4.3. 12.4.3 RequestAuthentication: JWT Validation</h4>
<div class="paragraph">
<p>Validar JWT tokens:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">apiVersion: security.istio.io/v1beta1
kind: RequestAuthentication
metadata:
  name: jwt-auth
spec:
  selector:
    matchLabels:
      app: api
  jwtRules:
  - issuer: "https://auth.company.com"
    jwksUri: "https://auth.company.com/.well-known/jwks.json"
    audiences: "my-app"
    forwardOriginalToken: true

---
# Con múltiples issuers
apiVersion: security.istio.io/v1beta1
kind: RequestAuthentication
metadata:
  name: multi-auth
spec:
  jwtRules:
  - issuer: "https://auth1.company.com"
    jwksUri: "https://auth1.company.com/.well-known/jwks.json"
  - issuer: "https://auth2.company.com"
    jwksUri: "https://auth2.company.com/.well-known/jwks.json"</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Testar JWT
TOKEN="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."
curl -H "Authorization: Bearer $TOKEN" http://api.example.com/endpoint</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_12_5_observabilidad">12.5. 12.5 Observabilidad</h3>
<div class="sect3">
<h4 id="_12_5_1_distributed_tracing">12.5.1. 12.5.1 Distributed Tracing</h4>
<div class="paragraph">
<p>Rastrear peticiones entre servicios:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Configuración de tracing en Istio
apiVersion: telemetry.istio.io/v1alpha1
kind: Telemetry
metadata:
  name: enable-tracing
spec:
  tracing:
  - providers:
    - name: "jaeger"
    randomSamplingPercentage: 100  # 100% de peticiones

---
# Configuración de Jaeger (storage backend)
apiVersion: v1
kind: ConfigMap
metadata:
  name: jaeger-config
  namespace: istio-system
data:
  sampling.json: |
    {
      "default_strategy": {
        "type": "probabilistic",
        "param": 1
      }
    }</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Acceder a Jaeger UI
istioctl dashboard jaeger

# Ver trazas
# http://localhost:16686

# Traces muestran:
# - Latencia de cada span
# - Errores en servicios
# - Dependencias entre servicios

# Ejemplo de trace:
# GET /api/users (100ms)
# ├─ frontend → backend (50ms)
# │  └─ query users table (40ms)
# ├─ backend → database (30ms)
# │  └─ SQL query (25ms)
# └─ database → cache (5ms)</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_12_5_2_metrics_prometheus">12.5.2. 12.5.2 Metrics: Prometheus</h4>
<div class="paragraph">
<p>Istio exporta métricas a Prometheus:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Métricas disponibles automáticamente:

# request_total: Número de peticiones
# - metric: istio_requests_total
# - labels: source_app, destination_app, response_code

# request_duration: Latencia
# - metric: istio_request_duration_milliseconds
# - labels: source_app, destination_app, le (bucket)

# request_bytes: Bytes enviados
# - metric: istio_request_bytes

# response_bytes: Bytes recibidos
# - metric: istio_response_bytes

# tcp_connections_opened: Conexiones TCP
# - metric: istio_tcp_connections_opened_total

# tcp_connections_closed: Conexiones TCP cerradas
# - metric: istio_tcp_connections_closed_total</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Dashboard de Prometheus
istioctl dashboard prometheus

# Ejemplos de queries PromQL:

# Tasa de error
sum(rate(istio_requests_total{response_code=~"5.."}[5m])) by (destination_app)

# P95 latencia
histogram_quantile(0.95,
  sum(rate(istio_request_duration_milliseconds_bucket[5m])) by (destination_app, le)
)

# Tráfico por servicio
sum(rate(istio_requests_total[5m])) by (destination_app)

# Versiones en canary deployment
sum(rate(istio_requests_total[5m])) by (destination_app, destination_version)</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_12_5_3_kiali_visualización">12.5.3. 12.5.3 Kiali: Visualización</h4>
<div class="paragraph">
<p>Panel de visualización de la malla:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Abrir Kiali
istioctl dashboard kiali

# Usuario: admin
# Password: admin

# Características:
# - Graph: Visualiza servicios y tráfico
# - Workloads: Estado de pods
# - Applications: Agrupación lógica
# - Services: Servicios K8s
# - Distributed Tracing: Integración con Jaeger
# - Metrics: Gráficas de Prometheus

# Cambiar namespace
En Kiali UI: dropdown arriba a la izquierda

# Ver tráfico en tiempo real
Graph → Hover sobre conexión

# Ver errores
Services → Click en servicio → Logs</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Configurar Kiali dashboard
apiVersion: v1
kind: ConfigMap
metadata:
  name: kiali
  namespace: istio-system
data:
  kiali.yaml: |
    auth:
      strategy: anonymous
    service:
      type: LoadBalancer
    external_services:
      jaeger:
        url: http://jaeger:16686
      prometheus:
        url: http://prometheus:9090</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_12_6_ejemplo_completo_aplicación_con_istio">12.6. 12.6 Ejemplo Completo: Aplicación con Istio</h3>
<div class="paragraph">
<p>Desplegar aplicación con gestión de tráfico segura:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># 1. Deployment v1
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-v1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: v1
  template:
    metadata:
      labels:
        app: myapp
        version: v1
    spec:
      containers:
      - name: app
        image: myapp:1.0.0
        ports:
        - containerPort: 8080

---
# 2. Deployment v2 (canary)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-v2
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myapp
      version: v2
  template:
    metadata:
      labels:
        app: myapp
        version: v2
    spec:
      containers:
      - name: app
        image: myapp:2.0.0
        ports:
        - containerPort: 8080

---
# 3. Service K8s
apiVersion: v1
kind: Service
metadata:
  name: myapp
spec:
  selector:
    app: myapp
  ports:
  - port: 8080
    targetPort: 8080
    name: http

---
# 4. DestinationRule (circuit breaker + subsets)
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: myapp
spec:
  host: myapp
  trafficPolicy:
    tls:
      mode: ISTIO_MUTUAL
    connectionPool:
      http:
        http1MaxPendingRequests: 100
        maxRequestsPerConnection: 2
    outlierDetection:
      consecutiveErrors: 5
      interval: 30s
      baseEjectionTime: 30s

  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2

---
# 5. VirtualService (90/10 canary)
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp
spec:
  hosts:
  - myapp
  http:
  - route:
    - destination:
        host: myapp
        subset: v1
      weight: 90
    - destination:
        host: myapp
        subset: v2
      weight: 10
    timeout: 5s
    retries:
      attempts: 3
      perTryTimeout: 1s

---
# 6. Gateway (ingreso)
apiVersion: networking.istio.io/v1beta1
kind: Gateway
metadata:
  name: myapp-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - "myapp.example.com"

---
# 7. VirtualService para Gateway
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp-gateway-routes
spec:
  hosts:
  - "myapp.example.com"
  gateways:
  - myapp-gateway
  http:
  - route:
    - destination:
        host: myapp
        port:
          number: 8080

---
# 8. PeerAuthentication (mTLS)
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: myapp-mtls
spec:
  selector:
    matchLabels:
      app: myapp
  mtls:
    mode: STRICT

---
# 9. AuthorizationPolicy
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: myapp-authz
spec:
  selector:
    matchLabels:
      app: myapp
  rules:
  - from:
    - source:
        principals: ["cluster.local/ns/default/sa/frontend"]
    to:
    - operation:
        methods: ["GET", "POST"]
        paths: ["/api/*"]</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Desplegar todo
kubectl apply -f myapp-istio.yaml

# Verificar recursos
kubectl get deployments,svc,vs,dr,gateway,pa,authz

# Acceder a aplicación
kubectl port-forward svc/istio-ingressgateway 8080:80 -n istio-system
curl http://localhost:8080 -H "Host: myapp.example.com"

# Ver Kiali
istioctl dashboard kiali

# Generar tráfico para ver métricas
while true; do
  curl http://localhost:8080 -H "Host: myapp.example.com"
  sleep 1
done

# Gradualmente aumentar tráfico a v2
kubectl patch vs myapp --type merge -p '
{
  "spec": {
    "http": [{
      "route": [
        {"destination": {"host": "myapp", "subset": "v1"}, "weight": 50},
        {"destination": {"host": "myapp", "subset": "v2"}, "weight": 50}
      ]
    }]
  }
}'

# Si hay errores, rollback
kubectl patch vs myapp --type merge -p '
{
  "spec": {
    "http": [{
      "route": [
        {"destination": {"host": "myapp", "subset": "v1"}, "weight": 100},
        {"destination": {"host": "myapp", "subset": "v2"}, "weight": 0}
      ]
    }]
  }
}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_12_7_best_practices_con_istio">12.7. 12.7 Best Practices con Istio</h3>
<div class="paragraph">
<p><strong>1. Seguridad</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ mTLS siempre habilitado
✅ Deny-all + allow específicos
✅ JWT validation
✅ Certificados actualizados
❌ HTTP sin encripción
❌ Allow-all policies</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Performance</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ Circuit breaker configurado
✅ Timeouts apropiados
✅ Connection pools limitados
✅ Outlier detection
❌ Limites sin controlar
❌ Infinitas reintentos</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Observabilidad</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ Tracing habilitado
✅ Métricas en Prometheus
✅ Alertas en Kiali
✅ Logs centralizados
❌ Sin visibilidad
❌ Sin tracing</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. Gradualidad</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">✅ Canary deployments
✅ Blue-green sin downtime
✅ A/B testing en producción
❌ Cambios abruptos
❌ Todos afectados simultáneamente</code></pre>
</div>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_12_8_resumen_del_módulo_12">12.8. 12.8 Resumen del Módulo 12</h3>
<div class="paragraph">
<p>En este módulo aprendiste:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Conceptos de Service Mesh</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Qué es y por qué usarlo</p>
</li>
<li>
<p>Sidecar proxies (Envoy)</p>
</li>
<li>
<p>Control Plane vs Data Plane</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Istio: Instalación y Arquitectura</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Instalación con istioctl</p>
</li>
<li>
<p>Inyección automática de sidecars</p>
</li>
<li>
<p>Componentes (Istiod, Envoy, Gateways)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Traffic Management</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>VirtualService: dónde va el tráfico</p>
</li>
<li>
<p>DestinationRule: cómo conectar</p>
</li>
<li>
<p>Gateway: punto de entrada</p>
</li>
<li>
<p>Canary y A/B testing</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Seguridad</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>mTLS automático entre servicios</p>
</li>
<li>
<p>AuthorizationPolicy: control de acceso</p>
</li>
<li>
<p>RequestAuthentication: JWT validation</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Observabilidad</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Distributed tracing con Jaeger</p>
</li>
<li>
<p>Métricas en Prometheus</p>
</li>
<li>
<p>Visualización en Kiali</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Ejemplo Completo</strong>: Aplicación con canary deployment</p>
</li>
<li>
<p><strong>Best Practices</strong>: Seguridad, performance, observabilidad, gradualidad</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Con estos conocimientos, estás listo para aprender sobre <strong>Desarrollo Avanzado</strong> en el Módulo 13.</p>
</div>
<div class="paragraph">
<p>Con estos conocimientos, estás listo para aprender sobre <strong>Desarrollo Avanzado</strong> en el Módulo 13.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_apéndices">13. Apéndices</h2>
<div class="sectionbody">
<hr>
<div class="sect2">
<h3 id="_a_comandos_de_kubectl_referencia_completa">13.1. A. Comandos de kubectl: Referencia Completa</h3>
<div class="sect3">
<h4 id="_a_1_comandos_básicos">13.1.1. A.1 Comandos Básicos</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Información del cluster
kubectl version
kubectl cluster-info
kubectl api-versions
kubectl api-resources

# Namespaces
kubectl get namespaces
kubectl create namespace production
kubectl delete namespace staging
kubectl config set-context --current --namespace=production

# Contextos
kubectl config view
kubectl config get-contexts
kubectl config use-context docker-desktop
kubectl config set-context my-context --cluster=minikube --namespace=default

# Crear recursos
kubectl create deployment nginx --image=nginx
kubectl create service clusterip myapp --tcp=80:8080
kubectl create configmap app-config --from-file=config.yaml
kubectl create secret generic db-secret --from-literal=password=secret123

# Aplicar manifests
kubectl apply -f deployment.yaml
kubectl apply -f *.yaml
kubectl apply -f directory/
kubectl apply -k kustomization/

# Get: listar recursos
kubectl get pods
kubectl get pods -n production
kubectl get pods -o wide
kubectl get pods -o yaml
kubectl get pods -o json
kubectl get pods --all-namespaces
kubectl get pods -A

# Get con labels
kubectl get pods -l app=nginx
kubectl get pods -l "app=nginx,tier=frontend"
kubectl get pods --show-labels

# Get con selección de columnas
kubectl get pods -o custom-columns=NAME:.metadata.name,STATUS:.status.phase
kubectl get pods -o jsonpath='{.items[*].metadata.name}'

# Describe: detalles de un recurso
kubectl describe pod my-pod
kubectl describe node worker-1
kubectl describe svc myapp

# Delete: borrar recursos
kubectl delete pod my-pod
kubectl delete deployment nginx
kubectl delete -f deployment.yaml
kubectl delete pods --all
kubectl delete pods -l app=nginx

# Edit: editar recursos en vivo
kubectl edit deployment nginx
kubectl edit svc myapp

# Patch: cambios menores
kubectl patch deployment nginx -p '{"spec":{"replicas":5}}'
kubectl set image deployment/nginx nginx=nginx:1.20

# Exposer: crear servicios
kubectl expose pod my-pod --port=8080 --type=ClusterIP
kubectl expose deployment nginx --port=80 --type=LoadBalancer

# Port-forward: acceso local
kubectl port-forward pod/my-pod 8080:8080
kubectl port-forward svc/myapp 8080:80
kubectl port-forward deployment/nginx 3000:80 --address 0.0.0.0</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_a_2_debugging">13.1.2. A.2 Debugging</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Logs
kubectl logs pod-name
kubectl logs pod-name -c container-name
kubectl logs pod-name --follow
kubectl logs pod-name --tail=50
kubectl logs pod-name --previous  # Si el pod se reincició
kubectl logs deployment/nginx --all-containers=true

# Exec: entrar en pod
kubectl exec -it pod-name -- /bin/bash
kubectl exec -it pod-name -c container-name -- /bin/sh
kubectl exec pod-name -- ls -la
kubectl exec pod-name -- env

# Top: recursos
kubectl top nodes
kubectl top pods
kubectl top pods -n production

# Describe: detalles completos
kubectl describe pod pod-name
kubectl describe node worker-1
# Muestra: status, eventos, recursos, etc.

# Events: eventos del cluster
kubectl get events
kubectl get events -n production
kubectl get events --sort-by='.lastTimestamp'

# Status del pod
kubectl get pod pod-name -o yaml | grep -A 20 status

# Debug pod con alpine
kubectl run debug --image=alpine --restart=Never -- sleep 1000
kubectl exec -it debug -- /bin/sh

# Verificar DNS
kubectl run --rm -it debug --image=alpine --restart=Never -- nslookup kubernetes.default
kubectl run --rm -it debug --image=alpine --restart=Never -- nslookup myapp.default.svc.cluster.local

# Conectar a servicio
kubectl run --rm -it debug --image=alpine --restart=Never -- wget -qO- http://myapp:8080/health

# Ver configuración de pod
kubectl get pod pod-name -o yaml
kubectl get pod pod-name -o json

# Ver diferencias entre manifest y cluster
kubectl diff -f deployment.yaml

# Eventos de deployment
kubectl describe deployment myapp
kubectl rollout status deployment/myapp
kubectl rollout history deployment/myapp</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_a_3_flags_comunes">13.1.3. A.3 Flags Comunes</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Namespace
-n, --namespace STRING
kubectl get pods -n production

# Output
-o, --output FORMAT (json, yaml, wide, custom-columns, jsonpath, etc.)
kubectl get pods -o json
kubectl get pods -o jsonpath='{.items[*].metadata.name}'

# Selector
-l, --selector SELECTOR
kubectl get pods -l app=nginx,tier=frontend

# All namespaces
-A, --all-namespaces
kubectl get pods -A

# Watch: monitorear cambios
-w, --watch
kubectl get pods -w

# Recurse
-R, --recursive
kubectl apply -f . -R

# Dry-run: simular sin aplicar
--dry-run=client
kubectl apply -f deployment.yaml --dry-run=client

# Sort-by: ordenar
--sort-by=FIELD
kubectl get pods --sort-by=.metadata.creationTimestamp

# Show-labels: mostrar labels
--show-labels
kubectl get pods --show-labels

# Field-selector: filtrar por campos
--field-selector STATUS.phase=Running
kubectl get pods --field-selector=status.phase=Running

# Context
--context CONTEXT
kubectl get pods --context=production-cluster

# Validate: validar YAML
--validate=true
kubectl apply -f deployment.yaml --validate=true

# Record: guardar cambios
--record
kubectl set image deployment/nginx nginx=nginx:1.20 --record</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_a_4_aliases_útiles">13.1.4. A.4 Aliases Útiles</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Agregar al ~/.bashrc o ~/.zshrc
alias k='kubectl'
alias kgp='kubectl get pods'
alias kgd='kubectl get deployment'
alias kgs='kubectl get svc'
alias kgc='kubectl get configmap'
alias kgn='kubectl get nodes'
alias kdp='kubectl describe pod'
alias kdd='kubectl describe deployment'
alias kds='kubectl describe svc'
alias kdel='kubectl delete'
alias kl='kubectl logs'
alias klf='kubectl logs -f'
alias kex='kubectl exec -it'
alias kpf='kubectl port-forward'
alias kctx='kubectl config use-context'
alias kge='kubectl get events --sort-by='\''.lastTimestamp'\'

# Funciones útiles
function kns() {
  kubectl config set-context --current --namespace=$1
}

function kdesc() {
  kubectl describe $1 $2 -n ${3:-default}
}

# Uso:
kns production     # Cambiar namespace
kdesc pod myapp    # Describir pod
kgp -n production  # Get pods con namespace</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_b_recursos_yaml_referencia_completa">13.2. B. Recursos YAML: Referencia Completa</h3>
<div class="sect3">
<h4 id="_b_1_estructura_general">13.2.1. B.1 Estructura General</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Estructura base de cualquier recurso Kubernetes
apiVersion: v1                    # Versión de API
kind: Pod                         # Tipo de recurso
metadata:                         # Metadatos
  name: my-pod                    # Nombre único
  namespace: default              # Namespace (default si omitido)
  labels:                         # Etiquetas (key-value)
    app: myapp
    tier: frontend
  annotations:                    # Anotaciones (descripción, info)
    description: "My application"
    managed-by: "helm"
  ownerReferences:                # Propietario (si es owned)
  - apiVersion: apps/v1
    kind: Deployment
    name: myapp
spec:                             # Especificación
  containers:                     # Contenedores
  - name: app
    image: myapp:1.0.0
    ports:
    - containerPort: 8080
  restartPolicy: Always           # Always, Never, OnFailure
status:                           # Estado (solo lectura)
  phase: Running
  conditions: []</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_b_2_api_versions_comunes">13.2.2. B.2 API Versions Comunes</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># v1 - Recursos básicos
apiVersion: v1
kind: Pod, Service, ConfigMap, Secret, PersistentVolume, etc.

# apps/v1 - Controladores
apiVersion: apps/v1
kind: Deployment, StatefulSet, DaemonSet, ReplicaSet, etc.

# batch/v1 - Trabajos
apiVersion: batch/v1
kind: Job, CronJob

# networking.k8s.io/v1 - Networking
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy, Ingress

# storage.k8s.io/v1 - Storage
apiVersion: storage.k8s.io/v1
kind: StorageClass, VolumeAttachment

# rbac.authorization.k8s.io/v1 - RBAC
apiVersion: rbac.authorization.k8s.io/v1
kind: Role, RoleBinding, ClusterRole, ClusterRoleBinding

# policy/v1 - Policies
apiVersion: policy/v1
kind: PodDisruptionBudget

# autoscaling/v2 - Autoscaling
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler

# cert-manager.io/v1 - Certificados
apiVersion: cert-manager.io/v1
kind: Certificate, Issuer, ClusterIssuer

# networking.istio.io/v1beta1 - Istio
apiVersion: networking.istio.io/v1beta1
kind: VirtualService, DestinationRule, Gateway

# Ver todas las versiones disponibles
kubectl api-versions

# Ver recursos de una versión
kubectl api-resources --api-group=apps</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_b_3_tipos_de_recursos_kinds">13.2.3. B.3 Tipos de Recursos (Kinds)</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Workload Resources (correr aplicaciones)
Pod, Deployment, StatefulSet, DaemonSet, Job, CronJob

# Service Resources (networking)
Service, Ingress, NetworkPolicy, ServiceEntry

# Storage Resources
PersistentVolume, PersistentVolumeClaim, StorageClass, VolumeSnapshot

# Configuration Resources
ConfigMap, Secret

# RBAC Resources
ServiceAccount, Role, RoleBinding, ClusterRole, ClusterRoleBinding

# Policies
PodSecurityPolicy, NetworkPolicy, ResourceQuota, LimitRange

# Cluster Resources
Node, Namespace, Cluster

# Custom Resources (CRD)
CustomResourceDefinition, [cualquier recurso custom]

# Metadata Resources
HorizontalPodAutoscaler, VerticalPodAutoscaler, PodDisruptionBudget

# Categorías
kubectl get pods            # Workloads
kubectl get svc             # Services
kubectl get pvc             # Storage
kubectl get configmap       # Configuration
kubectl get sa              # RBAC</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_b_4_campos_comunes">13.2.4. B.4 Campos Comunes</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Presente en casi todos los recursos

metadata:
  name: my-resource           # Nombre (único en namespace)
  namespace: default          # Namespace
  uid: "550e8400-e29b-41d4"  # ID único (generado)
  resourceVersion: "123456"   # Versión (para optimistic locking)
  generation: 1               # Generación
  creationTimestamp: "2024-01-15T10:30:00Z"
  deletionTimestamp: null     # Timestamp de eliminación
  labels: {}                  # Etiquetas para seleccionar
  annotations: {}             # Anotaciones (info adicional)
  ownerReferences: []         # Propietarios
  finalizers: []              # Limpieza antes de borrar
  managedFields: []           # Información de cambios

spec:                         # Especificación deseada
  # Varía según el kind

status:                       # Estado actual (solo lectura)
  # Varía según el kind
  phase: Running              # Estado general
  conditions: []              # Condiciones detalladas
  observedGeneration: 1       # Última generación observada

# Etiquetas comunes
labels:
  app: myapp                  # Nombre de la app
  version: v1                 # Versión
  tier: frontend              # Tier (frontend, backend, database)
  environment: production     # Entorno (production, staging, dev)
  component: api              # Componente
  team: platform              # Equipo responsable

# Anotaciones comunes
annotations:
  description: "My application"
  managed-by: "helm"
  prometheus.io/scrape: "true"
  prometheus.io/port: "8080"
  external-dns.alpha.kubernetes.io/hostname: "app.example.com"</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_b_5_selectores_y_queries">13.2.5. B.5 Selectores y Queries</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Label Selector: seleccionar recursos por labels
selector:
  matchLabels:
    app: nginx              # Exacto
    tier: frontend
  matchExpressions:
- key: environment
  operator: In              # In, NotIn, Exists, DoesNotExist
  values:
  - production
  - staging
- key: tier
  operator: NotIn
  values:
  - database

# Ejemplo: Deployment que selecciona Pods
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx          # DEBE coincidir con selector
        tier: frontend
    spec:
      containers:
      - name: nginx
        image: nginx

# Field Selector: seleccionar por campos
kubectl get pods --field-selector=status.phase=Running
kubectl get pods --field-selector=spec.nodeName=worker-1

# JSONPath: queries complejas
kubectl get pods -o jsonpath='{.items[*].metadata.name}'
kubectl get pods -o jsonpath='{.items[?(@.status.phase=="Running")].metadata.name}'
kubectl get pods -o jsonpath='{.items[*].spec.containers[*].image}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_c_glosario_términos_clave_de_kubernetes">13.3. C. Glosario: Términos Clave de Kubernetes</h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Término</th>
<th class="tableblock halign-left valign-top">Definición</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>API Server</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Servidor central que gestiona toda la comunicación en el cluster. Expone la API de Kubernetes.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>kubelet</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Agente en cada nodo que asegura que los pods corren como se especificó.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>kube-proxy</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Proxy de red en cada nodo que gestiona las reglas de networking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>etcd</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Base de datos distribuida que almacena todo el estado del cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Scheduler</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Componente que asigna pods a nodos basado en recursos y políticas.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Controller Manager</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ejecuta controllers que regulan el estado del cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Pod</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Unidad más pequeña desplegable. Puede contener 1+ contenedores.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Deployment</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Controller que gestiona pods (replicas, updates, rollbacks).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>StatefulSet</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Controller para apps que requieren identidad y storage persistente.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>DaemonSet</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Asegura que todos los nodos ejecuten un pod específico.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Service</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Abstracción que expone pods como servicio (IP, DNS, puerto).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Ingress</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Router HTTP/HTTPS que expone servicios al exterior.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>ConfigMap</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Objeto que almacena configuración en pares clave-valor.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Secret</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Objeto que almacena datos sensibles (passwords, tokens, etc.).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>PersistentVolume</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Storage independiente del ciclo de vida del pod.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>PersistentVolumeClaim</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Solicitud de storage por parte de un pod.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>StorageClass</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Define tipos de storage disponibles (fast SSD, standard, etc).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Namespace</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Separación lógica de recursos dentro del cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Label</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Par clave-valor para identificar y organizar recursos.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Annotation</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Información arbitraria attached a recursos (no se usa para seleccionar).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Selector</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Mecanismo para seleccionar recursos por labels.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>RBAC</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Role-Based Access Control. Control de permisos basado en roles.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Role</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Conjunto de permisos en un namespace específico.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>RoleBinding</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Vincula un Role a usuarios/serviceaccounts en un namespace.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>ClusterRole</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Conjunto de permisos a nivel de cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>ClusterRoleBinding</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Vincula un ClusterRole a usuarios/serviceaccounts globalmente.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>ServiceAccount</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Identidad para que los pods accedan la API de K8s.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Network Policy</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Define reglas de tráfico de entrada/salida para pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Container Runtime</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Software que ejecuta contenedores (Docker, containerd, CRI-O).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Node</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Máquina (física o virtual) que ejecuta pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Cluster</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Conjunto de nodos gestionados por Kubernetes.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Control Plane</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Componentes que gestionan el cluster (API Server, Scheduler, etc.).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Worker Node</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nodo que ejecuta cargas de trabajo (pods).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Taints &amp; Tolerations</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Mecanismo para repeler pods de ciertos nodos.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Affinity</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Preferencias de scheduling de pods a nodos específicos.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Quality of Service</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Garantías de recursos: Guaranteed, Burstable, BestEffort.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Resource Request</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cantidad mínima de recursos que un contenedor necesita.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Resource Limit</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cantidad máxima de recursos que un contenedor puede usar.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Probe</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Verificación de salud: Liveness, Readiness, Startup.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Finalizer</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hook que se ejecuta antes de que un objeto sea borrado.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Operator</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Controller que maneja aplicaciones complejas automáticamente.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Custom Resource Definition</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Define nuevos tipos de recursos personalizados.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Webhook</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Callback que se ejecuta durante operaciones de API.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Admission Controller</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Plugin que intercepta y valida solicitudes de API.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>CRI</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Container Runtime Interface. Interface para runtimes de contenedores.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>CNI</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Container Network Interface. Interface para plugins de red.</p></td>
</tr>
</tbody>
</table>
<hr>
</div>
<div class="sect2">
<h3 id="_d_referencias_y_recursos">13.4. D. Referencias y Recursos</h3>
<div class="sect3">
<h4 id="_d_1_documentación_oficial">13.4.1. D.1 Documentación Oficial</h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Recurso</th>
<th class="tableblock halign-left valign-top">URL</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Documentación Oficial</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://kubernetes.io/docs/" class="bare">https://kubernetes.io/docs/</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Referencia de API</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://kubernetes.io/docs/reference/" class="bare">https://kubernetes.io/docs/reference/</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Tutoriales Interactivos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://kubernetes.io/docs/tutorials/" class="bare">https://kubernetes.io/docs/tutorials/</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Conceptos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://kubernetes.io/docs/concepts/" class="bare">https://kubernetes.io/docs/concepts/</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Tareas Comunes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://kubernetes.io/docs/tasks/" class="bare">https://kubernetes.io/docs/tasks/</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Troubleshooting</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/" class="bare">https://kubernetes.io/docs/tasks/debug-application-cluster/</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubectl Cheatsheet</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://kubernetes.io/docs/reference/kubectl/cheatsheet/" class="bare">https://kubernetes.io/docs/reference/kubectl/cheatsheet/</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">API Reference</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/" class="bare">https://kubernetes.io/docs/reference/generated/kubernetes-api/</a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_d_2_libros_recomendados">13.4.2. D.2 Libros Recomendados</h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 50%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Libro</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Nivel</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubernetes in Action</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Guía práctica con ejemplos reales. Excelente para principiantes.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Principiante</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">The Kubernetes Book</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cobertura completa de Kubernetes. Muy recomendado.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Intermedio</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubernetes Patterns</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Patrones y mejores prácticas para diseñar aplicaciones.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Avanzado</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cloud Native DevOps with Kubernetes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">DevOps con Kubernetes, GitOps, CI/CD.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Intermedio-Avanzado</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Programming Kubernetes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Extend Kubernetes con código. Operators y controllers.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Avanzado</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Production Kubernetes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Manejo de Kubernetes en producción a escala.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Avanzado</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_d_3_cursos_online">13.4.3. D.3 Cursos Online</h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Plataforma</th>
<th class="tableblock halign-left valign-top">Curso</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubernetes.io</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubernetes by Example (gratis)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Linux Academy / A Cloud Guru</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Certified Kubernetes Administrator (CKA)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Udemy</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubernetes Complete Guide to DevOps</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pluralsight</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubernetes Path</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">KodeKloud</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubernetes for Developers</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">O&#8217;Reilly</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Varios cursos en demanda</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_d_4_comunidades">13.4.4. D.4 Comunidades</h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Comunidad</th>
<th class="tableblock halign-left valign-top">Descripción</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubernetes Slack</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Comunidad oficial con canales por tema</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stack Overflow</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Preguntas y respuestas (tag: kubernetes)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubernetes Forums</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Foros oficiales de discusión</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reddit: r/kubernetes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Comunidad de Reddit dedicada a Kubernetes</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GitHub Discussions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Discusiones en repositorio oficial</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CNCF Community</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cloud Native Computing Foundation (mantiene Kubernetes)</p></td>
</tr>
</tbody>
</table>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_e_laboratorios_prácticos">13.5. E. Laboratorios Prácticos</h3>
<div class="sect3">
<h4 id="_e_1_setup_del_entorno_local">13.5.1. E.1 Setup del Entorno Local</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Opción 1: Docker Desktop (recomendado)
# Descargar desde: https://www.docker.com/products/docker-desktop
# Habilitar Kubernetes en Settings → Kubernetes → Enable

# Opción 2: Minikube
curl -LO https://github.com/kubernetes/minikube/releases/download/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube
minikube start
minikube status
minikube stop

# Opción 3: Kind (Kubernetes in Docker)
go install sigs.k8s.io/kind@latest
kind create cluster --name my-cluster
kind delete cluster --name my-cluster

# Opción 4: k3s (Kubernetes ligero)
curl -sfL https://get.k3s.io | sh -
sudo systemctl start k3s
sudo systemctl stop k3s

# Instalar kubectl
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

# Instalar otros tools
# Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# kubectx (cambiar contexto rápidamente)
git clone https://github.com/ahmetb/kubectx /opt/kubectx
sudo ln -s /opt/kubectx/kubectx /usr/local/bin/kubectx

# Verificar instalación
kubectl version
kubectl cluster-info
kubectl get nodes</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_e_2_laboratorio_1_deploy_simple">13.5.2. E.2 Laboratorio 1: Deploy Simple</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Ejercicio: Desplegar nginx, exponerlo y acceder

# 1. Crear deployment
cat &gt; nginx-deploy.yaml &lt;&lt; EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
EOF

kubectl apply -f nginx-deploy.yaml

# 2. Crear servicio
kubectl expose deployment nginx --type=LoadBalancer --port=80

# 3. Verificar
kubectl get deployments
kubectl get pods
kubectl get svc

# 4. Acceder (esperar IP o usar port-forward)
kubectl port-forward svc/nginx 8080:80

# 5. En otra terminal
curl http://localhost:8080

# Solución esperada: página de bienvenida de nginx</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_e_3_laboratorio_2_configmap_y_secrets">13.5.3. E.3 Laboratorio 2: ConfigMap y Secrets</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Ejercicio: Crear app con configuración y secrets

# 1. Crear ConfigMap
kubectl create configmap app-config \
  --from-literal=log_level=info \
  --from-literal=env=production

# 2. Crear Secret
kubectl create secret generic db-secret \
  --from-literal=username=admin \
  --from-literal=password=secret123

# 3. Crear pod que use ambos
cat &gt; app-with-config.yaml &lt;&lt; EOF
apiVersion: v1
kind: Pod
metadata:
  name: app
spec:
  containers:
  - name: app
    image: myapp:1.0
    env:
    - name: LOG_LEVEL
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: log_level
    - name: DB_USERNAME
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: username
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: password
EOF

kubectl apply -f app-with-config.yaml

# 4. Verificar que el pod tiene las variables
kubectl exec -it app -- env | grep -E "LOG_LEVEL|DB_"

# Solución: Ver variables en el pod</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_e_4_laboratorio_3_scaling_y_autoescaling">13.5.4. E.4 Laboratorio 3: Scaling y Autoescaling</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Ejercicio: Escalar pods manualmente y luego automáticamente

# 1. Ver replicas
kubectl get deployment nginx

# 2. Escalar manualmente
kubectl scale deployment nginx --replicas=5

# 3. Ver que aumentó
kubectl get pods

# 4. Crear HPA
cat &gt; hpa.yaml &lt;&lt; EOF
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
EOF

kubectl apply -f hpa.yaml

# 5. Generar carga para ver scaling
kubectl run load-gen --image=busybox --restart=Never -- /bin/sh -c "while true; do wget -q -O- http://nginx; done"

# 6. Ver HPA en acción
kubectl get hpa -w
kubectl get pods -w

# Solución: Ver pods escalando arriba/abajo según carga</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_e_5_laboratorio_4_networking">13.5.5. E.5 Laboratorio 4: Networking</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Ejercicio: Crear servicios y testar conectividad

# 1. Crear dos deployments
kubectl create deployment web --image=nginx
kubectl create deployment api --image=node:alpine

# 2. Exponer con ClusterIP
kubectl expose deployment web --port=80 --type=ClusterIP
kubectl expose deployment api --port=3000 --type=ClusterIP

# 3. Desde un pod, conectar a otro servicio
kubectl run client --image=alpine --restart=Never -it -- sh

# Dentro del pod:
# nslookup web  # Ver IP
# wget -qO- http://web  # Acceder

# 4. Crear Ingress
cat &gt; ingress.yaml &lt;&lt; EOF
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-ingress
spec:
  rules:
  - host: web.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web
            port:
              number: 80
EOF

kubectl apply -f ingress.yaml

# 5. Acceder via ingress (requiere configured ingress controller)
# En /etc/hosts:
# 127.0.0.1 web.local

# Solución: Navegar a http://web.local</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
</div>
<div class="sect3">
<h4 id="_e_6_laboratorio_5_persistencia">13.5.6. E.6 Laboratorio 5: Persistencia</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml"># Ejercicio: Crear PVC y usarlo en pod

# 1. Ver StorageClasses disponibles
kubectl get storageclasses

# 2. Crear PersistentVolumeClaim
cat &gt; pvc.yaml &lt;&lt; EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: data-pvc
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: standard
  resources:
    requests:
      storage: 5Gi
EOF

kubectl apply -f pvc.yaml

# 3. Crear pod que use PVC
cat &gt; pod-with-pvc.yaml &lt;&lt; EOF
apiVersion: v1
kind: Pod
metadata:
  name: data-pod
spec:
  containers:
  - name: app
    image: nginx
    volumeMounts:
    - name: data
      mountPath: /data
  volumes:
  - name: data
    persistentVolumeClaim:
      claimName: data-pvc
EOF

kubectl apply -f pod-with-pvc.yaml

# 4. Escribir datos
kubectl exec -it data-pod -- sh -c "echo 'hello' &gt; /data/test.txt"

# 5. Eliminar pod y recrear
kubectl delete pod data-pod
kubectl apply -f pod-with-pvc.yaml

# 6. Verificar que datos persisten
kubectl exec -it data-pod -- cat /data/test.txt

# Solución: Ver "hello" en la salida</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
<div class="sect2">
<h3 id="_f_examen_de_certificación">13.6. F. Examen de Certificación</h3>
<div class="sect3">
<h4 id="_f_1_cka_certified_kubernetes_administrator">13.6.1. F.1 CKA: Certified Kubernetes Administrator</h4>
<div class="paragraph">
<p><strong>Contenido del examen:</strong>
- Cluster Architecture, Installation &amp; Configuration (25%)
- Workloads &amp; Scheduling (15%)
- Services &amp; Networking (20%)
- Storage (10%)
- Troubleshooting (30%)</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 50%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Tema</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Importancia</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cluster Setup</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kubeadm, versiones, upgrades</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alta</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RBAC</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Roles, RoleBindings, ServiceAccounts</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alta</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Networking</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Services, Ingress, Network Policies</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alta</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Storage</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PVC, PV, StorageClass</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Media</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Troubleshooting</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Debugging pods, nodes, networking</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alta</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Security</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pod Security, Secrets management</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Media</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Recursos de estudio:</strong>
- Documentación oficial: <a href="https://kubernetes.io/docs/" class="bare">https://kubernetes.io/docs/</a>
- Hands-on labs: <a href="https://kodekloud.com/courses/kubernetes-challenge/" class="bare">https://kodekloud.com/courses/kubernetes-challenge/</a>
- Simulacros: <a href="https://killer.sh/" class="bare">https://killer.sh/</a></p>
</div>
<div class="paragraph">
<p><strong>Tips para el examen:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>✅ Practica mucho: 70% del examen es práctico
✅ Domina kubectl: Es la herramienta principal
✅ Conoce los flags comunes: --dry-run, -o yaml, etc.
✅ Crea aliases útiles: alias k=kubectl
✅ Practica bajo presión: El examen tiene tiempo limitado
✅ Lee cuidadosamente: Las preguntas pueden ser tricky
❌ No intentes memorizar: Enfócate en entender conceptos</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_f_2_ckad_certified_kubernetes_application_developer">13.6.2. F.2 CKAD: Certified Kubernetes Application Developer</h4>
<div class="paragraph">
<p><strong>Contenido del examen:</strong>
- Application Design and Build (20%)
- Application Deployment (20%)
- Application Observability and Maintenance (15%)
- Application Environment, Config and Security (25%)
- Services and Networking (20%)</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 50%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Tema</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Importancia</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Deployments</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Crear, actualizar, debuggear</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alta</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Networking</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Services, Ingress, DNS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alta</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configuration</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ConfigMaps, Secrets, env vars</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alta</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Storage</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Volumes, PVC</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Media</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Observability</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Logs, metrics, debugging</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Media</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Security</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">RBAC, Pod Security, Secrets</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Media</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Resource Limits</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Requests, limits, QoS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Media</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Recursos de estudio:</strong>
- Documentación oficial
- KodeKloud CKAD course: <a href="https://kodekloud.com/courses/kubernetes-for-developers-ckad/" class="bare">https://kodekloud.com/courses/kubernetes-for-developers-ckad/</a>
- Simulacros: <a href="https://killer.sh/" class="bare">https://killer.sh/</a></p>
</div>
<div class="paragraph">
<p><strong>Tips para el examen:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>✅ Conoce imperative commands: kubectl run, create, expose
✅ Familiarízate con Deployments: Updates, rollbacks
✅ Entiende ConfigMaps y Secrets: Cómo usarlos
✅ Debugging: logs, exec, describe
✅ Networking: Services, DNS, Ingress
✅ Autoscaling: HPA, manual scaling</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_f_3_cks_certified_kubernetes_security_specialist">13.6.3. F.3 CKS: Certified Kubernetes Security Specialist</h4>
<div class="paragraph">
<p><strong>Contenido del examen:</strong>
- Cluster Setup (10%)
- Cluster Hardening (15%)
- System Hardening (15%)
- Minimize Microservice Vulnerabilities (20%)
- Supply Chain Security (20%)
- Monitoring, Logging and Runtime Security (20%)</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 50%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Tema</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Importancia</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pod Security</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Pod Security Policies, Security Contexts</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alta</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RBAC</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Roles, bindings, service accounts</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alta</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Network Policies</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Control de tráfico entre pods</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alta</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Secrets Management</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Encryption at rest, in transit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Alta</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Image Security</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Image scanning, registry security</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Media</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Runtime Security</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Container runtime, monitoring</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Media</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Compliance</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Best practices, hardening</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Media</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Recursos de estudio:</strong>
- Documentación oficial + security guide
- KodeKloud CKS course: <a href="https://kodekloud.com/courses/certified-kubernetes-security-specialist-cks/" class="bare">https://kodekloud.com/courses/certified-kubernetes-security-specialist-cks/</a>
- Simulacros: <a href="https://killer.sh/" class="bare">https://killer.sh/</a></p>
</div>
<div class="paragraph">
<p><strong>Tips para el examen:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>✅ Entiende RBAC profundamente: RBAC está en muchas preguntas
✅ Network Policies: Cómo bloquear/permitir tráfico
✅ Pod Security: Security Contexts, policies
✅ Encryption: etcd encryption, TLS
✅ Secrets management: No guardes en plain text
✅ Image security: Sighing, scanning, registry</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_f_4_estrategia_general_de_preparación">13.6.4. F.4 Estrategia General de Preparación</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Fase 1: Aprender (2-3 semanas)
# - Completar todos los módulos del curso
# - Hacer ejercicios prácticos
# - Leer documentación oficial

# Fase 2: Practicar (2-3 semanas)
# - Laboratorios prácticos intensivos
# - Simulacros de examen
# - Aumentar velocidad y precisión

# Fase 3: Intensivo (1 semana)
# - Simulacros bajo tiempo
# - Practica en entorno similiar al examen
# - Revisa temas débiles

# Fase 4: Descanso (3 días)
# - Descansa antes del examen
# - No intentes aprender cosas nuevas
# - Duerme bien

# Día del examen:
# - Llega 15 minutos antes
# - Verifica conexión de internet
# - Lee todas las preguntas primero
# - Maneja bien el tiempo
# - Evita errores de typo (copia-pega)

# Comando útil para practicar rápido:
alias kdry='kubectl --dry-run=client -o yaml'
alias kex='kubectl exec -it'
alias kl='kubectl logs'

# Practica imperativa:
kubectl run pod-name --image=image-name --dry-run=client -o yaml
kubectl create deployment name --image=image --dry-run=client -o yaml
kubectl expose pod pod-name --port=8080 --dry-run=client -o yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>]</p>
</div>
<hr>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_fin_del_curso_kubernetes_completo">14. FIN DEL CURSO: KUBERNETES COMPLETO</h2>
<div class="sectionbody">
<div class="paragraph">
<p><strong>Felicitaciones por completar este curso comprehensivo de Kubernetes.</strong></p>
</div>
<div class="paragraph">
<p>Durante 12 módulos + Apéndices, cubriste:</p>
</div>
<div class="paragraph">
<p>✅ <strong>Módulo 1:</strong> Introducción a Kubernetes
✅ <strong>Módulo 2:</strong> Pods y Contenedores
✅ <strong>Módulo 3:</strong> Controladores (Deployment, StatefulSet, DaemonSet, Jobs)
✅ <strong>Módulo 4:</strong> Servicios y Networking (Service, Ingress, DNS)
✅ <strong>Módulo 5:</strong> Configuración y Secretos (ConfigMap, Secret)
✅ <strong>Módulo 6:</strong> Storage (PV, PVC, StorageClass, StatefulSet)
✅ <strong>Módulo 7:</strong> Scaling y Autoscaling (HPA, VPA, manual scaling)
✅ <strong>Módulo 8:</strong> Seguridad (RBAC, Pod Security, Network Policies, mTLS)
✅ <strong>Módulo 9:</strong> Monitoreo y Logging (Prometheus, Grafana, ELK, Jaeger)
✅ <strong>Módulo 10:</strong> GitOps y CI/CD (Flux, ArgoCD, GitHub Actions, Tekton)
✅ <strong>Módulo 11:</strong> Helm Package Manager (Charts, Templating, Releases)
✅ <strong>Módulo 12:</strong> Service Mesh con Istio (mTLS, Routing, Observability)</p>
</div>
<div class="paragraph">
<p><strong>Apéndices:</strong>
✅ <strong>A:</strong> Comandos kubectl Referencia Completa
✅ <strong>B:</strong> Recursos YAML y Estructura
✅ <strong>C:</strong> Glosario de Términos
✅ <strong>D:</strong> Referencias y Recursos
✅ <strong>E:</strong> Laboratorios Prácticos
✅ <strong>F:</strong> Examen de Certificación (CKA, CKAD, CKS)</p>
</div>
<hr>
<div class="paragraph">
<p><strong>Próximos Pasos:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Practica constantemente</strong>: La mejor forma de aprender K8s es usándolo</p>
</li>
<li>
<p><strong>Construye proyectos</strong>: Deploya aplicaciones reales en K8s</p>
</li>
<li>
<p><strong>Explora ecosistema</strong>: Operator, CRDs, Plugins, Custom controllers</p>
</li>
<li>
<p><strong>Certifícate</strong>: CKA, CKAD o CKS según tu especialidad</p>
</li>
<li>
<p><strong>Contribuye</strong>: Kubernetes es open-source, contribuye a la comunidad</p>
</li>
</ol>
</div>
<hr>
<div class="paragraph">
<p><strong>Curso desarrollado como material de referencia comprehensive para Kubernetes. Todos los ejemplos son funcionales y listos para producción.</strong></p>
</div>
<div class="paragraph">
<p><strong>Última actualización: 2024</strong>
<strong>Versión del curso: 2.0</strong></p>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2025-11-06 07:42:52 +0100
</div>
</div>
</body>
</html>